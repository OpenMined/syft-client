{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Delete Operations Demo\n",
    "\n",
    "This notebook demonstrates how SyftWatcher handles file deletion operations and allows manual inspection of the append-only log."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path().absolute().parent))\n",
    "\n",
    "from syft_sync import SyftWatcher\n",
    "from tests.test_utils import (\n",
    "    extract_syft_archive,\n",
    "    read_file_from_archive,\n",
    "    get_archive_metadata,\n",
    "    verify_syft_message_content,\n",
    "    get_version_archive\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Create Test Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary directories for testing\n",
    "temp_dir = Path(tempfile.mkdtemp())\n",
    "watch_dir = temp_dir / \"watched\"\n",
    "log_dir = temp_dir / \"logs\"\n",
    "\n",
    "watch_dir.mkdir(parents=True)\n",
    "log_dir.mkdir(parents=True)\n",
    "\n",
    "print(f\"Watch directory: {watch_dir}\")\n",
    "print(f\"Log directory: {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Initialize Watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and start the watcher\n",
    "watcher = SyftWatcher(\n",
    "    watch_path=str(watch_dir),\n",
    "    log_path=str(log_dir),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "watcher.start()\n",
    "print(\"Watcher started!\")\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Create Some Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create several test files\n",
    "test_files = [\n",
    "    (\"important_doc.txt\", \"This document contains important information that should not be lost.\"),\n",
    "    (\"config.json\", json.dumps({\"app\": \"demo\", \"version\": \"1.0\", \"debug\": True}, indent=2)),\n",
    "    (\"script.py\", \"#!/usr/bin/env python3\\nprint('Hello from delete demo')\\n\"),\n",
    "]\n",
    "\n",
    "for filename, content in test_files:\n",
    "    file_path = watch_dir / filename\n",
    "    file_path.write_text(content)\n",
    "    print(f\"Created: {filename}\")\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Inspect Current Log Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_log_structure(log_dir):\n",
    "    \"\"\"Display the structure of the log directory\"\"\"\n",
    "    print(f\"\\nLog directory structure:\")\n",
    "    for root, dirs, files in os.walk(log_dir):\n",
    "        level = root.replace(str(log_dir), '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        sub_indent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            print(f'{sub_indent}{file}')\n",
    "\n",
    "show_log_structure(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show archive contents\n",
    "archives = sorted(log_dir.glob('*.tar.gz'))\n",
    "print(f\"\\nFound {len(archives)} archives:\")\n",
    "for archive in archives:\n",
    "    print(f\"  - {archive.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Delete a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete one of the files\n",
    "file_to_delete = watch_dir / \"important_doc.txt\"\n",
    "print(f\"Deleting: {file_to_delete.name}\")\n",
    "file_to_delete.unlink()\n",
    "\n",
    "# Wait for the delete event to be processed\n",
    "time.sleep(1.0)\n",
    "\n",
    "print(\"File deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Inspect Log After Deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show updated log structure\n",
    "show_log_structure(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all archives again\n",
    "archives = sorted(log_dir.glob('*.tar.gz'))\n",
    "print(f\"\\nNow have {len(archives)} archives:\")\n",
    "for archive in archives:\n",
    "    print(f\"  - {archive.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Examine Archive Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metadata from all archives\n",
    "all_events = []\n",
    "for archive_path in archives:\n",
    "    metadata_list = get_archive_metadata(archive_path)\n",
    "    for metadata in metadata_list:\n",
    "        if 'version_id' in metadata and 'event_type' in metadata:\n",
    "            event_info = {\n",
    "                'archive': archive_path.name,\n",
    "                'version_id': metadata['version_id'],\n",
    "                'event_type': metadata['event_type'],\n",
    "                'file_name': metadata.get('file_name', 'N/A'),\n",
    "                'timestamp': metadata.get('timestamp', 'N/A')\n",
    "            }\n",
    "            all_events.append(event_info)\n",
    "\n",
    "# Sort by timestamp\n",
    "all_events.sort(key=lambda x: x['timestamp'])\n",
    "\n",
    "# Display events\n",
    "print(\"\\nAll events in chronological order:\")\n",
    "for event in all_events:\n",
    "    print(f\"\\nArchive: {event['archive']}\")\n",
    "    print(f\"  Event: {event['event_type']}\")\n",
    "    print(f\"  File: {event['file_name']}\")\n",
    "    print(f\"  Version: {event['version_id']}\")\n",
    "    print(f\"  Time: {event['timestamp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Find and Restore Deleted File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the create event for our deleted file\n",
    "deleted_file_name = \"important_doc.txt\"\n",
    "create_event = None\n",
    "\n",
    "for event in all_events:\n",
    "    if event['event_type'] == 'file_created' and event['file_name'] == deleted_file_name:\n",
    "        create_event = event\n",
    "        break\n",
    "\n",
    "if create_event:\n",
    "    print(f\"Found create event for {deleted_file_name}:\")\n",
    "    print(f\"  Version ID: {create_event['version_id']}\")\n",
    "    print(f\"  Archive: {create_event['archive']}\")\n",
    "else:\n",
    "    print(f\"No create event found for {deleted_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read content from the archive\n",
    "if create_event:\n",
    "    archive = get_version_archive(log_dir, create_event['version_id'])\n",
    "    if archive:\n",
    "        try:\n",
    "            content = read_file_from_archive(archive, deleted_file_name)\n",
    "            print(f\"\\nRecovered content from archive:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(content)\n",
    "            print(\"-\" * 50)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading from archive: {e}\")\n",
    "    else:\n",
    "        print(\"Archive not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the file\n",
    "if create_event:\n",
    "    archive = get_version_archive(log_dir, create_event['version_id'])\n",
    "    if archive:\n",
    "        restore_path = watch_dir / f\"restored_{deleted_file_name}\"\n",
    "        \n",
    "        # Extract and restore\n",
    "        info = extract_syft_archive(archive)\n",
    "        try:\n",
    "            source_file = info[\"data_dir\"] / deleted_file_name\n",
    "            if source_file.exists():\n",
    "                shutil.copy2(source_file, restore_path)\n",
    "                print(f\"\\nFile restored to: {restore_path}\")\n",
    "                print(f\"Content: {restore_path.read_text()}\")\n",
    "            else:\n",
    "                print(f\"File not found in archive data directory\")\n",
    "        finally:\n",
    "            shutil.rmtree(info[\"temp_dir\"], ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Delete Events Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all delete events\n",
    "delete_events = [e for e in all_events if e['event_type'] == 'file_deleted']\n",
    "print(f\"\\nFound {len(delete_events)} delete events:\")\n",
    "for event in delete_events:\n",
    "    print(f\"\\n  File: {event['file_name']}\")\n",
    "    print(f\"  Time: {event['timestamp']}\")\n",
    "    print(f\"  Archive: {event['archive']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Examine a Specific Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick an archive to examine in detail\n",
    "if archives:\n",
    "    archive_to_examine = archives[0]  # Examine the first archive\n",
    "    print(f\"\\nExamining archive: {archive_to_examine.name}\")\n",
    "    \n",
    "    # Extract and show structure\n",
    "    info = extract_syft_archive(archive_to_examine)\n",
    "    try:\n",
    "        print(f\"\\nArchive structure:\")\n",
    "        print(f\"  Message directory: {info['message_dir'].name}\")\n",
    "        print(f\"  Has data directory: {info['data_dir'].exists()}\")\n",
    "        print(f\"  Metadata files: {len(info['metadata_files'])}\")\n",
    "        for mf in info['metadata_files']:\n",
    "            print(f\"    - {mf.name}\")\n",
    "        print(f\"  Data files: {len(info['data_files'])}\")\n",
    "        for df in info['data_files']:\n",
    "            print(f\"    - {df.name}\")\n",
    "            \n",
    "        # Show metadata content\n",
    "        if info['metadata_files']:\n",
    "            with open(info['metadata_files'][0], 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "            print(f\"\\nMetadata content:\")\n",
    "            print(json.dumps(metadata, indent=2))\n",
    "    finally:\n",
    "        shutil.rmtree(info[\"temp_dir\"], ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Stop Watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the watcher\n",
    "watcher.stop()\n",
    "print(\"Watcher stopped.\")\n",
    "\n",
    "# Show final stats\n",
    "stats = watcher.get_stats()\n",
    "print(f\"\\nFinal statistics:\")\n",
    "print(f\"  Files created: {stats['files_created']}\")\n",
    "print(f\"  Files modified: {stats['files_modified']}\")\n",
    "print(f\"  Files deleted: {stats['files_deleted']}\")\n",
    "print(f\"  Total versions: {stats['total_versions']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally cleanup the temporary directories\n",
    "cleanup = input(\"\\nCleanup temporary directories? (y/n): \")\n",
    "if cleanup.lower() == 'y':\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(\"Cleaned up!\")\n",
    "else:\n",
    "    print(f\"\\nDirectories preserved at:\")\n",
    "    print(f\"  Watch: {watch_dir}\")\n",
    "    print(f\"  Log: {log_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}