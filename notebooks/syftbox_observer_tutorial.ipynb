{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SyftBox File Observer Tutorial\n",
    "\n",
    "This tutorial demonstrates how to automatically create SyftMessages when files change in your datasites folder.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The SyftBox File Observer:\n",
    "- Monitors `~/SyftBox_{email}/datasites/` for file changes\n",
    "- Creates SyftMessages automatically for file events\n",
    "- Stores messages in `~/SyftBox_{email}/outbox/` ready for transport\n",
    "- Provides a REST API for monitoring and control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import required libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft_serve as ss\n",
    "import syft_client as sc\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "EMAIL = \"andrew@openmined.org\"  # Change to your email\n",
    "SYFTBOX_DIR = Path.home() / f\"SyftBox_{EMAIL}\"\n",
    "DATASITES_DIR = SYFTBOX_DIR / \"datasites\"\n",
    "OUTBOX_DIR = SYFTBOX_DIR / \"outbox\"\n",
    "\n",
    "# Create directories\n",
    "DATASITES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTBOX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ SyftBox: {SYFTBOX_DIR}\")\n",
    "print(f\"üìÇ Datasites: {DATASITES_DIR}\")\n",
    "print(f\"üì§ Outbox: {OUTBOX_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Observer Example\n",
    "\n",
    "Let's start with a simple observer that logs file changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate any existing servers\n",
    "ss.servers.terminate_all()\n",
    "\n",
    "def simple_observer():\n",
    "    from watchdog.observers import Observer\n",
    "    from watchdog.events import FileSystemEventHandler\n",
    "    import sys\n",
    "    \n",
    "    # Force unbuffered output\n",
    "    sys.stdout.reconfigure(line_buffering=True)\n",
    "    \n",
    "    class SimpleHandler(FileSystemEventHandler):\n",
    "        def on_any_event(self, event):\n",
    "            if not event.is_directory:\n",
    "                print(f\"üìù {event.event_type}: {Path(event.src_path).name}\", flush=True)\n",
    "    \n",
    "    observer = Observer()\n",
    "    observer.schedule(SimpleHandler(), str(DATASITES_DIR), recursive=True)\n",
    "    observer.start()\n",
    "    \n",
    "    return {\"status\": \"Observer started\", \"watching\": str(DATASITES_DIR)}\n",
    "\n",
    "# Create server\n",
    "server = ss.create(\n",
    "    name=\"simple_observer\",\n",
    "    dependencies=[\"watchdog\"],\n",
    "    endpoints={\"/start\": simple_observer}\n",
    ")\n",
    "\n",
    "print(f\"\\nüåê Server: {server.url}\")\n",
    "\n",
    "# Start the observer\n",
    "response = requests.get(f\"{server.url}/start\")\n",
    "print(f\"‚úÖ {response.json()['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Simple Observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test file\n",
    "test_file = DATASITES_DIR / \"test_data.csv\"\n",
    "test_file.write_text(\"id,name,value\\n1,Alice,100\\n2,Bob,200\")\n",
    "print(f\"Created: {test_file.name}\")\n",
    "\n",
    "# Wait a moment\n",
    "time.sleep(1)\n",
    "\n",
    "# Check the logs\n",
    "logs = ss.servers['simple_observer'].stdout.lines()[-5:]\n",
    "print(\"\\nRecent logs:\")\n",
    "for log in logs:\n",
    "    print(f\"  {log}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full SyftMessage Observer\n",
    "\n",
    "Now let's create the full observer that creates SyftMessages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate previous server\n",
    "ss.servers.terminate_all()\n",
    "\n",
    "# Global state\n",
    "state = {\n",
    "    \"observer\": None,\n",
    "    \"messages_created\": 0,\n",
    "    \"last_event\": None\n",
    "}\n",
    "\n",
    "def start_syft_observer():\n",
    "    from watchdog.observers import Observer\n",
    "    from watchdog.events import FileSystemEventHandler\n",
    "    import sys\n",
    "    \n",
    "    sys.stdout.reconfigure(line_buffering=True)\n",
    "    \n",
    "    class SyftMessageHandler(FileSystemEventHandler):\n",
    "        def on_created(self, event):\n",
    "            self.handle_event(event, \"created\")\n",
    "        \n",
    "        def on_modified(self, event):\n",
    "            self.handle_event(event, \"modified\")\n",
    "        \n",
    "        def on_deleted(self, event):\n",
    "            self.handle_event(event, \"deleted\")\n",
    "        \n",
    "        def handle_event(self, event, event_type):\n",
    "            if event.is_directory:\n",
    "                return\n",
    "                \n",
    "            file_path = Path(event.src_path)\n",
    "            \n",
    "            # Skip hidden and temp files\n",
    "            if file_path.name.startswith('.') or file_path.suffix == '.tmp':\n",
    "                return\n",
    "            \n",
    "            print(f\"\\nüîî {event_type}: {file_path.name}\", flush=True)\n",
    "            \n",
    "            try:\n",
    "                # Create SyftMessage\n",
    "                recipient = \"recipient@example.com\"  # In practice, determined by datasite\n",
    "                \n",
    "                message = sc.SyftMessage.create(\n",
    "                    sender_email=EMAIL,\n",
    "                    recipient_email=recipient,\n",
    "                    message_root=OUTBOX_DIR,\n",
    "                    message_type=\"file_update\"\n",
    "                )\n",
    "                \n",
    "                # Add event metadata\n",
    "                message.update_metadata({\n",
    "                    \"event_type\": event_type,\n",
    "                    \"datasite_path\": str(file_path.relative_to(DATASITES_DIR)),\n",
    "                    \"timestamp\": time.time()\n",
    "                })\n",
    "                \n",
    "                # Add file if it exists\n",
    "                if event_type != \"deleted\" and file_path.exists():\n",
    "                    syftbox_path = f\"/{EMAIL}/datasites/{file_path.relative_to(DATASITES_DIR)}\"\n",
    "                    message.add_file(\n",
    "                        source_path=file_path,\n",
    "                        syftbox_path=syftbox_path,\n",
    "                        permissions={\n",
    "                            \"read\": [recipient],\n",
    "                            \"write\": [EMAIL],\n",
    "                            \"admin\": [EMAIL]\n",
    "                        }\n",
    "                    )\n",
    "                \n",
    "                # Add README\n",
    "                message.add_readme(f\"\"\"\n",
    "                <html><body>\n",
    "                <h2>File Update</h2>\n",
    "                <p>Event: {event_type}</p>\n",
    "                <p>File: {file_path.name}</p>\n",
    "                <p>Time: {time.strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "                </body></html>\n",
    "                \"\"\")\n",
    "                \n",
    "                # Finalize\n",
    "                message.finalize()\n",
    "                \n",
    "                state[\"messages_created\"] += 1\n",
    "                state[\"last_event\"] = {\n",
    "                    \"type\": event_type,\n",
    "                    \"file\": file_path.name,\n",
    "                    \"message_id\": message.message_id\n",
    "                }\n",
    "                \n",
    "                print(f\"‚úÖ Created message: {message.message_id}\", flush=True)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {e}\", flush=True)\n",
    "    \n",
    "    if state[\"observer\"] is None:\n",
    "        observer = Observer()\n",
    "        observer.schedule(SyftMessageHandler(), str(DATASITES_DIR), recursive=True)\n",
    "        observer.start()\n",
    "        state[\"observer\"] = observer\n",
    "        \n",
    "    return {\"status\": \"SyftMessage observer started\"}\n",
    "\n",
    "def get_status():\n",
    "    return {\n",
    "        \"running\": state[\"observer\"] is not None,\n",
    "        \"messages_created\": state[\"messages_created\"],\n",
    "        \"last_event\": state[\"last_event\"]\n",
    "    }\n",
    "\n",
    "# Create server\n",
    "server = ss.create(\n",
    "    name=\"syft_observer\",\n",
    "    dependencies=[\"watchdog\"],\n",
    "    endpoints={\n",
    "        \"/start\": start_syft_observer,\n",
    "        \"/status\": get_status\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"üåê Server: {server.url}\")\n",
    "\n",
    "# Start observer\n",
    "response = requests.get(f\"{server.url}/start\")\n",
    "print(f\"‚úÖ {response.json()['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SyftMessage Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data file\n",
    "data_file = DATASITES_DIR / \"experiment_results.csv\"\n",
    "data_file.write_text(\"\"\"\n",
    "experiment_id,accuracy,precision,recall\n",
    "exp_001,0.92,0.89,0.94\n",
    "exp_002,0.94,0.91,0.96\n",
    "exp_003,0.93,0.90,0.95\n",
    "\"\".strip())\n",
    "\n",
    "print(f\"üìÑ Created: {data_file.name}\")\n",
    "\n",
    "# Wait for processing\n",
    "time.sleep(2)\n",
    "\n",
    "# Check status\n",
    "status = requests.get(f\"{server.url}/status\").json()\n",
    "print(f\"\\nüìä Status:\")\n",
    "print(f\"  Messages created: {status['messages_created']}\")\n",
    "if status['last_event']:\n",
    "    print(f\"  Last event: {status['last_event']['type']} - {status['last_event']['file']}\")\n",
    "    print(f\"  Message ID: {status['last_event']['message_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the outbox\n",
    "print(\"üì§ Messages in outbox:\\n\")\n",
    "\n",
    "for msg_dir in sorted(OUTBOX_DIR.iterdir()):\n",
    "    if msg_dir.is_dir() and msg_dir.name.startswith(\"gdrive_\"):\n",
    "        print(f\"üì© {msg_dir.name}\")\n",
    "        \n",
    "        # Load message\n",
    "        try:\n",
    "            msg = sc.SyftMessage(msg_dir)\n",
    "            metadata = msg.get_metadata()\n",
    "            \n",
    "            print(f\"   Event: {metadata.get('event_type')}\")\n",
    "            print(f\"   File: {metadata.get('datasite_path')}\")\n",
    "            print(f\"   Ready: {msg.is_ready}\")\n",
    "            \n",
    "            # Check files\n",
    "            files = msg.get_files()\n",
    "            if files:\n",
    "                print(f\"   Files: {[f['filename'] for f in files]}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   Error reading: {e}\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Observer Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View recent logs\n",
    "logs = ss.servers['syft_observer'].stdout.lines()[-20:]\n",
    "\n",
    "print(\"üìã Recent observer logs:\\n\")\n",
    "for log in logs:\n",
    "    if log.strip():  # Skip empty lines\n",
    "        print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple File Changes\n",
    "\n",
    "Let's test with multiple file operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subdirectory\n",
    "project_dir = DATASITES_DIR / \"ml_project\"\n",
    "project_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create multiple files\n",
    "files_created = []\n",
    "\n",
    "# Model file\n",
    "model_file = project_dir / \"model.json\"\n",
    "model_file.write_text(json.dumps({\n",
    "    \"model_type\": \"neural_network\",\n",
    "    \"layers\": [128, 64, 32, 10],\n",
    "    \"activation\": \"relu\"\n",
    "}, indent=2))\n",
    "files_created.append(model_file)\n",
    "print(f\"üìÑ Created: {model_file.relative_to(DATASITES_DIR)}\")\n",
    "\n",
    "time.sleep(0.5)\n",
    "\n",
    "# Results file\n",
    "results_file = project_dir / \"results.txt\"\n",
    "results_file.write_text(\"Training accuracy: 95.2%\\nValidation accuracy: 93.7%\")\n",
    "files_created.append(results_file)\n",
    "print(f\"üìÑ Created: {results_file.relative_to(DATASITES_DIR)}\")\n",
    "\n",
    "time.sleep(0.5)\n",
    "\n",
    "# Config file\n",
    "config_file = project_dir / \"config.yaml\"\n",
    "config_file.write_text(\"\"\"\n",
    "training:\n",
    "  epochs: 100\n",
    "  batch_size: 32\n",
    "  learning_rate: 0.001\n",
    "\"\".strip())\n",
    "files_created.append(config_file)\n",
    "print(f\"üìÑ Created: {config_file.relative_to(DATASITES_DIR)}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Created {len(files_created)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait and check status\n",
    "time.sleep(3)\n",
    "\n",
    "status = requests.get(f\"{server.url}/status\").json()\n",
    "print(f\"üìä Total messages created: {status['messages_created']}\")\n",
    "\n",
    "# Count messages in outbox\n",
    "message_count = len([d for d in OUTBOX_DIR.iterdir() \n",
    "                    if d.is_dir() and d.name.startswith(\"gdrive_\")])\n",
    "print(f\"üì§ Messages in outbox: {message_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Files\n",
    "\n",
    "Let's test file modifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the results file\n",
    "print(\"‚úèÔ∏è  Modifying results.txt...\")\n",
    "results_file.write_text(\"\"\"\n",
    "Training accuracy: 96.8%\n",
    "Validation accuracy: 94.9%\n",
    "Test accuracy: 94.2%\n",
    "\"\".strip())\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Check logs for the modification event\n",
    "logs = ss.servers['syft_observer'].stdout.lines()[-10:]\n",
    "print(\"\\nüìã Recent logs:\")\n",
    "for log in logs:\n",
    "    if \"modified\" in log.lower() or \"results.txt\" in log:\n",
    "        print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining a SyftMessage\n",
    "\n",
    "Let's examine one of the created messages in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most recent message\n",
    "message_dirs = sorted([d for d in OUTBOX_DIR.iterdir() \n",
    "                      if d.is_dir() and d.name.startswith(\"gdrive_\")])\n",
    "\n",
    "if message_dirs:\n",
    "    latest_msg_dir = message_dirs[-1]\n",
    "    print(f\"üì© Examining: {latest_msg_dir.name}\\n\")\n",
    "    \n",
    "    # Load the message\n",
    "    msg = sc.SyftMessage(latest_msg_dir)\n",
    "    \n",
    "    # Get metadata\n",
    "    metadata = msg.get_metadata()\n",
    "    print(\"üìã Metadata:\")\n",
    "    print(f\"  Message ID: {metadata.get('message_id')}\")\n",
    "    print(f\"  Sender: {metadata.get('sender_email')}\")\n",
    "    print(f\"  Recipient: {metadata.get('recipient_email')}\")\n",
    "    print(f\"  Event Type: {metadata.get('event_type')}\")\n",
    "    print(f\"  Datasite Path: {metadata.get('datasite_path')}\")\n",
    "    \n",
    "    # Check files\n",
    "    files = msg.get_files()\n",
    "    print(f\"\\nüìÅ Files ({len(files)}):\")\n",
    "    for f in files:\n",
    "        print(f\"  - {f['filename']}\")\n",
    "        print(f\"    Size: {f['file_size']} bytes\")\n",
    "        print(f\"    Hash: {f['file_hash'][:16]}...\")\n",
    "        print(f\"    Permissions: {f['permissions']['read']}\")\n",
    "    \n",
    "    # Check if ready\n",
    "    print(f\"\\n‚úÖ Ready to send: {msg.is_ready}\")\n",
    "    \n",
    "    # Check README\n",
    "    readme_path = latest_msg_dir / \"README.html\"\n",
    "    if readme_path.exists():\n",
    "        print(f\"\\nüìÑ Has README: Yes ({readme_path.stat().st_size} bytes)\")\n",
    "else:\n",
    "    print(\"No messages found in outbox\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Clean up test files and messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the observer\n",
    "if state[\"observer\"]:\n",
    "    state[\"observer\"].stop()\n",
    "    state[\"observer\"].join()\n",
    "    print(\"üõë Observer stopped\")\n",
    "\n",
    "# Terminate the server\n",
    "ss.servers.terminate_all()\n",
    "print(\"üõë Server terminated\")\n",
    "\n",
    "# Optional: Clean up test files\n",
    "print(\"\\nüßπ Clean up test files? (y/n): \", end=\"\")\n",
    "if input().lower() == 'y':\n",
    "    import shutil\n",
    "    \n",
    "    # Remove test files\n",
    "    for f in DATASITES_DIR.rglob(\"*\"):\n",
    "        if f.is_file():\n",
    "            f.unlink()\n",
    "            print(f\"  Deleted: {f.name}\")\n",
    "    \n",
    "    # Remove test directories\n",
    "    if project_dir.exists():\n",
    "        shutil.rmtree(project_dir)\n",
    "        print(f\"  Deleted: {project_dir.name}/\")\n",
    "    \n",
    "    # Remove messages\n",
    "    count = 0\n",
    "    for msg_dir in OUTBOX_DIR.iterdir():\n",
    "        if msg_dir.is_dir() and msg_dir.name.startswith(\"gdrive_\"):\n",
    "            shutil.rmtree(msg_dir)\n",
    "            count += 1\n",
    "    print(f\"  Deleted {count} messages from outbox\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Cleanup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we've learned how to:\n",
    "\n",
    "1. **Create a file observer** using watchdog and syft-serve\n",
    "2. **Monitor datasites folder** for file changes\n",
    "3. **Automatically create SyftMessages** for file events\n",
    "4. **Store messages in outbox** ready for transport\n",
    "5. **Access observer logs** through syft-serve\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Event Types**: created, modified, deleted\n",
    "- **SyftMessage Structure**: metadata, files, permissions, README\n",
    "- **Transport Agnostic**: Messages work with any transport (GDrive, email, etc.)\n",
    "- **Automatic Workflow**: No manual intervention needed\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Integrate with transport mechanisms (Google Drive sync)\n",
    "2. Add recipient determination logic based on datasites\n",
    "3. Implement message batching for efficiency\n",
    "4. Add filtering rules for specific file types\n",
    "5. Create notification system for important changes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}