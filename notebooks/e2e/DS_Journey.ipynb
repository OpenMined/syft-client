{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data Scientist's Quest\n",
    "## A Data Scientist's Guide to Syft-Client\n",
    "\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║                    THE SYFT DANCE                                ║\n",
    "║            Data Scientist (DS) Notebook                          ║\n",
    "║                                                                  ║\n",
    "║  This notebook is Part 2 of a 2-part collaboration demo.        ║\n",
    "║  Run this alongside: DO_Journey.ipynb                           ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```\n",
    "\n",
    "### What You'll Do:\n",
    "1. **Setup** - Install, configure credentials, and authenticate\n",
    "2. **Connect** - Add Data Owner as peer\n",
    "3. **Explore** - Discover and understand available datasets\n",
    "4. **Analyze** - Write and submit analysis code\n",
    "5. **Results** - Retrieve computed results\n",
    "\n",
    "### Prerequisites:\n",
    "- Google account with Google Drive\n",
    "- OAuth credentials (`credentials.json`) from Google Cloud Console\n",
    "- A partner running the DO notebook!\n",
    "- **IMPORTANT**: Wait for DO to be ready before starting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  BEFORE YOU BEGIN                                               ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  Make sure the Data Owner (DO) has:                              ║\n",
    "║  1. Started their notebook                                       ║\n",
    "║  2. Created their dataset                                        ║\n",
    "║  3. Told you their email address                                 ║\n",
    "║                                                                  ║\n",
    "║  Ask DO: \"What's your email? Are you ready?\"                    ║\n",
    "║                                                                  ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ACT 1: Setup\n",
    "## Scene 1.1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install syft-client from the beach-hands-on-demo branch\n",
    "!pip install -q git+https://github.com/OpenMined/syft-client.git@beach-hands-on-demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft_client as sc\n",
    "print(f\"syft-client version: {sc.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 1.2: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for file storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 1.3: Setup Credentials Directory\n",
    "\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  CREDENTIALS SETUP                                              ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  You need a `credentials.json` file from Google Cloud Console:  ║\n",
    "║                                                                  ║\n",
    "║  1. Go to https://console.cloud.google.com/                     ║\n",
    "║  2. Create a project (or use existing)                          ║\n",
    "║  3. Enable APIs: Google Drive API, Gmail API                    ║\n",
    "║  4. Go to APIs & Services -> Credentials                        ║\n",
    "║  5. Create OAuth 2.0 Client ID (Desktop app type)               ║\n",
    "║  6. Download as `credentials.json`                              ║\n",
    "║                                                                  ║\n",
    "║  IMPORTANT: Add authorized redirect URI:                        ║\n",
    "║     http://localhost:1/                                         ║\n",
    "║  (Go to Credentials -> Edit your OAuth Client -> Add URI)       ║\n",
    "║                                                                  ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Credentials directory in Google Drive\n",
    "CREDS_DIR = Path(\"/content/drive/MyDrive/syft-creds\")\n",
    "CREDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Credentials directory: {CREDS_DIR}\")\n",
    "print(f\"  credentials.json: {'exists' if (CREDS_DIR / 'credentials.json').exists() else 'MISSING - Please upload!'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload credentials.json if missing\n",
    "if not (CREDS_DIR / 'credentials.json').exists():\n",
    "    print(\"Please upload your credentials.json file:\")\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if 'credentials.json' in uploaded:\n",
    "        with open(CREDS_DIR / 'credentials.json', 'wb') as f:\n",
    "            f.write(uploaded['credentials.json'])\n",
    "        print(f\"\\ncredentials.json saved to {CREDS_DIR}\")\n",
    "    else:\n",
    "        print(\"ERROR: Please upload a file named 'credentials.json'\")\n",
    "else:\n",
    "    print(\"credentials.json already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 1.4: Enter Your Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your email address (Data Scientist)\n",
    "DS_EMAIL = input(\"Enter your email address (Data Scientist): \").strip()\n",
    "print(f\"\\nYou are: {DS_EMAIL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 1.5: Configure Token Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token path for Google Drive access\n",
    "# Each user needs their own token file\n",
    "TOKEN_PATH = CREDS_DIR / \"token_ds.json\"\n",
    "\n",
    "print(f\"Token path: {TOKEN_PATH}\")\n",
    "print(f\"  Token exists: {TOKEN_PATH.exists()}\")\n",
    "if not TOKEN_PATH.exists():\n",
    "    print(\"  (Will be created during login)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 1.6: Login as Data Scientist\n",
    "\n",
    "This will prompt you to authenticate with Google if no token exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login as Data Scientist\n",
    "ds_client = sc.login_ds(\n",
    "    email=DS_EMAIL,\n",
    "    token_path=TOKEN_PATH,\n",
    ")\n",
    "\n",
    "print(f\"\\nLogged in as Data Scientist: {ds_client.email}\")\n",
    "print(f\"   SyftBox folder: {ds_client.syftbox_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ACT 2: Connect with Data Owner\n",
    "## Scene 2.1: Get DO's Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Data Owner's email\n",
    "DO_EMAIL = input(\"Enter the Data Owner's email address: \").strip()\n",
    "print(f\"\\nData Owner: {DO_EMAIL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 2.2: Add DO as Peer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add DO as peer\n",
    "ds_client.add_peer(DO_EMAIL)\n",
    "\n",
    "print(f\"\\nPeer request sent to {DO_EMAIL}!\")\n",
    "print(\"DO will receive an email notification.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify peer was added\n",
    "ds_client.peers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  INTERMISSION - WAITING FOR DATA OWNER                          ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  Your peer request has been sent!                                ║\n",
    "║                                                                  ║\n",
    "║  Tell DO: \"I've sent a peer request. Please accept it!\"         ║\n",
    "║                                                                  ║\n",
    "║  The DO needs to:                                                ║\n",
    "║  1. Run their 'Accept Peer' cell                                 ║\n",
    "║  2. Enter your email to accept                                   ║\n",
    "║                                                                  ║\n",
    "║  You'll receive an EMAIL when DO accepts your request!          ║\n",
    "║                                                                  ║\n",
    "║  Wait for DO to accept, then continue to ACT 3...               ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tell DO: 'I've sent a peer request. Please accept it!'\")\n",
    "print(\"\\nWaiting for DO to accept your peer request...\")\n",
    "print(\"   You'll receive an EMAIL when they accept!\")\n",
    "print(\"   Then continue to ACT 3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ACT 3: Explore Available Data\n",
    "## Scene 3.1: Sync with DO's Datasite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync to get latest data from DO\n",
    "ds_client.sync()\n",
    "print(\"Synced with Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 3.2: Discover Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available datasets from DO\n",
    "datasets = ds_client.datasets.get_all(datasite=DO_EMAIL)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 3.3: Explore a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first dataset\n",
    "if datasets:\n",
    "    dataset = datasets[0]\n",
    "    dataset.describe()\n",
    "else:\n",
    "    print(\"No datasets found. Make sure DO has created a dataset and accepted your peer request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View dataset URLs\n",
    "if datasets:\n",
    "    print(f\"Dataset: {dataset.name}\")\n",
    "    print(f\"   Mock URL: {dataset.mock_url}\")\n",
    "    print(f\"   Private URL: {dataset.private_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 3.4: Preview Mock Data\n",
    "\n",
    "The mock data shows the structure without revealing private information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Read the mock data to understand the structure\n",
    "if datasets and dataset.mock_files:\n",
    "    mock_file = dataset.mock_files[0]  # First mock file\n",
    "    print(f\"Reading mock data from: {mock_file}\")\n",
    "    \n",
    "    df_mock = pd.read_csv(mock_file)\n",
    "    print(f\"\\nMock Data Preview ({len(df_mock)} rows):\")\n",
    "    print(df_mock.head(10))\n",
    "    print(f\"\\nColumns: {list(df_mock.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ACT 4: Submit Analysis Job\n",
    "## Scene 4.1: Construct Private Data Path\n",
    "\n",
    "Use `syft://private/...` URLs to reference the DO's private data.\n",
    "The `sc.resolve_path()` function converts these to actual file paths when running on DO's machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the private data URL\n",
    "if datasets:\n",
    "    private_url = str(dataset.private_url)\n",
    "    \n",
    "    # Get filename from mock files\n",
    "    if dataset.mock_files_urls:\n",
    "        mock_filename = Path(str(dataset.mock_files_urls[0])).name\n",
    "        # Private files typically have same name or without 'mock' prefix\n",
    "        private_filename = mock_filename.replace(\"_mock\", \"\").replace(\"mock_\", \"\")\n",
    "        PRIVATE_DATA_PATH = f\"{private_url}/{private_filename}\"\n",
    "    else:\n",
    "        PRIVATE_DATA_PATH = f\"{private_url}/sales_private.csv\"\n",
    "        \n",
    "    print(f\"Private data path to use in code:\")\n",
    "    print(f\"   {PRIVATE_DATA_PATH}\")\n",
    "else:\n",
    "    PRIVATE_DATA_PATH = f\"syft://private/syft_datasets/sales-data/sales_private.csv\"\n",
    "    print(f\"Using default private data path:\")\n",
    "    print(f\"   {PRIVATE_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 4.2: Write Analysis Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write analysis code to a file\n",
    "# This code will run on DO's machine with access to their private data\n",
    "\n",
    "analysis_code = f'''\n",
    "import os\n",
    "import json\n",
    "import syft_client as sc\n",
    "import pandas as pd\n",
    "\n",
    "# Access the private data using Syft URL\n",
    "data_path = \"{PRIVATE_DATA_PATH}\"\n",
    "resolved_path = sc.resolve_path(data_path)\n",
    "\n",
    "print(f\"Reading private data from: {{resolved_path}}\")\n",
    "\n",
    "# Load and analyze the data\n",
    "df = pd.read_csv(resolved_path)\n",
    "\n",
    "print(f\"\\\\nDataset shape: {{df.shape}}\")\n",
    "print(f\"Columns: {{list(df.columns)}}\")\n",
    "\n",
    "# Compute aggregate statistics\n",
    "results = {{\n",
    "    \"total_rows\": len(df),\n",
    "    \"columns\": list(df.columns),\n",
    "}}\n",
    "\n",
    "# Compute stats for numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    results[f\"{{col}}_sum\"] = float(df[col].sum())\n",
    "    results[f\"{{col}}_mean\"] = float(df[col].mean())\n",
    "\n",
    "# Calculate total revenue if applicable\n",
    "if \"quantity\" in df.columns and \"price_per_unit\" in df.columns:\n",
    "    total_revenue = (df[\"quantity\"] * df[\"price_per_unit\"]).sum()\n",
    "    results[\"total_revenue\"] = float(total_revenue)\n",
    "    print(f\"\\\\nTotal Revenue: ${{total_revenue:,.2f}}\")\n",
    "\n",
    "print(f\"\\\\nResults:\")\n",
    "print(json.dumps(results, indent=2))\n",
    "\n",
    "# Save results\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "with open(\"outputs/analysis_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\\\nResults saved to outputs/analysis_results.json\")\n",
    "'''\n",
    "\n",
    "# Save to file\n",
    "CODE_PATH = Path(\"/tmp/sales_analysis.py\")\n",
    "CODE_PATH.write_text(analysis_code)\n",
    "\n",
    "print(\"Analysis code written to:\", CODE_PATH)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CODE PREVIEW:\")\n",
    "print(\"=\"*60)\n",
    "print(analysis_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 4.3: Submit the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique job name\n",
    "JOB_NAME = f\"sales-analysis-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Submit the job to DO\n",
    "ds_client.submit_python_job(\n",
    "    user=DO_EMAIL,\n",
    "    code_path=str(CODE_PATH),\n",
    "    job_name=JOB_NAME,\n",
    ")\n",
    "\n",
    "print(f\"\\nJob '{JOB_NAME}' submitted to {DO_EMAIL}!\")\n",
    "print(\"DO will receive an email notification.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View your submitted jobs\n",
    "ds_client.jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  INTERMISSION - WAITING FOR JOB APPROVAL & EXECUTION            ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  Your job has been submitted!                                    ║\n",
    "║                                                                  ║\n",
    "║  Tell DO: \"I've submitted a job. Please review and run it!\"     ║\n",
    "║                                                                  ║\n",
    "║  The DO needs to:                                                ║\n",
    "║  1. Review your code                                             ║\n",
    "║  2. Approve the job                                              ║\n",
    "║  3. Execute the job                                              ║\n",
    "║                                                                  ║\n",
    "║  You'll receive EMAIL notifications for:                        ║\n",
    "║  - Job approved                                                  ║\n",
    "║  - Job completed                                                 ║\n",
    "║                                                                  ║\n",
    "║  Wait for DO to execute, then continue to ACT 5...              ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tell DO: 'I've submitted a job. Please review and run it!'\")\n",
    "print(\"\\nWaiting for DO to approve and execute your job...\")\n",
    "print(\"   You'll receive EMAIL notifications!\")\n",
    "print(\"   Then continue to ACT 5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ACT 5: Retrieve Results\n",
    "## Scene 5.1: Sync to Get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync to get the latest job status and results\n",
    "ds_client.sync()\n",
    "print(\"Synced with Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 5.2: Check Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all jobs\n",
    "ds_client.jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 5.3: View Job Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the completed job\n",
    "done_jobs = [j for j in ds_client.jobs if j.status == \"done\"]\n",
    "\n",
    "if done_jobs:\n",
    "    job = done_jobs[-1]  # Most recent completed job\n",
    "    print(f\"Job: {job.name}\")\n",
    "    print(f\"   Status: {job.status}\")\n",
    "    print(f\"\\nSTDOUT:\")\n",
    "    print(job.stdout)\n",
    "else:\n",
    "    print(\"No completed jobs yet. Wait for DO to execute your job.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 5.4: Access Result Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if done_jobs:\n",
    "    job = done_jobs[-1]\n",
    "    print(f\"Output files: {job.output_paths}\")\n",
    "    \n",
    "    # Read the results file\n",
    "    for output_path in job.output_paths:\n",
    "        if str(output_path).endswith(\".json\"):\n",
    "            print(f\"\\nReading results from: {output_path}\")\n",
    "            with open(output_path, \"r\") as f:\n",
    "                results = json.load(f)\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"ANALYSIS RESULTS:\")\n",
    "            print(\"=\"*60)\n",
    "            print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ACT 6: Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  CONGRATULATIONS! THE QUEST IS COMPLETE!                        ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  As a Data Scientist, you successfully:                          ║\n",
    "║                                                                  ║\n",
    "║  - Set up credentials and authenticated                         ║\n",
    "║  - Connected with a Data Owner                                  ║\n",
    "║  - Discovered and explored available datasets                   ║\n",
    "║  - Understood data structure using mock data                    ║\n",
    "║  - Wrote analysis code using Syft URLs                          ║\n",
    "║  - Submitted a job for remote execution                         ║\n",
    "║  - Received email notifications for job status                  ║\n",
    "║  - Retrieved computed results                                   ║\n",
    "║                                                                  ║\n",
    "║  You NEVER had direct access to the private data!               ║\n",
    "║  Your code ran on DO's machine, and only results were returned. ║\n",
    "║                                                                  ║\n",
    "║  This is privacy-preserving data science in action!             ║\n",
    "║                                                                  ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Appendix: Additional Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all your peers\n",
    "# ds_client.peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List datasets from ALL peers\n",
    "# ds_client.datasets.get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View job history\n",
    "# for job in ds_client.jobs:\n",
    "#     print(f\"{job.status}: {job.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
