{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data Guardian's Journey\n",
    "## A Data Owner's Guide to Syft-Client\n",
    "\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║                    THE SYFT DANCE                                ║\n",
    "║              Data Owner (DO) Notebook                            ║\n",
    "║                                                                  ║\n",
    "║  This notebook is Part 1 of a 2-part collaboration demo.        ║\n",
    "║  Run this alongside: DS_Journey.ipynb                           ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```\n",
    "\n",
    "### What You'll Do:\n",
    "1. **Setup** - Install, configure credentials, and authenticate\n",
    "2. **Monitor** - Start notification daemon for real-time alerts\n",
    "3. **Create Dataset** - Prepare data with mock + private versions\n",
    "4. **Accept Peer** - Welcome the Data Scientist\n",
    "5. **Review & Execute Jobs** - Process analysis requests\n",
    "\n",
    "### Prerequisites:\n",
    "- Google account with Google Drive\n",
    "- OAuth credentials (`credentials.json`) from Google Cloud Console\n",
    "- A partner running the DS notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ACT 1: Setup\n",
    "## Scene 1.1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install syft-client { display-mode: \"form\" }\n",
    "!pip install -q git+https://github.com/OpenMined/syft-client.git@beach-hands-on-demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import syft-client { display-mode: \"form\" }\n",
    "# Suppress noisy Google httplib2 warnings\n",
    "import logging\n",
    "logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.ERROR)\n",
    "logging.getLogger('google_auth_httplib2').setLevel(logging.ERROR)\n",
    "\n",
    "import syft_client as sc\n",
    "print(f\"syft-client version: {sc.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 1.2: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Mount Google Drive { display-mode: \"form\" }\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 1.3: Setup Credentials Directory\n",
    "\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  CREDENTIALS SETUP                                              ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  You need a `credentials.json` file from Google Cloud Console:  ║\n",
    "║                                                                  ║\n",
    "║  1. Go to https://console.cloud.google.com/                     ║\n",
    "║  2. Create a project (or use existing)                          ║\n",
    "║  3. Enable APIs: Google Drive API, Gmail API                    ║\n",
    "║  4. Go to APIs & Services -> Credentials                        ║\n",
    "║  5. Create OAuth 2.0 Client ID (Desktop app type)               ║\n",
    "║  6. Download as `credentials.json`                              ║\n",
    "║                                                                  ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup credentials directory { display-mode: \"form\" }\n",
    "from pathlib import Path\n",
    "\n",
    "# Credentials directory in Google Drive\n",
    "CREDS_DIR = Path(\"/content/drive/MyDrive/syft-creds\")\n",
    "CREDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Credentials directory: {CREDS_DIR}\")\n",
    "print(f\"  credentials.json: {'✅ exists' if (CREDS_DIR / 'credentials.json').exists() else '❌ MISSING - Please upload!'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Upload credentials.json if missing { display-mode: \"form\" }\n",
    "if not (CREDS_DIR / 'credentials.json').exists():\n",
    "    print(\"Please upload your credentials.json file:\")\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if 'credentials.json' in uploaded:\n",
    "        with open(CREDS_DIR / 'credentials.json', 'wb') as f:\n",
    "            f.write(uploaded['credentials.json'])\n",
    "        print(f\"\\n✅ credentials.json saved to {CREDS_DIR}\")\n",
    "    else:\n",
    "        print(\"❌ ERROR: Please upload a file named 'credentials.json'\")\n",
    "else:\n",
    "    print(\"✅ credentials.json already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 1.4: Enter Your Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your email address (Data Owner)\n",
    "DO_EMAIL = input(\"Enter your email address (Data Owner): \").strip()\n",
    "print(f\"\\nYou are: {DO_EMAIL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 1.5: Configure Token Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Configure token path { display-mode: \"form\" }\n",
    "TOKEN_PATH = CREDS_DIR / \"token_do.json\"\n",
    "\n",
    "print(f\"Token path: {TOKEN_PATH}\")\n",
    "print(f\"  Token exists: {'✅' if TOKEN_PATH.exists() else '⏳ (Will be created during login)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 1.6: Login as Data Owner\n",
    "\n",
    "This will prompt you to authenticate with Google if no token exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login as Data Owner\n",
    "do_client = sc.login_do(\n",
    "    email=DO_EMAIL,\n",
    "    token_path=TOKEN_PATH,\n",
    ")\n",
    "\n",
    "print(f\"\\nLogged in as Data Owner: {do_client.email}\")\n",
    "print(f\"   SyftBox folder: {do_client.syftbox_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 1.7: Create Drive Token for Notifications (Colab Only)\n",
    "\n",
    "In Colab, `sc.login_do()` uses Colab's built-in auth which doesn't create a token file.\n",
    "For peer notifications to work, we need to create a Drive token separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Create Drive token for notifications { display-mode: \"form\" }\n",
    "# Skip if token already exists\n",
    "\n",
    "if not TOKEN_PATH.exists():\n",
    "    print(\"Creating Drive token for peer notifications...\")\n",
    "    print(\"Follow the same OAuth flow as before.\\n\")\n",
    "    \n",
    "    from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "    import re\n",
    "    from urllib.parse import unquote\n",
    "    \n",
    "    DRIVE_SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    flow = InstalledAppFlow.from_client_secrets_file(\n",
    "        str(CREDS_DIR / 'credentials.json'), \n",
    "        DRIVE_SCOPES\n",
    "    )\n",
    "    flow.redirect_uri = \"http://localhost:1/\"\n",
    "    auth_url, _ = flow.authorization_url(prompt=\"consent\", access_type=\"offline\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Drive OAuth Authorization Required\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n1. Click this link:\\n\")\n",
    "    print(f\"   {auth_url}\\n\")\n",
    "    print(\"2. Sign in and grant Drive access\")\n",
    "    print(\"3. Copy the 'code' from the URL (page won't load - that's OK)\")\n",
    "    print(\"   Copy the part after 'code=' and before '&scope'\\n\")\n",
    "    \n",
    "    code = input(\"Enter authorization code: \").strip()\n",
    "    \n",
    "    # Extract code if full URL pasted\n",
    "    if \"code=\" in code:\n",
    "        match = re.search(r'code=([^&]+)', code)\n",
    "        if match:\n",
    "            code = match.group(1)\n",
    "    code = unquote(code)\n",
    "    \n",
    "    flow.fetch_token(code=code)\n",
    "    TOKEN_PATH.write_text(flow.credentials.to_json())\n",
    "    print(f\"\\n✅ Drive token saved to {TOKEN_PATH}\")\n",
    "else:\n",
    "    print(f\"✅ Drive token already exists: {TOKEN_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ACT 2: Start Notification Monitor\n",
    "\n",
    "The notification monitor watches for:\n",
    "- New peer requests\n",
    "- New job submissions\n",
    "- Job status changes\n",
    "\n",
    "And sends email notifications automatically!\n",
    "\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  TWO OPTIONS FOR NOTIFICATIONS                                  ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  Option A: In-Notebook Monitor (below)                          ║\n",
    "║     - Runs in background while notebook is active               ║\n",
    "║     - Uses NotificationMonitor.from_client()                    ║\n",
    "║                                                                  ║\n",
    "║  Option B: Daemon Mode (in Colab Terminal)                      ║\n",
    "║     - Runs independently in terminal                            ║\n",
    "║     - Create config file and run: syft-notify                   ║\n",
    "║     - See Appendix for daemon setup instructions                ║\n",
    "║                                                                  ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 2.1: Setup Gmail for Notifications (One-time)\n",
    "\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  GMAIL OAUTH FLOW (Manual for Colab)                            ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  When you run NotificationMonitor.setup(), you will:            ║\n",
    "║                                                                  ║\n",
    "║  1. See a URL printed - CLICK IT                                ║\n",
    "║  2. Sign in with your Google account                            ║\n",
    "║  3. Grant Gmail send permission                                 ║\n",
    "║  4. You'll be redirected to a page that WON'T LOAD (normal!)    ║\n",
    "║  5. Copy the 'code' from the URL bar:                           ║\n",
    "║       http://localhost:1/?code=4/0XXXXX...&scope=...            ║\n",
    "║     Copy the part after 'code=' and before '&scope'             ║\n",
    "║  6. Paste it back in the input box                              ║\n",
    "║                                                                  ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft_client.notifications import NotificationMonitor\n",
    "\n",
    "# Check credentials status\n",
    "creds_dir = NotificationMonitor.get_creds_dir()\n",
    "print(f\"Credentials directory: {creds_dir}\")\n",
    "print(f\"  credentials.json: {'exists' if (creds_dir / 'credentials.json').exists() else 'MISSING'}\")\n",
    "print(f\"  gmail_token.json: {'exists' if (creds_dir / 'gmail_token.json').exists() else 'MISSING (will be created)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Gmail setup - Follow the instructions printed!\n",
    "# You'll need to click a link, authorize, and paste back the code\n",
    "NotificationMonitor.setup()\n",
    "print(\"\\nGmail notification setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 2.2: Start the Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start notification monitor (runs in background)\n",
    "monitor = NotificationMonitor.from_client(do_client)\n",
    "monitor.start()  # Start all (jobs + peers)\n",
    "\n",
    "print(\"Notification monitor started!\")\n",
    "print(\"  - Watching for new peer requests\")\n",
    "print(\"  - Watching for new job submissions\")\n",
    "print(\"  - Will send email notifications automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ACT 3: Create Your Dataset\n",
    "## Scene 3.1: Download Sample Data\n",
    "\n",
    "We'll use a sample sales dataset. In real scenarios, you'd use your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Sample dataset URLs\n",
    "MOCK_URL = \"https://raw.githubusercontent.com/OpenMined/datasets/refs/heads/main/beach/sales-dataset/mock/sales.csv\"\n",
    "PRIVATE_URL = \"https://raw.githubusercontent.com/OpenMined/datasets/refs/heads/main/beach/sales-dataset/private/sales.csv\"\n",
    "\n",
    "# Download to temporary locations\n",
    "DATA_DIR = Path(\"/tmp/dataset\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mock_path = DATA_DIR / \"sales_mock.csv\"\n",
    "private_path = DATA_DIR / \"sales_private.csv\"\n",
    "readme_path = DATA_DIR / \"readme.md\"\n",
    "\n",
    "# Download mock data\n",
    "r = requests.get(MOCK_URL)\n",
    "mock_path.write_bytes(r.content)\n",
    "\n",
    "# Download private data  \n",
    "r = requests.get(PRIVATE_URL)\n",
    "private_path.write_bytes(r.content)\n",
    "\n",
    "# Create readme\n",
    "readme_path.write_text(\"\"\"# Sales Dataset\n",
    "\n",
    "This dataset contains sales transaction records.\n",
    "\n",
    "## Columns\n",
    "- `product_id`: Unique product identifier\n",
    "- `quantity`: Number of units sold\n",
    "- `price_per_unit`: Price per unit in USD\n",
    "- `date`: Transaction date\n",
    "\n",
    "## Mock vs Private\n",
    "- **Mock data**: Synthetic data with similar structure (safe to share)\n",
    "- **Private data**: Real transaction data (protected)\n",
    "\"\"\")\n",
    "\n",
    "print(\"Sample data downloaded:\")\n",
    "print(f\"   Mock: {mock_path}\")\n",
    "print(f\"   Private: {private_path}\")\n",
    "print(f\"   Readme: {readme_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Mock Data Preview (this is what DS will see):\")\n",
    "print(pd.read_csv(mock_path).head())\n",
    "\n",
    "print(\"\\nPrivate Data Preview (this stays with you):\")\n",
    "print(pd.read_csv(private_path).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 3.2: Create the Dataset\n",
    "\n",
    "This registers your dataset with Syft, making the mock data discoverable by peers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "import shutil\n",
    "\n",
    "DATASET_NAME = \"sales-data\"\n",
    "\n",
    "# Clean up existing dataset paths first (important for re-runs)\n",
    "public_dataset_path = do_client.syftbox_folder / do_client.email / \"public\" / \"syft_datasets\" / DATASET_NAME\n",
    "private_dataset_path = do_client.syftbox_folder / \"private\" / \"syft_datasets\" / DATASET_NAME\n",
    "\n",
    "for path in [public_dataset_path, private_dataset_path]:\n",
    "    if path.exists():\n",
    "        print(f\"Cleaning up existing dataset: {path}\")\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "do_client.create_dataset(\n",
    "    name=DATASET_NAME,\n",
    "    mock_path=str(mock_path),\n",
    "    private_path=str(private_path),\n",
    "    summary=\"Sales transaction records for analysis\",\n",
    "    readme_path=str(readme_path),\n",
    "    tags=[\"sales\", \"transactions\", \"demo\"],\n",
    ")\n",
    "\n",
    "print(f\"Dataset '{DATASET_NAME}' created!\")\n",
    "\n",
    "# Verify the dataset exists locally\n",
    "dataset_path = do_client.syftbox_folder / do_client.email / \"public\" / \"syft_datasets\" / DATASET_NAME\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "print(f\"Exists: {dataset_path.exists()}\")\n",
    "if dataset_path.exists():\n",
    "    print(f\"Contents: {list(dataset_path.iterdir())}\")\n",
    "\n",
    "# Sync to Drive\n",
    "do_client.sync()\n",
    "print(\"Synced to Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View your datasets\n",
    "do_client.datasets.get_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  INTERMISSION - WAITING FOR DATA SCIENTIST                      ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  Your stage is set! Now tell your DS partner:                   ║\n",
    "║                                                                  ║\n",
    "║  \"I'm ready! My email is: {DO_EMAIL}\"                           ║\n",
    "║                                                                  ║\n",
    "║  The DS should now:                                              ║\n",
    "║  1. Run their notebook up to 'Add Peer'                         ║\n",
    "║  2. Add you as a peer                                           ║\n",
    "║                                                                  ║\n",
    "║  You'll receive an EMAIL notification when DS adds you!         ║\n",
    "║                                                                  ║\n",
    "║  Wait for DS to add you, then continue to ACT 4...              ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTell your DS partner: 'I'm ready! Add me as peer: {DO_EMAIL}'\")\n",
    "print(\"\\nWaiting for DS to add you as peer...\")\n",
    "print(\"   You'll receive an EMAIL when they do!\")\n",
    "print(\"   Then continue to ACT 4.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ACT 4: Accept the Peer Request\n",
    "## Scene 4.1: Check for New Peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync and check peers\n",
    "do_client.sync()\n",
    "do_client.peers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 4.2: Accept the Peer\n",
    "\n",
    "Enter the DS's email to accept their peer request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DS email\n",
    "DS_EMAIL = input(\"Enter the Data Scientist's email to accept: \").strip()\n",
    "print(f\"\\nAccepting peer request from: {DS_EMAIL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add DS as peer (accept the request)\n",
    "do_client.add_peer(DS_EMAIL)\n",
    "\n",
    "print(f\"\\nPeer request from {DS_EMAIL} accepted!\")\n",
    "\n",
    "# Notify DS that their request was accepted\n",
    "monitor.notify_peer_granted(DS_EMAIL)\n",
    "print(f\"Notification sent to {DS_EMAIL}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify peers\n",
    "do_client.peers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  INTERMISSION - WAITING FOR JOB SUBMISSION                      ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  The DS can now:                                                 ║\n",
    "║  1. Explore your datasets                                        ║\n",
    "║  2. Write analysis code                                          ║\n",
    "║  3. Submit a job                                                 ║\n",
    "║                                                                  ║\n",
    "║  Tell DS: \"Peer accepted! You can explore my data now.\"         ║\n",
    "║                                                                  ║\n",
    "║  You'll receive an EMAIL notification when DS submits a job!    ║\n",
    "║                                                                  ║\n",
    "║  Wait for DS to submit a job, then continue to ACT 5...         ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tell DS: 'Peer accepted! You can explore my data and submit jobs now.'\")\n",
    "print(\"\\nWaiting for DS to submit a job...\")\n",
    "print(\"   You'll receive an EMAIL when they do!\")\n",
    "print(\"   Then continue to ACT 5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ACT 5: Review and Execute Jobs\n",
    "## Scene 5.1: View Incoming Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync to get latest jobs\n",
    "do_client.sync()\n",
    "\n",
    "# View all jobs\n",
    "do_client.jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 5.2: Review a Job\n",
    "\n",
    "Before approving, review what the code does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first pending job\n",
    "pending_jobs = [j for j in do_client.jobs if j.status == \"inbox\"]\n",
    "\n",
    "if not pending_jobs:\n",
    "    print(\"No pending jobs. Wait for DS to submit one.\")\n",
    "else:\n",
    "    job = pending_jobs[0]\n",
    "    print(f\"Job: {job.name}\")\n",
    "    print(f\"   From: {job.submitted_by}\")\n",
    "    print(f\"   Status: {job.status}\")\n",
    "    print(f\"   Location: {job.location}\")\n",
    "    \n",
    "    # Show the submitted code\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUBMITTED CODE:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Read the Python file (the actual code DS wrote)\n",
    "    for f in job.location.iterdir():\n",
    "        if f.suffix == \".py\":\n",
    "            print(f\"\\n--- {f.name} ---\")\n",
    "            print(f.read_text())\n",
    "    \n",
    "    # Also show run.sh (the wrapper script)\n",
    "    run_script = job.location / \"run.sh\"\n",
    "    if run_script.exists():\n",
    "        print(f\"\\n--- run.sh ---\")\n",
    "        print(run_script.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 5.3: Approve the Job\n",
    "\n",
    "If the code looks safe, approve it for execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approve the job\n",
    "if pending_jobs:\n",
    "    job = pending_jobs[0]\n",
    "    job.approve()\n",
    "    print(f\"\\nJob '{job.name}' approved!\")\n",
    "    print(\"DS will receive an email notification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene 5.4: Execute the Job\n",
    "\n",
    "Run the approved job on your private data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute all approved jobs\n",
    "do_client.process_approved_jobs()\n",
    "\n",
    "print(\"\\nJob execution complete!\")\n",
    "print(\"   Results have been synced to Google Drive.\")\n",
    "print(\"   DS will receive an email notification.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View updated job status\n",
    "do_client.jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the executed job's output\n",
    "done_jobs = [j for j in do_client.jobs if j.status == \"done\"]\n",
    "if done_jobs:\n",
    "    job = done_jobs[-1]\n",
    "    print(f\"Job '{job.name}' output:\")\n",
    "    print(job.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ACT 6: Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the notification monitor\n",
    "monitor.stop()\n",
    "print(\"Notification monitor stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  CONGRATULATIONS! THE DANCE IS COMPLETE!                        ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  As a Data Owner, you successfully:                              ║\n",
    "║                                                                  ║\n",
    "║  - Set up credentials and notification monitoring               ║\n",
    "║  - Created a dataset with mock + private data                   ║\n",
    "║  - Received email notification of peer request                  ║\n",
    "║  - Accepted a peer request from a Data Scientist                ║\n",
    "║  - Received email notification of job submission                ║\n",
    "║  - Reviewed and approved a job submission                       ║\n",
    "║  - Executed the job on your private data                        ║\n",
    "║  - Shared results back to the Data Scientist                    ║\n",
    "║                                                                  ║\n",
    "║  Your private data NEVER left your control!                     ║\n",
    "║  Only the computed results were shared.                         ║\n",
    "║                                                                  ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Appendix A: View Notification State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View notification state (what was sent)\n",
    "import json\n",
    "state_path = NotificationMonitor.get_creds_dir() / \"notification_state.json\"\n",
    "\n",
    "if state_path.exists():\n",
    "    with open(state_path) as f:\n",
    "        state_data = json.load(f)\n",
    "    print(\"Notifications sent:\")\n",
    "    print(json.dumps(state_data, indent=2))\n",
    "else:\n",
    "    print(\"No notification state file found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Appendix B: Daemon Mode (Alternative to In-Notebook Monitor)\n",
    "\n",
    "Instead of running the monitor in the notebook, you can run it as a daemon in Colab's terminal.\n",
    "\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  DAEMON MODE SETUP                                              ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  1. Open Colab Terminal (click terminal icon)                   ║\n",
    "║                                                                  ║\n",
    "║  2. Create daemon config:                                        ║\n",
    "║                                                                  ║\n",
    "║     cat > /content/drive/MyDrive/syft-creds/daemon.yaml << EOF  ║\n",
    "║     do_email: \"your-email@example.com\"                          ║\n",
    "║     syftbox_root: \"/content/SyftBox_your-email@example.com\"     ║\n",
    "║     drive_token_path: \"/content/drive/MyDrive/syft-creds/token_do.json\"  ║\n",
    "║     gmail_token_path: \"/content/drive/MyDrive/syft-creds/gmail_token.json\" ║\n",
    "║     EOF                                                          ║\n",
    "║                                                                  ║\n",
    "║  3. Run the daemon:                                              ║\n",
    "║     syft-notify --config /content/drive/MyDrive/syft-creds/daemon.yaml  ║\n",
    "║                                                                  ║\n",
    "║  4. The daemon will run in the terminal, monitoring for events  ║\n",
    "║     and sending email notifications automatically.              ║\n",
    "║                                                                  ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Generate daemon config for your email\n",
    "daemon_config = f\"\"\"\n",
    "# Daemon config for {DO_EMAIL}\n",
    "# Save this to: /content/drive/MyDrive/syft-creds/daemon.yaml\n",
    "\n",
    "do_email: \"{DO_EMAIL}\"\n",
    "syftbox_root: \"/content/SyftBox_{DO_EMAIL}\"\n",
    "drive_token_path: \"/content/drive/MyDrive/syft-creds/token_do.json\"\n",
    "gmail_token_path: \"/content/drive/MyDrive/syft-creds/gmail_token.json\"\n",
    "\"\"\"\n",
    "print(daemon_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Appendix C: Additional Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approve all pending jobs\n",
    "# for job in do_client.jobs:\n",
    "#     if job.status == \"inbox\":\n",
    "#         job.approve()\n",
    "#         print(f\"Approved: {job.name}\")\n",
    "\n",
    "# Execute all approved jobs\n",
    "# do_client.process_approved_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a dataset\n",
    "# do_client.delete_dataset(name=\"sales-data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
