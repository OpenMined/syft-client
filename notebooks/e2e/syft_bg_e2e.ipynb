{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup (Colab or local)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "print(f\"Environment: {'Colab' if IN_COLAB else 'Local'}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    CREDS_DIR = Path(\"/content/drive/MyDrive/syft-creds\")\n",
    "    \n",
    "    # Install packages\n",
    "    !pip install -q syft-client syft-bg syft-approve syft-notify syft-job syft-datasets\n",
    "else:\n",
    "    CREDS_DIR = Path.home() / \".syft-creds\"\n",
    "\n",
    "print(f\"Credentials dir: {CREDS_DIR}\")\n",
    "print(f\"Config exists: {(CREDS_DIR / 'config.yaml').exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import syft_client as sc\n",
    "import subprocess, json, uuid, shutil, time, os\n",
    "\n",
    "email_do = \"test1@openmined.org\"\n",
    "email_ds = \"test2@openmined.org\"\n",
    "\n",
    "token_do = CREDS_DIR / \"token_do.json\"\n",
    "token_ds = CREDS_DIR / \"token_ds.json\"\n",
    "\n",
    "# Convert DS token if needed (handles nested format)\n",
    "ds_nested_paths = [\n",
    "    Path.home() / \".syft/test2_at_openmined_org/tokens/google_org.json\",\n",
    "    CREDS_DIR / \"test2_token_nested.json\",\n",
    "]\n",
    "for ds_nested in ds_nested_paths:\n",
    "    if ds_nested.exists() and not token_ds.exists():\n",
    "        with open(ds_nested) as f:\n",
    "            data = json.load(f)\n",
    "        with open(token_ds, \"w\") as f:\n",
    "            json.dump(data.get(\"token_data\", data), f)\n",
    "        break\n",
    "\n",
    "print(f\"DO token: {token_do.exists()}\")\n",
    "print(f\"DS token: {token_ds.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start daemons\n",
    "subprocess.run([\"syft-bg\", \"stop\"], capture_output=True)  # Clean start\n",
    "time.sleep(1)\n",
    "subprocess.run([\"syft-bg\", \"start\"], capture_output=True)\n",
    "time.sleep(3)\n",
    "!syft-bg status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login\n",
    "client_do = sc.login_do(email=email_do, token_path=token_do)\n",
    "client_ds = sc.login_ds(email=email_ds, token_path=token_ds)\n",
    "print(f\"DO: {client_do.email}\")\n",
    "print(f\"DS: {client_ds.email}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS adds DO as peer\n",
    "client_ds.load_peers()\n",
    "if email_do not in [p.email for p in client_ds.version_manager.approved_peers]:\n",
    "    client_ds.add_peer(email_do)\n",
    "    print(f\"Peer request sent to {email_do}\")\n",
    "else:\n",
    "    print(\"Already peers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for peer auto-approval\n",
    "for i in range(12):\n",
    "    try:\n",
    "        client_do.load_peers()\n",
    "        client_ds.load_peers()\n",
    "        do_peers = [p.email for p in client_do.version_manager.approved_peers]\n",
    "        ds_peers = [p.email for p in client_ds.version_manager.approved_peers]\n",
    "        if email_ds in do_peers and email_do in ds_peers:\n",
    "            print(f\"Peers connected: {do_peers}\")\n",
    "            break\n",
    "        print(f\"Waiting... pending: {[p.email for p in client_do.version_manager.pending_peers]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Waiting... {type(e).__name__}\")\n",
    "    time.sleep(5)\n",
    "else:\n",
    "    print(\"Timeout - check: syft-bg logs approve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"id\": \"c1\", \"role\": \"user\", \"text\": \"how do I protect my identity online?\"},\n",
    "    {\"id\": \"c2\", \"role\": \"user\", \"text\": \"what are the best privacy tools?\"},\n",
    "    {\"id\": \"c3\", \"role\": \"user\", \"text\": \"how to secure personal information?\"},\n",
    "    {\"id\": \"c4\", \"role\": \"user\", \"text\": \"what is the weather today?\"},\n",
    "])\n",
    "\n",
    "tmp = Path(\"/tmp\" if not IN_COLAB else \"/content\")\n",
    "mock_path, private_path = tmp / \"mock.csv\", tmp / \"private.csv\"\n",
    "df.head(2).to_csv(mock_path, index=False)\n",
    "df.to_csv(private_path, index=False)\n",
    "\n",
    "dataset_name = \"TestData\"\n",
    "for p in [client_do.syftbox_folder/client_do.email/\"public\"/\"syft_datasets\"/dataset_name,\n",
    "          client_do.syftbox_folder/\"private\"/\"syft_datasets\"/dataset_name]:\n",
    "    if p.exists(): shutil.rmtree(p)\n",
    "\n",
    "client_do.create_dataset(name=dataset_name, mock_path=str(mock_path), private_path=str(private_path),\n",
    "                         summary=\"Test\", tags=[\"test\"])\n",
    "client_do.sync()\n",
    "print(f\"Dataset: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create job\n",
    "tmp = Path(\"/tmp\" if not IN_COLAB else \"/content\")\n",
    "job_dir = tmp / \"test_job\"\n",
    "if job_dir.exists(): shutil.rmtree(job_dir)\n",
    "job_dir.mkdir()\n",
    "\n",
    "(job_dir / \"params.json\").write_text(json.dumps({\n",
    "    \"SIMILARITY_PROMPT\": \"protect identity\",\n",
    "    \"SIMILARITY_THRESHOLD\": 0.1\n",
    "}))\n",
    "\n",
    "(job_dir / \"main.py\").write_text('''import json, os, pandas as pd, syft_client as sc\n",
    "with open(\"params.json\") as f: params = json.load(f)\n",
    "df = pd.read_csv(sc.resolve_dataset_file_path(\"TestData\"))\n",
    "def sim(a, b): w1, w2 = set(a.lower().split()), set(b.lower().split()); return len(w1&w2)/len(w1|w2) if w1|w2 else 0\n",
    "df[\"score\"] = df[\"text\"].apply(lambda x: sim(x, params[\"SIMILARITY_PROMPT\"]))\n",
    "results = df[df[\"score\"] >= params[\"SIMILARITY_THRESHOLD\"]][[\"id\",\"text\",\"score\"]].to_dict(\"records\")\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "with open(\"outputs/results.json\", \"w\") as f: json.dump(results, f)\n",
    "print(f\"Matches: {len(results)}\")\n",
    "''')\n",
    "\n",
    "print(f\"Job: {list(job_dir.iterdir())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job\n",
    "job_name = f\"job_{uuid.uuid4().hex[:6]}\"\n",
    "client_ds.submit_python_job(user=email_do, code_path=str(job_dir), job_name=job_name, dependencies=[\"pandas\"])\n",
    "print(f\"Submitted: {job_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for auto-approval\n",
    "for i in range(6):\n",
    "    client_do.sync()\n",
    "    jobs = [j for j in client_do.job_client.jobs if j.name == job_name]\n",
    "    if jobs and jobs[0].status == \"approved\":\n",
    "        print(\"Approved\")\n",
    "        break\n",
    "    print(f\"Waiting... {jobs[0].status if jobs else 'pending'}\")\n",
    "    time.sleep(5)\n",
    "else:\n",
    "    print(\"Timeout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute\n",
    "client_do.job_runner.process_approved_jobs()\n",
    "client_do.sync()\n",
    "job = [j for j in client_do.job_client.jobs if j.name == job_name][0]\n",
    "print(f\"Status: {job.status}\")\n",
    "if job.stdout: print(job.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS results\n",
    "client_ds.sync()\n",
    "ds_job = [j for j in client_ds.job_client.jobs if j.name == job_name][0]\n",
    "print(f\"Status: {ds_job.status}\")\n",
    "if ds_job.output_paths:\n",
    "    with open(ds_job.output_paths[0]) as f: print(json.dumps(json.load(f), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logs\n",
    "!syft-bg logs approve\n",
    "print(\"---\")\n",
    "!syft-bg logs notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "!syft-bg stop\n",
    "!syft-bg status"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
