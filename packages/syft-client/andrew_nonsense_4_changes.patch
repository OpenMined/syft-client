diff --git a/.claude/settings.local.json b/.claude/settings.local.json
index fbffb35..3713f3b 100644
--- a/.claude/settings.local.json
+++ b/.claude/settings.local.json
@@ -22,7 +22,24 @@
       "Bash(uv run:*)",
       "Bash(uv add:*)",
       "Bash(timeout 5 uv run:*)",
-      "Bash(pkill:*)"
+      "Bash(pkill:*)",
+      "Bash(pip3 list:*)",
+      "Bash(source:*)",
+      "Bash(/Users/atrask/Library/Python/3.9/bin/python3 -c \"import cProfile; import syft_client as sc; cProfile.run(''sc.login(\"\"andrew@openmined.org\"\")'', ''login.prof'')\")",
+      "Bash(kill:*)",
+      "Bash(true)",
+      "Bash(pip install:*)",
+      "Bash(curl:*)",
+      "Bash(pip3 install:*)",
+      "Bash(uv publish:*)",
+      "Bash(ss terminate_all:*)",
+      "Bash(git -C /Users/atrask/Desktop/Laboratory/syft-serve add -A)",
+      "Bash(git -C /Users/atrask/Desktop/Laboratory/syft-serve commit -m \"$(cat <<''EOF''\nRelease version 0.2.8\n\n- Updated version in pyproject.toml and __init__.py\n- Fixed local path dependency handling for uv environments\n- Improved metadata compatibility\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\")",
+      "Bash(git -C /Users/atrask/Desktop/Laboratory/syft-serve push origin main)",
+      "Bash(chmod:*)",
+      "WebFetch(domain:developers.google.com)",
+      "Bash(git checkout:*)",
+      "Bash(git branch:*)"
     ],
     "deny": []
   }
diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
index b1b9a44..00c46e9 100644
--- a/.github/workflows/ci.yml
+++ b/.github/workflows/ci.yml
@@ -21,7 +21,7 @@ jobs:
       - name: Set up Python
         uses: actions/setup-python@v4
         with:
-          python-version: "3.10"
+          python-version: "3.11"
 
       - name: Install dependencies
         run: |
@@ -46,8 +46,8 @@ jobs:
     strategy:
       fail-fast: false
       matrix:
-        os: [ubuntu-latest]
-        python-version: ["3.10", "3.12"]
+        os: [ubuntu-latest, macos-latest, windows-latest]
+        python-version: ["3.8", "3.9", "3.10", "3.11"]
 
     steps:
       - name: Checkout code
@@ -72,7 +72,7 @@ jobs:
             --junit-xml=junit-${{ matrix.os }}-${{ matrix.python-version }}.xml
 
       - name: Upload coverage to Codecov
-        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.10'
+        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
         uses: codecov/codecov-action@v3
         with:
           file: ./coverage.xml
@@ -101,7 +101,7 @@ jobs:
       - name: Set up Python
         uses: actions/setup-python@v4
         with:
-          python-version: "3.10"
+          python-version: "3.11"
 
       - name: Install dependencies
         run: |
@@ -323,7 +323,7 @@ jobs:
       - name: Set up Python
         uses: actions/setup-python@v4
         with:
-          python-version: "3.10"
+          python-version: "3.11"
 
       - name: Install build dependencies
         run: |
diff --git a/.github/workflows/integration.yml b/.github/workflows/integration.yml
index f57b094..aec85d6 100644
--- a/.github/workflows/integration.yml
+++ b/.github/workflows/integration.yml
@@ -1,22 +1,6 @@
 name: Integration Tests
 
 on:
-  push:
-    branches: [ main ]
-    paths:
-      - 'syft_client/**'
-      - 'tests/**'
-      - '.github/workflows/integration.yml'
-      - 'requirements.txt'
-      - 'pyproject.toml'
-  pull_request:
-    branches: [ main ]
-    paths:
-      - 'syft_client/**'
-      - 'tests/**'
-      - '.github/workflows/integration.yml'
-      - 'requirements.txt'
-      - 'pyproject.toml'
   schedule:
     # Run nightly at 2 AM UTC
     - cron: '0 2 * * *'
@@ -29,7 +13,6 @@ on:
         type: choice
         options:
           - full
-          - login-only
           - two-user-only
           - cleanup-only
       verbose:
@@ -43,230 +26,11 @@ env:
   FORCE_COLOR: 1
 
 jobs:
-  post-merge-tests:
-    name: Post-Merge Live Tests
-    runs-on: ubuntu-latest
-    timeout-minutes: 30
-    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
-    
-    steps:
-      - name: Checkout code
-        uses: actions/checkout@v4
-
-      - name: Set up Python
-        uses: actions/setup-python@v4
-        with:
-          python-version: "3.10"
-
-      - name: Install dependencies
-        run: |
-          python -m pip install --upgrade pip
-          pip install -e ".[test]"
-
-      - name: Setup test credentials
-        env:
-          GOOGLE_SERVICE_ACCOUNT_KEY: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_KEY }}
-          TEST_USER1_CREDENTIALS: ${{ secrets.TEST_USER1_CREDENTIALS }}
-          TEST_USER2_CREDENTIALS: ${{ secrets.TEST_USER2_CREDENTIALS }}
-          TEST_USER1_TOKEN: ${{ secrets.TEST_USER1_TOKEN }}
-          TEST_USER2_TOKEN: ${{ secrets.TEST_USER2_TOKEN }}
-          TEST_USER1_EMAIL: ${{ secrets.TEST_USER1_EMAIL }}
-          TEST_USER2_EMAIL: ${{ secrets.TEST_USER2_EMAIL }}
-        run: |
-          echo "üöÄ Setting up credentials for post-merge live tests..."
-          
-          # Sanitize email addresses for directory names
-          SANITIZED_USER1_EMAIL=$(echo "$TEST_USER1_EMAIL" | sed 's/@/_at_/g' | sed 's/\./_/g')
-          SANITIZED_USER2_EMAIL=$(echo "$TEST_USER2_EMAIL" | sed 's/@/_at_/g' | sed 's/\./_/g')
-          
-          mkdir -p ~/.syft/test
-          mkdir -p ~/.syft/gdrive/$SANITIZED_USER1_EMAIL
-          mkdir -p ~/.syft/gdrive/$SANITIZED_USER2_EMAIL
-          
-          # Write all credentials and tokens
-          echo "$GOOGLE_SERVICE_ACCOUNT_KEY" > ~/.syft/test/service-account.json
-          echo "$TEST_USER1_CREDENTIALS" > ~/.syft/test/user1-creds.json
-          echo "$TEST_USER2_CREDENTIALS" > ~/.syft/test/user2-creds.json
-          
-          echo "$TEST_USER1_CREDENTIALS" > ~/.syft/gdrive/$SANITIZED_USER1_EMAIL/credentials.json
-          echo "$TEST_USER2_CREDENTIALS" > ~/.syft/gdrive/$SANITIZED_USER2_EMAIL/credentials.json
-          
-          echo "$TEST_USER1_TOKEN" > ~/.syft/gdrive/$SANITIZED_USER1_EMAIL/token.json
-          echo "$TEST_USER2_TOKEN" > ~/.syft/gdrive/$SANITIZED_USER2_EMAIL/token.json
-          
-          echo "{\"email\": \"$TEST_USER1_EMAIL\"}" > ~/.syft/gdrive/$SANITIZED_USER1_EMAIL/account_info.json
-          echo "{\"email\": \"$TEST_USER2_EMAIL\"}" > ~/.syft/gdrive/$SANITIZED_USER2_EMAIL/account_info.json
-          
-          chmod 600 ~/.syft/test/*.json ~/.syft/gdrive/*/credentials.json ~/.syft/gdrive/*/token.json ~/.syft/gdrive/*/account_info.json
-          
-          echo "‚úÖ Credentials configured for post-merge testing"
-
-      - name: Run critical smoke tests
-        env:
-          TEST_USER1_EMAIL: ${{ secrets.TEST_USER1_EMAIL }}
-          TEST_USER2_EMAIL: ${{ secrets.TEST_USER2_EMAIL }}
-          GOOGLE_APPLICATION_CREDENTIALS: ~/.syft/test/service-account.json
-          SYFT_TEST_MODE: integration
-        run: |
-          echo "üî• Running critical smoke tests after merge..."
-          
-          # Test 1: Login functionality (CRITICAL - must pass)
-          echo "üìå Test 1: Login Authentication"
-          pytest tests/integration/test_login_only.py -v --tb=short \
-            -m "integration" \
-            --junit-xml=junit-smoke-login.xml
-          
-          # Test 2: Two-user workflow (CRITICAL - must pass)
-          echo "üìå Test 2: Two-User Workflow"
-          pytest tests/integration/test_two_user_workflow.py::TestTwoUserWorkflow::test_bidirectional_friend_setup -v --tb=short \
-            --junit-xml=junit-smoke-two-user.xml
-
-      - name: Display audit logs
-        if: always()
-        env:
-          TEST_USER1_EMAIL: ${{ secrets.TEST_USER1_EMAIL }}
-          TEST_USER2_EMAIL: ${{ secrets.TEST_USER2_EMAIL }}
-          GOOGLE_APPLICATION_CREDENTIALS: ~/.syft/test/service-account.json
-        run: |
-          echo "üìö Listing CI Audit Logs created in Google Drive..."
-          python -c "
-          import syft_client as sc
-          import os
-          
-          user1_email = os.environ.get('TEST_USER1_EMAIL')
-          user2_email = os.environ.get('TEST_USER2_EMAIL')
-          
-          print('üîç Checking audit logs for both test users...')
-          
-          for email in [user1_email, user2_email]:
-              try:
-                  user = sc.login(email, verbose=False, force_relogin=False)
-                  print(f'\\nüìÅ Audit logs for {email}:')
-                  
-                  # List files in CI_AUDIT_LOGS_DO_NOT_DELETE folder at root
-                  results = user.service.files().list(
-                      q=\"name='CI_AUDIT_LOGS_DO_NOT_DELETE' and 'root' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false\",
-                      fields=\"files(id)\"
-                  ).execute()
-                  
-                  if results.get('files'):
-                      audit_folder_id = results['files'][0]['id']
-                      
-                      # List audit files
-                      audit_files = user.service.files().list(
-                          q=f\"'{audit_folder_id}' in parents and trashed=false\",
-                          fields=\"files(id,name,createdTime)\",
-                          orderBy=\"createdTime desc\"
-                      ).execute()
-                      
-                      for file in audit_files.get('files', []):
-                          print(f\"   - {file['name']} (created: {file['createdTime']})  \")
-                  else:
-                      print('   No audit logs folder found')
-              except Exception as e:
-                  print(f'   Error checking {email}: {e}')
-          
-          print('\\n‚úÖ Audit log listing complete')
-          "
-
-      - name: Run live API tests
-        env:
-          TEST_USER1_EMAIL: ${{ secrets.TEST_USER1_EMAIL }}
-          TEST_USER2_EMAIL: ${{ secrets.TEST_USER2_EMAIL }}
-          GOOGLE_APPLICATION_CREDENTIALS: ~/.syft/test/service-account.json
-          SYFT_TEST_MODE: integration
-        run: |
-          echo "üåê Running live API verification tests..."
-          
-          # Create a Python script to test live functionality
-          cat > test_live_api.py << 'EOF'
-          import syft_client as sc
-          import os
-          import sys
-          
-          def test_live_api():
-              """Test that the API works with live Google Drive"""
-              user1_email = os.environ.get('TEST_USER1_EMAIL')
-              user2_email = os.environ.get('TEST_USER2_EMAIL')
-              
-              print("üîç Testing live API functionality...")
-              
-              # Test 1: Can authenticate
-              print("  1Ô∏è‚É£ Testing authentication...")
-              try:
-                  user1 = sc.login(user1_email, verbose=False, force_relogin=False)
-                  assert user1.authenticated, "User1 authentication failed"
-                  print(f"     ‚úÖ User1 authenticated: {user1.my_email}")
-              except Exception as e:
-                  print(f"     ‚ùå Authentication failed: {e}")
-                  return False
-              
-              # Test 2: Can access Google Drive API
-              print("  2Ô∏è‚É£ Testing Google Drive API access...")
-              try:
-                  result = user1.service.files().list(pageSize=1, fields="files(id,name)").execute()
-                  print(f"     ‚úÖ Google Drive API accessible")
-              except Exception as e:
-                  print(f"     ‚ùå API access failed: {e}")
-                  return False
-              
-              # Test 3: Can create and delete folders
-              print("  3Ô∏è‚É£ Testing folder operations...")
-              try:
-                  test_folder_id = user1._create_folder("test_post_merge_folder")
-                  assert test_folder_id, "Folder creation failed"
-                  print(f"     ‚úÖ Created test folder: {test_folder_id}")
-                  
-                  # Clean up
-                  user1.service.files().delete(fileId=test_folder_id).execute()
-                  print(f"     ‚úÖ Deleted test folder")
-              except Exception as e:
-                  print(f"     ‚ùå Folder operations failed: {e}")
-                  return False
-              
-              # Test 4: SyftBox exists or can be created
-              print("  4Ô∏è‚É£ Testing SyftBox functionality...")
-              try:
-                  if not user1._folder_exists("SyftBoxTransportService"):
-                      user1.reset_syftbox()
-                  assert user1._folder_exists("SyftBoxTransportService"), "SyftBox not found"
-                  print(f"     ‚úÖ SyftBox verified")
-              except Exception as e:
-                  print(f"     ‚ùå SyftBox test failed: {e}")
-                  return False
-              
-              print("\n‚úÖ All live API tests passed!")
-              return True
-          
-          if __name__ == "__main__":
-              success = test_live_api()
-              sys.exit(0 if success else 1)
-          EOF
-          
-          python test_live_api.py
-
-      - name: Upload post-merge test results
-        if: always()
-        uses: actions/upload-artifact@v4
-        with:
-          name: post-merge-test-results
-          path: |
-            junit-smoke-*.xml
-            test_live_api.py
-
-      - name: Notify on failure
-        if: failure()
-        run: |
-          echo "‚ùå POST-MERGE TESTS FAILED!"
-          echo "Critical functionality may be broken in production."
-          echo "Please review the test results and fix immediately."
-          # Add Slack/email notification here if configured
-
   integration-full:
     name: Full Integration Test Suite
     runs-on: ubuntu-latest
     timeout-minutes: 45
-    if: github.event_name == 'pull_request' || github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && github.event.inputs.test_scope == 'full')
+    if: github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && github.event.inputs.test_scope == 'full')
     
     steps:
       - name: Checkout code
@@ -275,7 +39,7 @@ jobs:
       - name: Set up Python
         uses: actions/setup-python@v4
         with:
-          python-version: "3.10"
+          python-version: "3.11"
 
       - name: Install dependencies
         run: |
@@ -449,18 +213,6 @@ jobs:
               print(f'‚ö†Ô∏è  Pre-cleanup warning: {e}')
           "
 
-      - name: Run login test
-        env:
-          TEST_USER1_EMAIL: ${{ secrets.TEST_USER1_EMAIL }}
-          TEST_USER2_EMAIL: ${{ secrets.TEST_USER2_EMAIL }}
-          GOOGLE_APPLICATION_CREDENTIALS: ~/.syft/test/service-account.json
-          SYFT_TEST_MODE: integration
-        run: |
-          echo "üîê Running login authentication test..."
-          pytest tests/integration/test_login_only.py -v --tb=short \
-            -m "integration" \
-            --junit-xml=junit-login.xml
-
       - name: Run authentication tests
         env:
           TEST_USER1_EMAIL: ${{ secrets.TEST_USER1_EMAIL }}
@@ -481,7 +233,7 @@ jobs:
         run: |
           pytest tests/integration/test_syftbox_ops.py -v --tb=short \
             -m "integration and syftbox" \
-            --junit-xml=junit-syftbox.xml || true
+            --junit-xml=junit-syftbox.xml
 
       - name: Debug credential setup (main job)
         run: |
@@ -529,9 +281,9 @@ jobs:
           GOOGLE_APPLICATION_CREDENTIALS: ~/.syft/test/service-account.json
           SYFT_TEST_MODE: integration
         run: |
-          # Friend management tests are part of test_two_user_workflow.py
-          echo "Friend management tests are included in two-user workflow tests"
-          echo "Skipping separate friend management test file (does not exist)"
+          pytest tests/integration/test_friend_management.py -v --tb=short \
+            -m "integration and friends" \
+            --junit-xml=junit-friends.xml
 
       - name: Run edge cases and stress tests
         env:
@@ -540,10 +292,50 @@ jobs:
           GOOGLE_APPLICATION_CREDENTIALS: ~/.syft/test/service-account.json
           SYFT_TEST_MODE: integration
         run: |
-          # Edge cases and stress tests are part of test_two_user_workflow.py
-          echo "Edge cases and stress tests are included in two-user workflow tests"
-          echo "Skipping separate edge cases test file (does not exist)"
+          pytest tests/integration/test_edge_cases.py -v --tb=short \
+            -m "integration and slow" \
+            --junit-xml=junit-edge-cases.xml
 
+      - name: Generate test report
+        if: always()
+        run: |
+          echo "## üß™ Integration Test Results" > test-report.md
+          echo "" >> test-report.md
+          echo "### Test Summary" >> test-report.md
+          
+          # Count passed/failed tests from JUnit files
+          if ls junit-*.xml 1> /dev/null 2>&1; then
+            python -c "
+            import xml.etree.ElementTree as ET
+            import glob
+            
+            total_tests = 0
+            total_failures = 0
+            total_errors = 0
+            
+            for file in glob.glob('junit-*.xml'):
+                try:
+                    tree = ET.parse(file)
+                    root = tree.getroot()
+                    total_tests += int(root.attrib.get('tests', 0))
+                    total_failures += int(root.attrib.get('failures', 0))
+                    total_errors += int(root.attrib.get('errors', 0))
+                except:
+                    pass
+            
+            passed = total_tests - total_failures - total_errors
+            print(f'- ‚úÖ Passed: {passed}')
+            print(f'- ‚ùå Failed: {total_failures}')  
+            print(f'- üí• Errors: {total_errors}')
+            print(f'- üìä Total: {total_tests}')
+            " >> test-report.md
+          fi
+          
+          echo "" >> test-report.md
+          echo "### Test Environment" >> test-report.md
+          echo "- Python Version: $(python --version)" >> test-report.md
+          echo "- OS: Ubuntu Latest" >> test-report.md
+          echo "- Timestamp: $(date -u)" >> test-report.md
 
       - name: Post-cleanup test environment
         if: always()
@@ -569,86 +361,9 @@ jobs:
           name: integration-test-results-full
           path: |
             junit-*.xml
+            test-report.md
             ~/.syft/test/*.log
 
-  login-only:
-    name: Login Test Only
-    runs-on: ubuntu-latest
-    timeout-minutes: 15
-    if: github.event_name == 'workflow_dispatch' && github.event.inputs.test_scope == 'login-only'
-    
-    steps:
-      - name: Checkout code
-        uses: actions/checkout@v4
-
-      - name: Set up Python
-        uses: actions/setup-python@v4
-        with:
-          python-version: "3.10"
-
-      - name: Install dependencies
-        run: |
-          python -m pip install --upgrade pip
-          pip install -e ".[test]"
-
-      - name: Setup test credentials
-        env:
-          GOOGLE_SERVICE_ACCOUNT_KEY: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_KEY }}
-          TEST_USER1_CREDENTIALS: ${{ secrets.TEST_USER1_CREDENTIALS }}
-          TEST_USER2_CREDENTIALS: ${{ secrets.TEST_USER2_CREDENTIALS }}
-          TEST_USER1_TOKEN: ${{ secrets.TEST_USER1_TOKEN }}
-          TEST_USER2_TOKEN: ${{ secrets.TEST_USER2_TOKEN }}
-          TEST_USER1_EMAIL: ${{ secrets.TEST_USER1_EMAIL }}
-          TEST_USER2_EMAIL: ${{ secrets.TEST_USER2_EMAIL }}
-        run: |
-          echo "üîç Setting up test credentials for login-only test..."
-          
-          # Sanitize email addresses for directory names
-          SANITIZED_USER1_EMAIL=$(echo "$TEST_USER1_EMAIL" | sed 's/@/_at_/g' | sed 's/\./_/g')
-          SANITIZED_USER2_EMAIL=$(echo "$TEST_USER2_EMAIL" | sed 's/@/_at_/g' | sed 's/\./_/g')
-          
-          mkdir -p ~/.syft/test
-          mkdir -p ~/.syft/gdrive/$SANITIZED_USER1_EMAIL
-          mkdir -p ~/.syft/gdrive/$SANITIZED_USER2_EMAIL
-          
-          # Write all necessary files
-          echo "$GOOGLE_SERVICE_ACCOUNT_KEY" > ~/.syft/test/service-account.json
-          echo "$TEST_USER1_CREDENTIALS" > ~/.syft/test/user1-creds.json
-          echo "$TEST_USER2_CREDENTIALS" > ~/.syft/test/user2-creds.json
-          
-          echo "$TEST_USER1_CREDENTIALS" > ~/.syft/gdrive/$SANITIZED_USER1_EMAIL/credentials.json
-          echo "$TEST_USER2_CREDENTIALS" > ~/.syft/gdrive/$SANITIZED_USER2_EMAIL/credentials.json
-          
-          echo "$TEST_USER1_TOKEN" > ~/.syft/gdrive/$SANITIZED_USER1_EMAIL/token.json
-          echo "$TEST_USER2_TOKEN" > ~/.syft/gdrive/$SANITIZED_USER2_EMAIL/token.json
-          
-          echo "{\"email\": \"$TEST_USER1_EMAIL\"}" > ~/.syft/gdrive/$SANITIZED_USER1_EMAIL/account_info.json
-          echo "{\"email\": \"$TEST_USER2_EMAIL\"}" > ~/.syft/gdrive/$SANITIZED_USER2_EMAIL/account_info.json
-          
-          chmod 600 ~/.syft/test/*.json ~/.syft/gdrive/*/credentials.json ~/.syft/gdrive/*/token.json ~/.syft/gdrive/*/account_info.json
-          
-          echo "‚úÖ Credentials configured successfully"
-
-      - name: Run login-only test
-        env:
-          TEST_USER1_EMAIL: ${{ secrets.TEST_USER1_EMAIL }}
-          TEST_USER2_EMAIL: ${{ secrets.TEST_USER2_EMAIL }}
-          GOOGLE_APPLICATION_CREDENTIALS: ~/.syft/test/service-account.json
-          SYFT_TEST_MODE: integration
-        run: |
-          echo "üîê Running login-only test..."
-          pytest tests/integration/test_login_only.py -v --tb=short \
-            -m "integration" \
-            --junit-xml=junit-login.xml
-          echo "‚úÖ Login test completed successfully"
-
-      - name: Upload test results
-        if: always()
-        uses: actions/upload-artifact@v4
-        with:
-          name: login-only-results
-          path: junit-login.xml
-
   two-user-workflow-only:
     name: Two-User Workflow Test
     runs-on: ubuntu-latest
@@ -662,7 +377,7 @@ jobs:
       - name: Set up Python
         uses: actions/setup-python@v4
         with:
-          python-version: "3.10"
+          python-version: "3.11"
 
       - name: Install dependencies
         run: |
@@ -821,7 +536,7 @@ jobs:
       - name: Set up Python
         uses: actions/setup-python@v4
         with:
-          python-version: "3.10"
+          python-version: "3.11"
 
       - name: Install dependencies
         run: |
@@ -934,25 +649,12 @@ jobs:
   notify-results:
     name: Notify Results
     runs-on: ubuntu-latest
-    needs: [post-merge-tests, integration-full, login-only, two-user-workflow-only, cleanup-only]
-    if: |
-      always() && (
-        github.event_name == 'schedule' ||
-        (github.event_name == 'push' && github.ref == 'refs/heads/main')
-      )
+    needs: [integration-full, two-user-workflow-only, cleanup-only]
+    if: always() && github.event_name == 'schedule'
     
     steps:
-      - name: Notify on post-merge failure
-        if: github.event_name == 'push' && needs.post-merge-tests.result == 'failure'
-        run: |
-          echo "üö® CRITICAL: Post-merge tests failed!"
-          echo "Production code may be broken!"
-          echo "Commit: ${{ github.sha }}"
-          echo "Author: ${{ github.actor }}"
-          # Add urgent notification logic here (Slack, PagerDuty, etc.)
-          
-      - name: Notify on nightly failure
-        if: github.event_name == 'schedule' && needs.integration-full.result == 'failure'
+      - name: Notify on failure
+        if: needs.integration-full.result == 'failure'
         run: |
           echo "üí• Nightly integration tests failed!"
           echo "Check the workflow logs for details."
diff --git a/.github/workflows/pr-check.yml b/.github/workflows/pr-check.yml
index 1876528..ba4740d 100644
--- a/.github/workflows/pr-check.yml
+++ b/.github/workflows/pr-check.yml
@@ -21,7 +21,7 @@ jobs:
       - name: Set up Python
         uses: actions/setup-python@v4
         with:
-          python-version: "3.10"
+          python-version: "3.11"
 
       - name: Install dependencies
         run: |
@@ -77,7 +77,7 @@ jobs:
       - name: Set up Python
         uses: actions/setup-python@v4
         with:
-          python-version: "3.10"
+          python-version: "3.11"
 
       - name: Install bandit
         run: pip install bandit[toml]
@@ -117,7 +117,7 @@ jobs:
     strategy:
       fail-fast: false
       matrix:
-        python-version: ["3.10", "3.12"]  # Test current Colab version and latest stable
+        python-version: ["3.8", "3.11"]  # Test oldest and newest
     steps:
       - name: Checkout code
         uses: actions/checkout@v4
@@ -140,9 +140,8 @@ jobs:
         run: |
           python -c "
           import syft_client
-          import sys
-          print(f'‚úÖ Python {sys.version.split()[0]} compatibility OK')
-          "
+          print(f'‚úÖ Python {python_version} compatibility OK')
+          " python_version="${{ matrix.python-version }}"
 
       - name: Run minimal unit tests
         run: |
diff --git a/.github/workflows/publish.yml b/.github/workflows/publish.yml
index 08e97db..b60acc7 100644
--- a/.github/workflows/publish.yml
+++ b/.github/workflows/publish.yml
@@ -26,7 +26,7 @@ jobs:
       - name: Set up Python
         uses: actions/setup-python@v4
         with:
-          python-version: "3.10"
+          python-version: "3.11"
 
       - name: Install build dependencies
         run: |
@@ -52,8 +52,8 @@ jobs:
     strategy:
       fail-fast: false
       matrix:
-        os: [ubuntu-latest]
-        python-version: ["3.10", "3.12"]
+        os: [ubuntu-latest, macos-latest, windows-latest]
+        python-version: ["3.8", "3.9", "3.10", "3.11"]
 
     steps:
       - name: Set up Python ${{ matrix.python-version }}
diff --git a/Latency Testing.ipynb b/Latency Testing.ipynb
new file mode 100644
index 0000000..48f746a
--- /dev/null
+++ b/Latency Testing.ipynb	
@@ -0,0 +1,258 @@
+{
+ "cells": [
+  {
+   "cell_type": "code",
+   "execution_count": 1,
+   "id": "5baa0d01-c6fa-4984-822e-4e6df9d03836",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import syft_serve as ss\n",
+    "import syft_client as sc"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "id": "8737269c-2b32-4ddd-8d92-0734f96ae391",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# ss.servers.terminate_all()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 9,
+   "id": "3f50e3ed-0d68-4c92-90dd-7876a677dcec",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "[2/2] ‚úÖ Logged in as andrew@openmined.org                                                  \n",
+      "[2/2] ‚úÖ Logged in as liamtrask@gmail.com                                                  \n"
+     ]
+    }
+   ],
+   "source": [
+    "andrew_client = sc.login(\"andrew@openmined.org\", verbose=False)\n",
+    "liam_client = sc.login(\"liamtrask@gmail.com\", verbose=False)#, \"/Users/atrask/Downloads/client_secret_370526552993-10jtbi4vuvaig2qe0iseohdl2ltd7up8.apps.googleusercontent.com.json\", verbose=False)\n",
+    "# andrew_client.reset_syftbox()\n",
+    "# liam_client.reset_syftbox()\n",
+    "# andrew_client.add_friend(\"liamtrask@gmail.com\")\n",
+    "# liam_client.add_friend(\"andrew@openmined.org\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 22,
+   "id": "b1a38014-9ce2-4e2e-8663-15461c2cc412",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import base64\n",
+    "test_data = base64.b64encode(b\"A\").decode('utf-8')"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 23,
+   "id": "520da8bf-9f20-4afd-953f-d8a973f97778",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "success = andrew_client.submit_to_form_fast(\n",
+    "          from_email=\"test@example.com\",\n",
+    "          to_email=\"andrew@openmined.org\",\n",
+    "          message_id=\"test_message_123\",\n",
+    "          message_size=\"1024\",\n",
+    "          message_data=test_data\n",
+    "          # file_path=\"datasites/test/message.tar.gz\"\n",
+    "      )"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 24,
+   "id": "19dc63d4-7c6d-4815-b191-26ad257f69a0",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "1.11 s ¬± 107 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
+     ]
+    }
+   ],
+   "source": [
+    "%%timeit\n",
+    "success = andrew_client.submit_to_form_fast(\n",
+    "          from_email=\"test@example.com\",\n",
+    "          to_email=\"andrew@openmined.org\",\n",
+    "          message_id=\"test_message_123\",\n",
+    "          message_size=\"1024\",\n",
+    "          message_data=test_data\n",
+    "          # file_path=\"datasites/test/message.tar.gz\"\n",
+    "      )\n",
+    "results = andrew_client.get_results_from_form()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 19,
+   "id": "f40a20ae-db4a-460a-ac25-d97c032d3ae5",
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "{'form_url': 'https://docs.google.com/forms/d/1xb1zbPZr_7sPavcM51be49MG304iy0J3_dkCj2Unyx8/viewform',\n",
+       " 'form_id': '1xb1zbPZr_7sPavcM51be49MG304iy0J3_dkCj2Unyx8',\n",
+       " 'spreadsheet_url': 'https://docs.google.com/spreadsheets/d/1ELoB2OLXwwV421ElfqW3HMqfGizhQAnfIzWIPMKTFQ8/edit?ouid=117176484630596301481',\n",
+       " 'spreadsheet_id': '1ELoB2OLXwwV421ElfqW3HMqfGizhQAnfIzWIPMKTFQ8',\n",
+       " 'form_edit_url': 'https://docs.google.com/forms/d/1FAIpQLScafdxkvLD43-3oGM2CHL7IqWKAbIAhrRlMTseK2ZI3legpEA/edit',\n",
+       " 'note': 'Spreadsheet created but needs manual linking via Forms UI',\n",
+       " 'existing': False,\n",
+       " 'entry_map': {'from_email': '1995482074',\n",
+       "  'to_email': '1553143275',\n",
+       "  'message_id': '471668893',\n",
+       "  'message_size': '1864565',\n",
+       "  'message_data': '750395008',\n",
+       "  'file_path': '1096996663'},\n",
+       " 'submit_url': 'https://docs.google.com/forms/d/1xb1zbPZr_7sPavcM51be49MG304iy0J3_dkCj2Unyx8/formResponse',\n",
+       " 'prepared_at': '2025-09-06T10:57:24.241131'}"
+      ]
+     },
+     "execution_count": 19,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "andrew_client.form_inbox_metadata"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "227a0678-df01-43de-99d7-bd2fc21b886e",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# liam_client.update_inbox()\n",
+    "liam_client.update_inbox_from_sheets()\n",
+    "liam_client.autoapprove_inbox()\n",
+    "liam_client.merge_new_syncs()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 22,
+   "id": "d4aa5d9e-6302-4b2c-a66e-07d6d3b7daee",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "198 ms ¬± 0 ns per loop (mean ¬± std. dev. of 1 run, 1 loop each)\n"
+     ]
+    }
+   ],
+   "source": [
+    "%%timeit -n1 -r1\n",
+    "# # %%memray_flamegraph --trace-python-allocators --leaks\n",
+    "\n",
+    "andrew_client.send_file_or_folder_to_friends(\"syft://data.txt\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "6accc739-9fae-4cfe-b3be-98cbc5a65bfa",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "\n",
+    "# liam_client.update_inbox()\n",
+    "liam_client.update_inbox_from_sheets()\n",
+    "liam_client.autoapprove_inbox()\n",
+    "liam_client.merge_new_syncs()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "ca098617-dcd4-48ea-b776-63c243499dea",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "destroy_watcher_sender_endpoint(\"andrew@openmined.org\")\n",
+    "server = create_watcher_sender_endpoint(\"andrew@openmined.org\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "f8c8220f-9268-40ac-b519-d05aa5417139",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "a0b5cad5-b4d9-4e93-87e6-914986910906",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "server.stdout.lines()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "1e351e56-23b0-4238-a7eb-f03af9368a4e",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# liam_client.update_inbox()\n",
+    "liam_client.update_inbox_from_sheets()\n",
+    "liam_client.autoapprove_inbox()\n",
+    "liam_client.merge_new_syncs()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "38c74e08-46f4-4511-b25d-4fbb86accd14",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  }
+ ],
+ "metadata": {
+  "kernelspec": {
+   "display_name": "Python 3 (ipykernel)",
+   "language": "python",
+   "name": "python3"
+  },
+  "language_info": {
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 3
+   },
+   "file_extension": ".py",
+   "mimetype": "text/x-python",
+   "name": "python",
+   "nbconvert_exporter": "python",
+   "pygments_lexer": "ipython3",
+   "version": "3.12.9"
+  }
+ },
+ "nbformat": 4,
+ "nbformat_minor": 5
+}
diff --git a/SYNC_ECHO_PREVENTION.md b/SYNC_ECHO_PREVENTION.md
new file mode 100644
index 0000000..5d53813
--- /dev/null
+++ b/SYNC_ECHO_PREVENTION.md
@@ -0,0 +1,90 @@
+# Sync Echo Prevention
+
+The syft-client includes sync echo prevention to avoid infinite loops where the same file gets synced back and forth between peers.
+
+## How it works
+
+When the file watcher detects a change, it checks if the file's content matches the **most recent sync** (stored in `.sync_history`). If it does, the change is considered an "echo" and is not propagated. If the file has been edited since the most recent sync, it will be sent even if there are older syncs with matching content.
+
+### The Logic
+
+1. When a file changes, the watcher computes its hash
+2. It finds the **most recent sync** for that file (by timestamp in the folder name)
+3. If the most recent sync is within the threshold (default 60 seconds) AND matches the current content ‚Üí it's an echo
+4. If the most recent sync doesn't match ‚Üí the file has been edited and should be sent
+
+This ensures that:
+- Real edits are always detected and sent
+- Echo prevention only applies to the most recent sync
+- Older syncs are irrelevant - only the latest state matters
+
+## Configuration Options
+
+### Environment Variables
+
+#### `SYFT_SYNC_ECHO_THRESHOLD`
+- **Default**: 60 (seconds)
+- **Description**: How recent the most recent sync must be to be considered for echo prevention
+- **Example**: `export SYFT_SYNC_ECHO_THRESHOLD=120` (2 minutes)
+- **Set to 0**: Disables echo prevention entirely
+
+### Python API
+
+When using the client programmatically:
+
+```python
+import syft_client as sc
+
+client = sc.login("user@example.com")
+
+# Check if a file matches the most recent sync (default: 60 seconds)
+is_echo = client._is_file_from_recent_sync("/path/to/file.txt")
+
+# Custom threshold
+is_echo = client._is_file_from_recent_sync("/path/to/file.txt", threshold_seconds=120)
+
+# Get info about the most recent sync
+sync_info = client._get_recent_sync_info("/path/to/file.txt")
+if sync_info:
+    print(f"Most recent sync was {sync_info['age_seconds']}s ago")
+```
+
+## Sync History Storage
+
+Sync history is stored in `.sync_history` directories within each datasite folder:
+```
+datasites/
+‚îî‚îÄ‚îÄ user@example.com/
+    ‚îî‚îÄ‚îÄ project/
+        ‚îú‚îÄ‚îÄ file.txt
+        ‚îî‚îÄ‚îÄ .sync_history/
+            ‚îî‚îÄ‚îÄ file.txt/
+                ‚îú‚îÄ‚îÄ 1234567890.0_abc123.syftmessage/  ‚Üê Most recent
+                ‚îî‚îÄ‚îÄ 1234567891.0_def456.syftmessage/  ‚Üê Older
+```
+
+The folder names contain timestamps, allowing the system to identify the most recent sync.
+
+## Cleaning Sync History
+
+To save disk space, you can clean old sync history:
+
+```python
+# Clean history for a specific datasite (keeps most recent sync)
+client._clean_sync_history_for_datasite(datasite_path)
+
+# Remove all history
+client._clean_sync_history_for_datasite(datasite_path, keep_latest=False)
+```
+
+## Troubleshooting
+
+If files are not syncing:
+1. Check if echo prevention is too aggressive: increase `SYFT_SYNC_ECHO_THRESHOLD`
+2. Look at the most recent sync in `.sync_history` to see what content is expected
+3. Disable temporarily: set `SYFT_SYNC_ECHO_THRESHOLD=0`
+
+If you're getting sync loops:
+1. Ensure echo prevention is enabled (it is by default)
+2. Check that all peers have the updated syft-client with echo prevention
+3. Verify the sync history is being written correctly
\ No newline at end of file
diff --git a/TODO.md b/TODO.md
deleted file mode 100644
index a9c58e1..0000000
--- a/TODO.md
+++ /dev/null
@@ -1,72 +0,0 @@
-# TODO: Future Improvements for Syft-Client
-
-This document tracks planned improvements and feature requests for the syft-client library.
-
-## üöÄ High Priority
-
-### User Experience Improvements
-- [ ] **Progress Indicators** - Add tqdm progress bars for file uploads/downloads and long operations
-- [ ] **Better Error Messages** - Provide clear, actionable error messages with recovery suggestions
-- [ ] **Interactive Setup Wizard** - Enhance the wizard with step-by-step validation
-- [ ] **Status Dashboard** - Create a widget to show connection status and active operations
-
-### Core Functionality
-- [ ] **Batch Friend Operations** - Add/remove multiple friends at once
-- [ ] **Friend Removal** - Implement safe friend removal with proper cleanup
-- [ ] **Message History** - Track sent/received messages with timestamps
-- [ ] **Auto-sync Mechanism** - Configurable polling for new messages
-- [ ] **Retry Logic** - Automatic retry with exponential backoff for network failures
-
-## üîí Security Enhancements
-
-- [ ] **End-to-End Encryption** - Implement file encryption before upload
-- [ ] **Key Management** - Secure key exchange and storage system
-- [ ] **Digital Signatures** - Sign messages for authenticity verification
-- [ ] **Zero-Knowledge Proofs** - Enhanced privacy for sensitive operations
-- [ ] **Audit Logging** - Comprehensive logging with privacy controls
-
-## üåê Transport Layer Extensions
-
-- [ ] **Email Transport** - SMTP/IMAP backend for email-based communication
-- [ ] **WebRTC Support** - Direct peer-to-peer connections
-- [ ] **IPFS Integration** - Decentralized storage backend
-- [ ] **AWS S3 Support** - Cloud storage integration
-- [ ] **Multi-Transport** - Use multiple transports simultaneously with failover
-
-## üìä Performance & Scalability
-
-- [ ] **Chunked Transfers** - Handle large files with resume capability
-- [ ] **Parallel Operations** - Concurrent file uploads/downloads
-- [ ] **Caching Layer** - Smart caching for frequently accessed data
-- [ ] **Connection Pooling** - Reuse API connections efficiently
-- [ ] **Rate Limiting** - Respect and handle API rate limits gracefully
-
-## üß™ Testing & Quality
-
-- [ ] **Increase Test Coverage** - Target 90%+ coverage
-- [ ] **Performance Benchmarks** - Add speed and resource usage tests
-- [ ] **Integration Test Suite** - Comprehensive end-to-end tests
-- [ ] **Mock Backend** - Testing without real Google Drive
-- [ ] **Continuous Monitoring** - Health checks and status monitoring
-
-## üìö Documentation
-
-- [ ] **Video Tutorials** - Create walkthrough videos
-- [ ] **Architecture Guide** - Detailed system design documentation
-- [ ] **Migration Guide** - Help users upgrade between versions
-- [ ] **Troubleshooting Database** - Common issues and solutions
-- [ ] **Example Gallery** - Real-world use cases and examples
-
-## üé® Developer Experience
-
-- [ ] **Type Hints** - Complete type annotations throughout codebase
-- [ ] **Async Support** - Async/await for non-blocking operations
-- [ ] **Plugin System** - Extensibility through plugins
-- [ ] **CLI Tool** - Command-line interface for power users
-- [ ] **Debug Mode** - Verbose logging and diagnostic tools
-
----
-
-Last Updated: 2024-08-29
-
-To contribute or discuss these items, please visit: https://github.com/OpenMined/syft-client/issues
\ No newline at end of file
diff --git a/hi.txt b/hi.txt
new file mode 100644
index 0000000..b6fc4c6
--- /dev/null
+++ b/hi.txt
@@ -0,0 +1 @@
+hello
\ No newline at end of file
diff --git a/notebook_file_observer.py b/notebook_file_observer.py
deleted file mode 100644
index e864757..0000000
--- a/notebook_file_observer.py
+++ /dev/null
@@ -1,162 +0,0 @@
-#!/usr/bin/env python3
-"""
-Notebook-friendly version of SyftBox File Observer
-Copy and paste this into a Jupyter notebook
-"""
-
-# Cell 1: Setup and start observer
-import syft_serve as ss
-import syft_client as sc
-from pathlib import Path
-import requests
-
-# Configuration
-EMAIL = "andrew@openmined.org"
-SYFTBOX_DIR = Path.home() / f"SyftBox_{EMAIL}"
-DATASITES_DIR = SYFTBOX_DIR / "datasites"
-OUTBOX_DIR = SYFTBOX_DIR / "outbox"
-
-# Ensure directories exist
-DATASITES_DIR.mkdir(parents=True, exist_ok=True)
-OUTBOX_DIR.mkdir(parents=True, exist_ok=True)
-
-print(f"üìÅ SyftBox directory: {SYFTBOX_DIR}")
-print(f"üìÇ Datasites: {DATASITES_DIR}")
-print(f"üì§ Outbox: {OUTBOX_DIR}")
-
-# Cell 2: Define the observer function
-def create_observer():
-    from watchdog.observers import Observer
-    from watchdog.events import FileSystemEventHandler
-    import time
-    import sys
-    
-    # Force unbuffered output
-    sys.stdout.reconfigure(line_buffering=True)
-    
-    class DataSitesHandler(FileSystemEventHandler):
-        def on_any_event(self, event):
-            if not event.is_directory and not event.src_path.endswith('.tmp'):
-                print(f"[{time.strftime('%H:%M:%S')}] {event.event_type}: {Path(event.src_path).name}", flush=True)
-                
-                # Create SyftMessage
-                if event.event_type in ['created', 'modified']:
-                    try:
-                        file_path = Path(event.src_path)
-                        if file_path.exists() and not file_path.name.startswith('.'):
-                            # Create message
-                            msg = sc.SyftMessage.create(
-                                sender_email=EMAIL,
-                                recipient_email="recipient@example.com",
-                                message_root=OUTBOX_DIR
-                            )
-                            
-                            # Add file
-                            msg.add_file(
-                                source_path=file_path,
-                                path=f"/{EMAIL}/datasites/{file_path.relative_to(DATASITES_DIR)}",
-                                permissions={"read": ["recipient@example.com"], "write": [EMAIL], "admin": [EMAIL]}
-                            )
-                            
-                            # Finalize
-                            msg.finalize()
-                            print(f"   ‚úÖ Created message: {msg.message_id}", flush=True)
-                    except Exception as e:
-                        print(f"   ‚ùå Error: {e}", flush=True)
-    
-    # Create observer
-    observer = Observer()
-    observer.schedule(DataSitesHandler(), str(DATASITES_DIR), recursive=True)
-    observer.start()
-    
-    return observer
-
-# Cell 3: Create server with observer
-ss.servers.terminate_all()
-
-# Global observer reference
-observer = None
-
-def start():
-    global observer
-    if observer is None:
-        observer = create_observer()
-        return {"status": "Observer started", "watching": str(DATASITES_DIR)}
-    return {"status": "Already running"}
-
-def status():
-    return {
-        "running": observer is not None and observer.is_alive(),
-        "datasites_dir": str(DATASITES_DIR),
-        "outbox_dir": str(OUTBOX_DIR)
-    }
-
-def list_messages():
-    messages = []
-    for msg_dir in OUTBOX_DIR.iterdir():
-        if msg_dir.is_dir() and msg_dir.name.startswith("gdrive_"):
-            messages.append(msg_dir.name)
-    return {"messages": messages, "count": len(messages)}
-
-# Create server
-server = ss.create(
-    name="notebook_observer",
-    dependencies=["watchdog"],
-    endpoints={
-        "/start": start,
-        "/status": status,
-        "/messages": list_messages
-    }
-)
-
-print(f"\\nüåê Server: {server.url}")
-
-# Auto-start
-response = requests.get(f"{server.url}/start")
-print(f"‚úÖ {response.json()['status']}")
-
-# Cell 4: Test the observer
-print("\\nüìù Test the observer by creating files:")
-print(f"\\n# Create a test file")
-print(f"test_file = DATASITES_DIR / 'test.txt'")
-print(f"test_file.write_text('Hello SyftBox!')")
-print(f"\\n# Check messages")
-print(f"requests.get('{server.url}/messages').json()")
-print(f"\\n# View logs")
-print(f"ss.servers['notebook_observer'].stdout.lines()[-10:]")
-
-# Cell 5: Helper functions
-def create_test_file(name="test.csv", content="id,value\\n1,100\\n2,200"):
-    """Create a test file in datasites"""
-    file_path = DATASITES_DIR / name
-    file_path.write_text(content)
-    print(f"Created: {file_path}")
-    return file_path
-
-def view_logs(n=10):
-    """View recent observer logs"""
-    logs = ss.servers['notebook_observer'].stdout.lines()
-    return logs[-n:] if logs else []
-
-def list_outbox():
-    """List messages in outbox with details"""
-    for msg_dir in sorted(OUTBOX_DIR.iterdir()):
-        if msg_dir.is_dir() and msg_dir.name.startswith("gdrive_"):
-            print(f"\\nüì© {msg_dir.name}")
-            
-            # Check for files
-            files_dir = msg_dir / "data" / "files"
-            if files_dir.exists():
-                files = list(files_dir.iterdir())
-                print(f"   Files: {[f.name for f in files]}")
-            
-            # Check if locked/ready
-            if (msg_dir / "lock.json").exists():
-                print("   Status: ‚úÖ Ready to send")
-            else:
-                print("   Status: ‚è≥ Not finalized")
-
-print("\\nüõ†Ô∏è Helper functions available:")
-print("  create_test_file()  - Create a test file")
-print("  view_logs()         - View observer logs")
-print("  list_outbox()       - List messages in detail")
\ No newline at end of file
diff --git a/potential_improvements.md b/potential_improvements.md
deleted file mode 100644
index e91c4da..0000000
--- a/potential_improvements.md
+++ /dev/null
@@ -1,198 +0,0 @@
-# Syft-Client Potential Improvements
-
-This document outlines potential enhancements for the syft-client library, with special consideration for Jupyter notebook and Google Colab environments.
-
-## üîß Bug Fixes & Code Quality
-
-### High Priority
-- **Fix duplicate token fields**: Remove duplicate `client_id` and `client_secret` in token saving (`gdrive_unified.py:320-321, 382-383`)
-- **Improve error handling**: Better network failure recovery and user-friendly error messages
-- **Input validation**: Add comprehensive validation for email addresses and file paths
-- **Race condition fixes**: Handle concurrent operations safely
-
-### Medium Priority
-- **Memory optimization**: Optimize for notebook environments with limited memory
-- **Connection cleanup**: Ensure proper cleanup of Google API connections
-- **Edge case handling**: Better handling when folders are manually deleted from Drive
-
-## üì± Jupyter/Colab Specific Enhancements
-
-### Interactive Features
-- **Rich display widgets**: Use `syft-widget` more extensively for interactive UIs
-- **Progress bars**: Add `tqdm` integration for long operations (file transfers, friend setup)
-- **Interactive friend management**: Widget-based friend adding/removing interface
-- **Real-time status updates**: Live updates of connection status in notebooks
-- **Embedded file browsers**: Widget to browse and select files from Drive
-
-### Notebook Integration
-- **Cell magic commands**: Add `%%syft_sync` magic for automatic syncing
-- **Auto-save integration**: Automatically backup notebooks to friend channels
-- **Colab-specific optimizations**: Better integration with Colab's file system and auth
-- **Markdown rendering**: Rich display of friend lists and status in markdown format
-- **Interactive setup wizard**: Step-by-step notebook setup with embedded forms
-
-## üöÄ New Features
-
-### Core Functionality
-- **File encryption**: End-to-end encryption before sharing (notebook-friendly key management)
-- **Message queuing**: Queue system for reliable message delivery
-- **Bulk operations**: Add/remove multiple friends at once
-- **Group channels**: Multi-participant communication channels
-- **File versioning**: Track and manage different versions of shared files
-- **Sync mechanisms**: Auto-sync with configurable intervals
-
-### Advanced Features
-- **Smart notifications**: Notebook-friendly notification system (no popup blocking)
-- **File watching**: Monitor local files and auto-sync changes
-- **Collaboration tools**: Real-time collaborative editing markers
-- **Data lineage**: Track file origins and transformations
-- **Checkpoint system**: Create and restore communication channel snapshots
-
-## üîê Security & Privacy
-
-### Authentication Improvements
-- **Service account support**: Better for automated notebooks
-- **Token rotation**: Automatic token refresh and rotation
-- **Multi-factor auth**: Support for 2FA in interactive environments
-- **Session management**: Secure session handling with timeouts
-- **Credential isolation**: Better separation between different accounts
-
-### Privacy Features
-- **Zero-knowledge proofs**: Enhanced privacy for sensitive data
-- **Secure key exchange**: Automated secure key distribution
-- **Audit logging**: Comprehensive logging with privacy controls
-- **Permission templates**: Pre-defined security levels (public, private, restricted)
-- **Digital signatures**: Message authenticity verification
-
-## üåê Transport Layer Extensions
-
-### Additional Transports
-- **Email integration**: SMTP/IMAP transport layer
-- **WebRTC**: Direct peer-to-peer in browser environments
-- **IPFS support**: Decentralized storage integration
-- **Matrix protocol**: Integration with Matrix for messaging
-- **Cloud storage**: AWS S3, Azure Blob, etc.
-
-### Transport Management
-- **Multi-transport**: Use multiple transports simultaneously
-- **Failover mechanisms**: Automatic switching between transports
-- **Transport optimization**: Choose best transport based on data type/size
-- **Bandwidth management**: Throttling and QoS controls
-
-## üë• Enhanced Friend Management
-
-### Core Improvements
-- **Friend removal**: Safe unfriending with data cleanup
-- **Request workflow**: Approval/rejection system for friend requests
-- **Friend categories**: Organize friends into groups (work, personal, etc.)
-- **Status tracking**: Online/offline status based on recent activity
-- **Metadata management**: Notes, tags, and relationship details
-
-### Advanced Features
-- **Friend discovery**: Find mutual connections
-- **Invitation system**: Send invites via email with setup instructions
-- **Relationship levels**: Different permission levels for different friends
-- **Blocked users**: Block and unblock functionality
-- **Friend analytics**: Usage statistics and interaction history
-
-## üõ†Ô∏è Developer Experience
-
-### Documentation & Testing
-- **Interactive tutorials**: Notebook-based learning materials
-- **Unit test suite**: Comprehensive testing framework
-- **Integration tests**: End-to-end workflow testing
-- **API documentation**: Detailed docstrings and examples
-- **Troubleshooting guides**: Common issues and solutions
-- **Performance benchmarks**: Speed and resource usage metrics
-
-### Development Tools
-- **Debug mode**: Verbose logging and diagnostic tools
-- **Mock backends**: Testing without real Google Drive access
-- **Configuration management**: Easy setup for different environments
-- **CLI tools**: Command-line utilities for advanced users
-- **Monitoring dashboard**: Web-based status monitoring
-
-## üìä Performance & Scalability
-
-### Optimization
-- **Caching strategies**: Smart caching for frequently accessed data
-- **Batch operations**: Reduce API calls through batching
-- **Parallel processing**: Concurrent operations where safe
-- **Memory management**: Efficient memory usage in notebooks
-- **Connection pooling**: Reuse connections for better performance
-
-### Scalability
-- **Large file handling**: Chunked uploads/downloads with resume capability
-- **High friend counts**: Efficient management of many connections
-- **Rate limiting**: Respect Google API rate limits intelligently
-- **Load balancing**: Distribute operations across multiple accounts
-- **Storage optimization**: Efficient use of Google Drive storage quotas
-
-## üé® User Interface Enhancements
-
-### Notebook UI
-- **Rich visualizations**: Beautiful displays of connection status and data flows
-- **Interactive dashboards**: Real-time monitoring widgets
-- **Drag-and-drop**: Easy file sharing through notebook interface
-- **Customizable themes**: Different visual themes for notebooks
-- **Accessibility**: Screen reader and keyboard navigation support
-
-### Workflow Improvements
-- **Setup wizards**: Step-by-step interactive setup
-- **Templates**: Pre-configured setups for common use cases
-- **Shortcuts**: Quick actions for common operations
-- **Undo/redo**: Reversible operations where possible
-- **Batch wizards**: Setup multiple friends or channels at once
-
-## üîÑ Integration & Compatibility
-
-### Ecosystem Integration
-- **Pandas integration**: Direct DataFrame sharing between friends
-- **NumPy support**: Efficient array sharing
-- **Matplotlib/Plotly**: Share visualizations and plots
-- **Scikit-learn**: Model sharing and collaborative ML
-- **TensorFlow/PyTorch**: Deep learning model collaboration
-
-### Platform Compatibility
-- **Cross-platform**: Ensure compatibility across different OS
-- **Browser support**: Better browser compatibility in Colab
-- **Mobile-friendly**: Basic mobile interface for monitoring
-- **Offline support**: Limited functionality without internet
-- **Legacy support**: Maintain compatibility with older Python versions
-
-## üìÖ Implementation Priority
-
-### Phase 1 (Quick Wins)
-1. Fix duplicate token fields bug
-2. Add progress bars for long operations
-3. Create interactive setup wizard
-4. Implement rich display for friend lists
-5. Add basic file encryption
-
-### Phase 2 (Core Features)
-1. Implement friend removal functionality
-2. Add bulk friend operations
-3. Create sync mechanism with auto-refresh
-4. Add group channel support
-5. Implement file versioning
-
-### Phase 3 (Advanced Features)
-1. Add additional transport layers
-2. Implement zero-knowledge privacy features
-3. Create comprehensive monitoring dashboard
-4. Add advanced security features
-5. Build ecosystem integrations
-
-## üí° Notes
-
-- **Notebook-First Design**: All features should work seamlessly in Jupyter/Colab
-- **Interactive Priority**: Prefer interactive widgets over command-line interfaces
-- **Memory Conscious**: Consider memory constraints in notebook environments
-- **User-Friendly**: Minimize technical complexity for end users
-- **Privacy-First**: Security and privacy should be built-in, not bolted-on
-- **Documentation Heavy**: Excellent docs are crucial for adoption
-- **Backwards Compatible**: Maintain compatibility with existing notebooks
-
----
-
-*This document should be regularly updated as the project evolves and new requirements emerge.*
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
index dc4fa1c..9f29c03 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -5,4 +5,4 @@ google-auth-httplib2
 syft-widget
 pyyaml
 watchdog
-syft-serve
\ No newline at end of file
+syft-serve>=0.2.8
\ No newline at end of file
diff --git a/syft_client/__init__.py b/syft_client/__init__.py
index 2851587..5fb6258 100644
--- a/syft_client/__init__.py
+++ b/syft_client/__init__.py
@@ -8,7 +8,7 @@ Based on the Beach RFC specifications for transport-agnostic communication.
 """
 
 from syft_client.gdrive_unified import GDriveUnifiedClient, create_gdrive_client
-from syft_client.auth import login, list_accounts, logout, add_current_credentials_to_wallet
+from syft_client.auth import login, list_accounts, logout, add_current_credentials_to_wallet, reset_credentials
 from syft_client.wizard import wizard
 from syft_client.syft_file_backed_view import SyftFileBackedView
 from syft_client.syft_message import SyftMessage
@@ -21,6 +21,7 @@ __all__ = [
     "login",
     "list_accounts",
     "logout",
+    "reset_credentials",
     "add_current_credentials_to_wallet",
     "wizard",
     "SyftFileBackedView",
diff --git a/syft_client/auth.py b/syft_client/auth.py
index e63c54c..429ad2b 100644
--- a/syft_client/auth.py
+++ b/syft_client/auth.py
@@ -3,32 +3,24 @@ Simplified authentication interface for syft_client
 """
 
 import os
-import sys
 import json
 import shutil
 import urllib.parse
-from typing import Optional, List
+import time
+from datetime import datetime
+from typing import Optional, List, Dict
 from pathlib import Path
 
 # Try importing Colab auth
-def _is_colab():
-    """Check if running in Google Colab"""
-    try:
-        import google.colab
-        return True
-    except ImportError:
-        return False
-
 try:
     from google.colab import auth as colab_auth
     from google.colab import userdata
+    IN_COLAB = True
 except ImportError:
-    colab_auth = None
-    userdata = None
+    IN_COLAB = False
 
 from .gdrive_unified import GDriveUnifiedClient, create_gdrive_client
 
-
 # Wallet helper functions (previously in credential_wallet.py)
 def _get_wallet_dir() -> Path:
     """Get the wallet directory path"""
@@ -53,29 +45,133 @@ def _get_stored_credentials_path(email: str) -> Optional[str]:
 
 
 def _get_stored_token_path(email: str) -> Optional[str]:
-    """Get the path to stored token for an email"""
+    """Get the path to the most recent valid stored token for an email"""
     account_dir = _get_account_dir(email)
-    token_path = account_dir / "token.json"
+    if not account_dir.exists():
+        return None
+    
+    # Get all token files
+    token_files = sorted([f for f in account_dir.glob("token_*.json")], reverse=True)
+    
+    # Try each token file, starting with the most recent
+    for token_file in token_files:
+        try:
+            # Extract timestamp from filename
+            filename = token_file.name
+            timestamp_str = filename.replace("token_", "").replace(".json", "")
+            
+            # Parse timestamp and check age
+            token_time = datetime.strptime(timestamp_str, "%Y%m%d_%H%M%S")
+            token_age_minutes = (datetime.now() - token_time).total_seconds() / 60
+            
+            # If token is less than 59 minutes old, assume it's still valid
+            if token_age_minutes < 59:
+                return str(token_file)
+            
+            # For older tokens, check if they can be loaded
+            with open(token_file, 'r') as f:
+                token_data = json.load(f)
+            # If we can load it, return this path
+            return str(token_file)
+        except:
+            # If token is corrupted or can't parse timestamp, continue to next one
+            continue
     
-    if token_path.exists():
-        return str(token_path)
     return None
 
 
 def _save_token(email: str, token_data: dict) -> bool:
-    """Save OAuth token to wallet"""
+    """Save OAuth token to wallet with timestamp"""
     account_dir = _get_account_dir(email)
     account_dir.mkdir(parents=True, exist_ok=True)
     
     try:
-        token_path = account_dir / "token.json"
+        # Create filename with timestamp
+        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
+        token_path = account_dir / f"token_{timestamp}.json"
+        
+        # Save the new token
         with open(token_path, 'w') as f:
             json.dump(token_data, f, indent=2)
+        
+        # Clean up old tokens - keep only the 5 most recent
+        token_files = sorted([f for f in account_dir.glob("token_*.json")], reverse=True)
+        if len(token_files) > 5:
+            for old_token in token_files[5:]:
+                try:
+                    old_token.unlink()
+                except:
+                    pass
+        
+        return True
+    except Exception as e:
+        return False
+
+
+def _update_token_timestamp(token_path: str) -> bool:
+    """Update the timestamp of a token file when it's successfully used"""
+    try:
+        # Read the token data
+        with open(token_path, 'r') as f:
+            token_data = json.load(f)
+        
+        # Get the directory and create new filename with current timestamp
+        token_file = Path(token_path)
+        account_dir = token_file.parent
+        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
+        new_path = account_dir / f"token_{timestamp}.json"
+        
+        # Save to new file
+        with open(new_path, 'w') as f:
+            json.dump(token_data, f, indent=2)
+        
+        # Remove old file if it's different
+        if str(new_path) != str(token_file):
+            token_file.unlink()
+        
+        # Clean up old tokens - keep only the 5 most recent
+        token_files = sorted([f for f in account_dir.glob("token_*.json")], reverse=True)
+        if len(token_files) > 5:
+            for old_token in token_files[5:]:
+                try:
+                    old_token.unlink()
+                except:
+                    pass
+        
         return True
     except Exception as e:
         return False
 
 
+def _list_recent_tokens(email: str) -> List[Dict[str, str]]:
+    """List recent tokens for an email with their timestamps"""
+    account_dir = _get_account_dir(email)
+    if not account_dir.exists():
+        return []
+    
+    tokens = []
+    token_files = sorted([f for f in account_dir.glob("token_*.json")], reverse=True)
+    
+    for token_file in token_files[:5]:  # Only show up to 5 most recent
+        try:
+            # Extract timestamp from filename
+            filename = token_file.name
+            timestamp_str = filename.replace("token_", "").replace(".json", "")
+            
+            # Parse timestamp
+            timestamp = datetime.strptime(timestamp_str, "%Y%m%d_%H%M%S")
+            
+            tokens.append({
+                "filename": filename,
+                "timestamp": timestamp.strftime("%Y-%m-%d %H:%M:%S"),
+                "path": str(token_file)
+            })
+        except:
+            continue
+    
+    return tokens
+
+
 def _add_to_wallet(email: str, credentials_path: str, verbose: bool = True) -> bool:
     """Add credentials to the wallet"""
     if not os.path.exists(credentials_path):
@@ -83,27 +179,6 @@ def _add_to_wallet(email: str, credentials_path: str, verbose: bool = True) -> b
             print(f"‚ùå Credentials file not found: {credentials_path}")
         return False
         
-    # Validate that the credentials file is valid JSON with required fields
-    try:
-        with open(credentials_path, 'r') as f:
-            creds_data = json.load(f)
-            
-        # Check for required OAuth2 fields
-        required_fields = ['installed', 'web']
-        if not any(field in creds_data for field in required_fields):
-            if verbose:
-                print(f"‚ùå Invalid credentials file: missing 'installed' or 'web' configuration")
-            return False
-            
-    except json.JSONDecodeError as e:
-        if verbose:
-            print(f"‚ùå Invalid JSON in credentials file: {e}")
-        return False
-    except Exception as e:
-        if verbose:
-            print(f"‚ùå Error reading credentials file: {e}")
-        return False
-        
     account_dir = _get_account_dir(email)
     account_dir.mkdir(parents=True, exist_ok=True)
     
@@ -183,19 +258,6 @@ def _get_google_console_url(email: str) -> str:
     return f"https://console.cloud.google.com/apis/credentials?authuser={encoded_email}"
 
 
-def _get_credentials_setup_url(email: str) -> str:
-    """
-    Get the credentials setup URL (alias for _get_google_console_url for backwards compatibility)
-    
-    Args:
-        email: Email address to use
-        
-    Returns:
-        URL with authuser parameter
-    """
-    return _get_google_console_url(email)
-
-
 def login(email: Optional[str] = None, credentials_path: Optional[str] = None, verbose: bool = False, force_relogin: bool = False) -> GDriveUnifiedClient:
     """
     Simple login function that checks wallet or adds new credentials
@@ -211,406 +273,64 @@ def login(email: Optional[str] = None, credentials_path: Optional[str] = None, v
     Returns:
         Authenticated GDriveUnifiedClient
     """
+    # Early validation for credentials_path
+    if credentials_path and not email:
+        raise RuntimeError("Email address is required when providing a credentials_path")
     
     # If no email provided, check wallet for accounts
     if not email:
         accounts = _list_wallet_accounts()
-        
-        if len(accounts) == 0:
+        if not accounts:
             raise RuntimeError("No accounts found in wallet. Please provide an email address.")
         elif len(accounts) == 1:
-            # Auto-select the only account
             email = accounts[0]
             if verbose:
                 print(f"üîë Auto-selecting the only account in wallet: {email}")
         else:
-            # Multiple accounts - prompt for selection
             print("\nüìã Multiple accounts found in wallet:")
             for i, account in enumerate(accounts, 1):
                 print(f"{i}. {account}")
-            
             while True:
                 try:
-                    choice = input(f"\nSelect account [1-{len(accounts)}]: ").strip()
-                    idx = int(choice) - 1
+                    idx = int(input(f"\nSelect account [1-{len(accounts)}]: ").strip()) - 1
                     if 0 <= idx < len(accounts):
                         email = accounts[idx]
                         break
-                    else:
-                        print(f"‚ùå Please enter a number between 1 and {len(accounts)}")
+                    print(f"‚ùå Please enter a number between 1 and {len(accounts)}")
                 except (ValueError, EOFError, KeyboardInterrupt):
                     print("\n‚ùå Cancelled")
                     raise RuntimeError("No account selected")
     
-    # If credentials_path is provided, skip straight to using it
+    # If credentials_path is provided, add to wallet first
     if credentials_path:
-        if not email:
-            raise RuntimeError("Email address is required when providing a credentials_path")
         path = os.path.expanduser(credentials_path)
         if not os.path.exists(path):
             raise RuntimeError(f"Credentials file not found: {path}")
-        
-        if not verbose:
-            # Use carriage return for progress updates
-            print(f"[1/4] üîê Adding credentials for {email}...", end='', flush=True)
-            if not _add_to_wallet(email, path, verbose=False):
-                print(f"\r‚ùå Failed to add credentials for {email}" + " " * 50)
-                raise RuntimeError(f"Invalid or malformed credentials file: {path}")
-            print(f"\r[2/4] üîë Logging in as {email}..." + " " * 30, end='', flush=True)
-            client = create_gdrive_client(email, verbose=False, force_relogin=force_relogin)
-            print(f"\r[3/4] üîê Checking for new inboxes..." + " " * 30, end='', flush=True)
-            # Automatically create shortcuts for shared folders
-            shortcut_results = client._create_shortcuts_for_shared_folders(verbose=False)
-            
-            # Build login message with inbox count
-            login_msg = f"\r[4/4] ‚úÖ Logged in as {client.my_email}"
-            if shortcut_results['created'] > 0:
-                login_msg += f" ({shortcut_results['created']} new inbox{'es' if shortcut_results['created'] != 1 else ''} added!)"
-            print(login_msg + " " * 50)  # Extra spaces to clear the line
-        else:
-            print(f"üîê Using provided credentials file: {path}")
-            if not _add_to_wallet(email, path, verbose=verbose):
-                raise RuntimeError(f"Invalid or malformed credentials file: {path}")
-            print(f"‚úÖ Added {email} to wallet")
-            client = create_gdrive_client(email, verbose=verbose, force_relogin=force_relogin)
-            # Automatically create shortcuts for shared folders
-            shortcut_results = client._create_shortcuts_for_shared_folders(verbose=False)
-            
-            # Build login message with inbox count
-            login_msg = f"‚úÖ Logged in as {client.my_email}"
-            if shortcut_results['created'] > 0:
-                login_msg += f" ({shortcut_results['created']} new inbox{'es' if shortcut_results['created'] != 1 else ''} added!)"
-            print(login_msg)
-        
-        return client
+        print(f"[1/3] üîê Adding credentials for {email}...", end='', flush=True)
+        _add_to_wallet(email, path, verbose=verbose)
     
-    # 1. Check if email is in wallet
+    # Common login flow for both wallet and credentials_path cases
     if _get_stored_credentials_path(email):
-        if not verbose:
-            # Use carriage return for progress updates
-            import sys
-            print(f"[1/3] üîë Logging in as {email}...", end='', flush=True)
-            client = create_gdrive_client(email, verbose=False, force_relogin=force_relogin)
-            print(f"\r[2/3] üîê Checking for new inboxes..." + " " * 30, end='', flush=True)
-            # Automatically create shortcuts for shared folders
-            shortcut_results = client._create_shortcuts_for_shared_folders(verbose=False)
-            
-            # Build login message with inbox count
-            login_msg = f"\r[3/3] ‚úÖ Logged in as {client.my_email}"
-            if shortcut_results['created'] > 0:
-                login_msg += f" ({shortcut_results['created']} new inbox{'es' if shortcut_results['created'] != 1 else ''} added!)"
-            print(login_msg + " " * 50)  # Extra spaces to clear the line
-        else:
-            # Verbose mode - show all messages
-            print(f"üîë Found stored credentials for {email}")
-            client = create_gdrive_client(email, verbose=verbose, force_relogin=force_relogin)
-            # Automatically create shortcuts for shared folders
-            shortcut_results = client._create_shortcuts_for_shared_folders(verbose=False)
-            
-            # Build login message with inbox count
-            login_msg = f"‚úÖ Logged in as {client.my_email}"
-            if shortcut_results['created'] > 0:
-                login_msg += f" ({shortcut_results['created']} new inbox{'es' if shortcut_results['created'] != 1 else ''} added!)"
-            print(login_msg)
+        steps = (["[2/3]", "[3/3]"] if credentials_path else ["[1/2]", "[2/2]"])
+        
+        print(f"\r{steps[0]} üîë Logging in as {email}..." + " " * 30, end='', flush=True)
+        client = create_gdrive_client(email, verbose=verbose, force_relogin=force_relogin)
+        
+        print(f"\r{steps[1]} ‚úÖ Logged in as {client.my_email}" + " " * 50)
         
         return client
     
-    # 2. Check if we're in Google Colab - use Colab auth
-    if _is_colab():
-        if colab_auth is None:
-            print(f"‚ùå Colab authentication not available")
-            return None
-            
-        try:
-            # Show nice Colab welcome message
-            from IPython.display import HTML, display
-            colab_welcome = f'''
-            <div style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin: 10px 0; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
-                <div style="background: white; border-radius: 8px; padding: 20px;">
-                    <h2 style="color: #1a202c; margin: 0 0 10px 0; font-family: -apple-system, system-ui, sans-serif;">
-                        üéâ Welcome to SyftClient on Google Colab!
-                    </h2>
-                    <p style="color: #4a5568; margin: 10px 0; font-size: 16px;">
-                        Authenticating as: <strong style="color: #667eea;">{email}</strong>
-                    </p>
-                    <div style="background: #f7fafc; border-left: 4px solid #667eea; padding: 10px; margin: 15px 0; border-radius: 4px;">
-                        <p style="color: #2d3748; margin: 0; font-size: 14px;">
-                            ‚ú® Colab provides seamless Google Drive integration<br>
-                            üîê Using your Colab session's Google account<br>
-                            üìÅ Your SyftBox will be created automatically
-                        </p>
-                    </div>
-                    <p style="color: #718096; font-size: 12px; margin-top: 15px; margin-bottom: 0;">
-                        <em>Note: You may see an authentication popup if this is your first time.</em>
-                    </p>
-                </div>
-            </div>
-            '''
-            display(HTML(colab_welcome))
-            
-            # Authenticate with Colab
-            colab_auth.authenticate_user()
-            
-            # Create client with Colab auth method
-            client = GDriveUnifiedClient(email=email, auth_method="colab", verbose=False)
-            if client.authenticate():
-                # Show success message
-                success_html = f'''
-                <div style="padding: 15px; background: #f0fdf4; border-left: 4px solid #10b981; border-radius: 4px; margin: 10px 0;">
-                    <div style="display: flex; align-items: center;">
-                        <span style="font-size: 24px; margin-right: 10px;">‚úÖ</span>
-                        <div>
-                            <p style="color: #065f46; font-weight: 600; margin: 0;">
-                                Successfully authenticated as {client.my_email}
-                            </p>
-                            <p style="color: #047857; font-size: 14px; margin: 5px 0 0 0;">
-                                Your SyftBox is ready in Google Drive
-                            </p>
-                        </div>
-                    </div>
-                </div>
-                '''
-                display(HTML(success_html))
-                
-                # Check if the authenticated email matches requested email
-                if client.my_email != email:
-                    warning_html = f'''
-                    <div style="padding: 10px; background: #fef3c7; border-left: 4px solid #f59e0b; border-radius: 4px; margin: 10px 0;">
-                        <p style="color: #92400e; margin: 0; font-size: 14px;">
-                            ‚ö†Ô∏è Note: Authenticated as <strong>{client.my_email}</strong> instead of {email}<br>
-                            <span style="font-size: 12px;">Google Colab uses your logged-in Google account</span>
-                        </p>
-                    </div>
-                    '''
-                    display(HTML(warning_html))
-                
-                # Automatically create shortcuts for shared folders
-                shortcut_results = client._create_shortcuts_for_shared_folders(verbose=False)
-                if shortcut_results['created'] > 0:
-                    inbox_html = f'''
-                    <div style="padding: 10px; background: #ede9fe; border-left: 4px solid #8b5cf6; border-radius: 4px; margin: 10px 0;">
-                        <p style="color: #5b21b6; margin: 0; font-size: 14px;">
-                            üì• Added {shortcut_results['created']} new inbox{'es' if shortcut_results['created'] != 1 else ''}!
-                        </p>
-                    </div>
-                    '''
-                    display(HTML(inbox_html))
-                
-                return client
-            else:
-                error_html = '''
-                <div style="padding: 15px; background: #fef2f2; border-left: 4px solid #ef4444; border-radius: 4px; margin: 10px 0;">
-                    <p style="color: #991b1b; font-weight: 600; margin: 0;">
-                        ‚ùå Failed to authenticate with Google Colab
-                    </p>
-                    <p style="color: #b91c1c; font-size: 14px; margin: 5px 0 0 0;">
-                        Please try again or check your Google account permissions
-                    </p>
-                </div>
-                '''
-                display(HTML(error_html))
-                return None
-        except Exception as e:
-            error_html = f'''
-            <div style="padding: 15px; background: #fef2f2; border-left: 4px solid #ef4444; border-radius: 4px; margin: 10px 0;">
-                <p style="color: #991b1b; font-weight: 600; margin: 0;">
-                    ‚ùå Colab authentication error
-                </p>
-                <p style="color: #b91c1c; font-size: 14px; margin: 5px 0 0 0;">
-                    {str(e)}
-                </p>
-            </div>
-            '''
-            display(HTML(error_html))
-            return None
-    
-    # 3. Not in wallet and not in Colab - show wizard if in Jupyter
-    # Check if we're in a Jupyter notebook
+    # Not in wallet - try wizard if in IPython
     try:
         from IPython import get_ipython
         if get_ipython() is not None:
-            # We're in IPython/Jupyter - show the wizard
             from .wizard import wizard
-            print(f"‚ùå No credentials found for {email}")
-            print(f"Run syft_client.wizard() or print your client object to create credentials")
-            wizard()  # Call wizard directly, it will display itself
-            return None
+            print(f"‚ùå No credentials found for {email}\nRun syft_client.wizard() or print your client object to create credentials")
+            return wizard(email=email)
     except ImportError:
         pass
-    
-    # If not in Jupyter or verbose=False, show minimal message
-    if verbose:
-        print(f"‚ùå No credentials found for {email} in wallet")
-    
-    # Check if we're in a CI/non-interactive environment
-    is_ci = os.environ.get('CI') or os.environ.get('GITHUB_ACTIONS') or not sys.stdin.isatty()
-    if is_ci:
-        raise RuntimeError(f"No credentials found for {email} and running in non-interactive mode (CI={os.environ.get('CI')}, GITHUB_ACTIONS={os.environ.get('GITHUB_ACTIONS')}). "
-                         f"Please provide credentials or add them to the wallet first.")
-    
-    # Terminal fallback
-    print("\nüîß Let's set up Google Drive access for this account")
-    print("Choose an option:")
-    print("1. I have a credentials.json file")
-    print("2. I need to create a new Google Cloud project")
-    print("3. Exit")
-    
-    try:
-        # Double-check we're not in CI before trying to read input
-        if os.environ.get('CI') or os.environ.get('GITHUB_ACTIONS'):
-            print("‚ùå Cancelled")
-            raise RuntimeError(f"Cannot prompt for input in CI environment")
-        choice = input("\nYour choice [1-3]: ").strip()
-        
-        if choice == "1":
-            # Existing flow - add credentials
-            path = input("\nEnter path to credentials.json: ").strip()
-            if not path:
-                print("‚ùå No path provided")
-                raise RuntimeError(f"No credentials available for {email}")
-            
-            # Expand path
-            path = os.path.expanduser(path)
-            
-            if os.path.exists(path):
-                _add_to_wallet(email, path, verbose=verbose)
-                if verbose:
-                    print(f"‚úÖ Added {email} to wallet")
-                client = create_gdrive_client(email, verbose=verbose)
-                # Automatically create shortcuts for shared folders
-                shortcut_results = client._create_shortcuts_for_shared_folders(verbose=False)
-                
-                # Build login message with inbox count
-                login_msg = f"‚úÖ Logged in as {client.my_email}"
-                if shortcut_results['created'] > 0:
-                    login_msg += f" ({shortcut_results['created']} new inbox{'es' if shortcut_results['created'] != 1 else ''} added!)"
-                print(login_msg)
-                
-                return client
-            else:
-                print(f"‚ùå File not found: {path}")
-                raise RuntimeError(f"Could not find credentials at {path}")
-                
-        elif choice == "2":
-            # New wizard for creating project
-            print("\nüìã Google Cloud Project Setup Wizard")
-            print("=" * 50)
-            print(f"\nWe'll set up a Google Cloud project for {email}")
-            print("This is a one-time setup that takes about 5 minutes.\n")
-            
-            print("üìù Step 1: Create a Google Cloud Project")
-            print("-" * 40)
-            print(f"1. Open: https://console.cloud.google.com/projectcreate?authuser={email}")
-            print("2. Enter a project name (e.g., 'syftbox-drive')")
-            print("3. Click 'CREATE'")
-            print("4. Wait for the project to be created")
-            input("\nPress Enter when done...")
-            
-            print("\nüìù Step 2: Enable Google Drive API")
-            print("-" * 40)
-            print(f"1. Open: https://console.cloud.google.com/apis/library/drive.googleapis.com?authuser={email}")
-            print("2. Click 'ENABLE'")
-            print("3. Wait for it to enable")
-            input("\nPress Enter when done...")
-            
-            print("\nüìù Step 3: Configure OAuth Consent Screen")
-            print("-" * 40)
-            print(f"1. Open: https://console.cloud.google.com/apis/credentials/consent?authuser={email}")
-            print("2. Choose User Type:")
-            print("   - If you have a Google Workspace domain: Choose 'Internal'")
-            print("   - For personal Gmail accounts: Choose 'External'")
-            print("3. Click 'CREATE'")
-            print("\n4. Fill in the required fields:")
-            print("   - App name: SyftBox Drive (or any name)")
-            print("   - User support email: (select your email)")
-            print("   - Developer contact: (your email)")
-            print("5. Click 'SAVE AND CONTINUE'")
-            print("\n6. On Scopes page: Click 'SAVE AND CONTINUE'")
-            print("\n7. On Test users page:")
-            print(f"   - Click 'ADD USERS'")
-            print(f"   - Add: {email}")
-            print("   - Click 'SAVE AND CONTINUE'")
-            print("\n8. Review and click 'BACK TO DASHBOARD'")
-            input("\nPress Enter when done...")
-            
-            print("\nüìù Step 4: Create OAuth 2.0 Credentials")
-            print("-" * 40)
-            print(f"1. Open: https://console.cloud.google.com/apis/credentials?authuser={email}")
-            print("2. Click '+ CREATE CREDENTIALS' ‚Üí 'OAuth client ID'")
-            print("3. Application type: 'Desktop app'")
-            print("4. Name: 'SyftBox Client' (or any name)")
-            print("5. Click 'CREATE'")
-            print("6. Click 'DOWNLOAD JSON' on the popup")
-            print("7. Save the file as 'credentials.json'")
-            input("\nPress Enter when done...")
-            
-            print("\n‚úÖ Setup complete! Now let's add your credentials.")
-            
-            # Try common download locations
-            common_paths = [
-                "~/Downloads/credentials.json",
-                "~/Downloads/client_secret*.json",
-                "./credentials.json"
-            ]
-            
-            found_path = None
-            for p in common_paths:
-                expanded = os.path.expanduser(p)
-                import glob
-                matches = glob.glob(expanded)
-                if matches:
-                    found_path = matches[0]
-                    break
-            
-            if found_path:
-                print(f"\nüîç Found credentials at: {found_path}")
-                use_it = input("Use this file? [Y/n]: ").strip().lower()
-                if use_it in ['', 'y', 'yes']:
-                    wallet.add_credentials(email, found_path, verbose=verbose)
-                    if verbose:
-                        print(f"‚úÖ Added {email} to wallet")
-                    client = create_gdrive_client(email, verbose=verbose)
-                    # Automatically create shortcuts for shared folders
-                    shortcut_results = client._create_shortcuts_for_shared_folders(verbose=False)
-                    
-                    # Build login message with inbox count
-                    login_msg = f"‚úÖ Logged in as {client.my_email}"
-                    if shortcut_results['created'] > 0:
-                        login_msg += f" ({shortcut_results['created']} new inbox{'es' if shortcut_results['created'] != 1 else ''} added!)"
-                    print(login_msg)
-                    
-                    return client
-            
-            # Manual path entry
-            path = input("\nEnter path to downloaded credentials.json: ").strip()
-            if path:
-                path = os.path.expanduser(path)
-                if os.path.exists(path):
-                    _add_to_wallet(email, path, verbose=verbose)
-                    if verbose:
-                        print(f"‚úÖ Added {email} to wallet")
-                    client = create_gdrive_client(email, verbose=verbose)
-                    # Automatically create shortcuts for shared folders
-                    shortcut_results = client._create_shortcuts_for_shared_folders(verbose=False)
-                    
-                    # Build login message with inbox count
-                    login_msg = f"‚úÖ Logged in as {client.my_email}"
-                    if shortcut_results['created'] > 0:
-                        login_msg += f" ({shortcut_results['created']} new inbox{'es' if shortcut_results['created'] != 1 else ''} added!)"
-                    print(login_msg)
-                    
-                    return client
-                else:
-                    print(f"‚ùå File not found: {path}")
-                    
-        else:
-            print("\nüëã Exiting...")
-            raise RuntimeError(f"Setup cancelled")
-            
-    except (EOFError, KeyboardInterrupt):
-        print("\n‚ùå Cancelled")
-        raise RuntimeError(f"No credentials available for {email}")
-    
+    print("\n‚ùå Cancelled")
+    raise RuntimeError(f"No credentials available for {email}")
 
 def list_accounts() -> list:
     """
@@ -621,7 +341,7 @@ def list_accounts() -> list:
     """
     accounts = _list_wallet_accounts()
     
-    if _is_colab():
+    if IN_COLAB:
         # Also check if we can get Colab user
         try:
             from googleapiclient.discovery import build
@@ -683,21 +403,87 @@ def add_current_credentials_to_wallet() -> Optional[str]:
         return None
 
 
+def reset_credentials(email: str):
+    """
+    Clear all cached credentials for an account to force re-authentication
+    
+    This is useful when you need to get new credentials with additional scopes
+    (e.g., adding Google Sheets access)
+    
+    Args:
+        email: Email address to reset credentials for
+    """
+    if not email:
+        print("‚ùå Please specify an email to reset credentials for")
+        return
+    
+    # Clear all tokens for the account
+    account_dir = _get_account_dir(email)
+    if account_dir.exists():
+        token_count = 0
+        for token_file in account_dir.glob("token_*.json"):
+            try:
+                token_file.unlink()
+                token_count += 1
+            except:
+                pass
+        if token_count > 0:
+            print(f"üóëÔ∏è  Cleared {token_count} cached token(s) for {email}")
+            print(f"üìù Please re-authenticate to get new credentials:")
+            print(f"   client = login('{email}', force_relogin=True)")
+        else:
+            print(f"üìÅ No cached tokens found for {email}")
+    else:
+        print(f"üìÅ No account found for {email}")
+
+
 def logout(email: Optional[str] = None, clear_tokens_only: bool = True):
     """
     Logout from an account (remove from wallet)
     
     Args:
         email: Email to logout from
-        clear_tokens_only: Deprecated - only full removal is supported now
+        clear_tokens_only: If True, only clear tokens. If False, remove entire account
     """
     if not email:
         print("‚ùå Please specify an email to logout")
-        return False
+        return
         
-    if not clear_tokens_only:
-        # Remove entire account
-        return _remove_from_wallet(email)
+    if clear_tokens_only:
+        # Clear all tokens for the account
+        account_dir = _get_account_dir(email)
+        if account_dir.exists():
+            token_count = 0
+            for token_file in account_dir.glob("token_*.json"):
+                try:
+                    token_file.unlink()
+                    token_count += 1
+                except:
+                    pass
+            if token_count > 0:
+                print(f"üóëÔ∏è  Cleared {token_count} cached token{'s' if token_count != 1 else ''} for {email}")
+            else:
+                print(f"üìÅ No cached tokens found for {email}")
+        else:
+            print(f"üìÅ No account found for {email}")
     else:
-        print("‚ÑπÔ∏è  Token caching is disabled. Use logout(email, clear_tokens_only=False) to remove account from wallet.")
-        return True
\ No newline at end of file
+        # Remove entire account
+        _remove_from_wallet(email)
+
+
+def list_recent_tokens(email: str) -> None:
+    """
+    List recent cached tokens for an email
+    
+    Args:
+        email: Email address to check tokens for
+    """
+    tokens = _list_recent_tokens(email)
+    
+    if not tokens:
+        print(f"üìÅ No cached tokens found for {email}")
+        return
+    
+    print(f"\nüîë Recent tokens for {email}:")
+    for i, token in enumerate(tokens, 1):
+        print(f"{i}. {token['timestamp']} - {token['filename']}")
\ No newline at end of file
diff --git a/syft_client/gdrive_unified.py b/syft_client/gdrive_unified.py
index de4a745..45c4c72 100644
--- a/syft_client/gdrive_unified.py
+++ b/syft_client/gdrive_unified.py
@@ -5,6 +5,13 @@ Unified Google Drive client with multiple authentication methods
 import os
 import json
 import io
+import tarfile
+import tempfile
+import shutil
+import threading
+import yaml
+import time
+from datetime import datetime
 from pathlib import Path
 from typing import Optional, List, Dict, Union
 
@@ -35,7 +42,7 @@ class GDriveUnifiedClient:
     with high-level API for file operations and permissions
     """
     
-    SCOPES = ['https://www.googleapis.com/auth/drive']
+    SCOPES = ['https://www.googleapis.com/auth/drive', 'https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/forms.body']
     
     def __init__(self, auth_method: str = "auto", credentials_file: str = "credentials.json", 
                  email: Optional[str] = None, verbose: bool = True, force_relogin: bool = False):
@@ -58,47 +65,38 @@ class GDriveUnifiedClient:
         self.verbose = verbose
         self.force_relogin = force_relogin
         self.local_syftbox_dir = None
+        self._syftbox_folder_id = None  # Cache for SyftBoxTransportService folder ID
+        self._folder_cache = {}  # General cache for folder paths to IDs
+        self._friends_cache = None  # Cache for friends list
+        self._friends_cache_time = None  # Timestamp for friends cache
+        self.creds = None  # Store credentials for background threads
+        self._sheets_service = None  # Cache for Google Sheets service
+        self._sheet_cache = {}  # Cache for sheet lookups
+        self._sheet_cache_time = {}  # Timestamps for sheet cache entries
+        self._spreadsheet_info_cache = {}  # Cache for spreadsheet properties
+        self._spreadsheet_info_cache_time = {}  # Timestamps for spreadsheet info cache
+        self._metadata_cache = {}  # Cache for parsed message metadata
+        self._path_cache = {}  # Cache for string paths
+        self._dir_structure = set()  # Pre-created directories
+        self._form_inbox_metadata = None  # Lazy-loaded form inbox metadata
+        self._form_inbox_prepared = False  # Whether we've prepared the form for submission
         
     def __repr__(self) -> str:
         """Pretty representation of the client"""
         if not self.authenticated:
-            return f"<GDriveUnifiedClient(not authenticated)>"
+            return f"<GDriveUnifiedClient(not authenticated) - run .wizard() to create credentials>"
         
         # Get SyftBox info
         syftbox_info = "not created"
+        syftbox_id = None
         try:
-            results = self.service.files().list(
-                q="name='SyftBoxTransportService' and mimeType='application/vnd.google-apps.folder' and 'root' in parents and trashed=false",
-                fields="files(id)"
-            ).execute()
-            if results.get('files'):
+            # Use cached lookup
+            syftbox_id = self._get_syftbox_folder_id()
+            if syftbox_id:
                 syftbox_info = "‚úì created"
         except:
             pass
         
-        # Count communication channels
-        channel_count = 0
-        if syftbox_info == "‚úì created":
-            try:
-                # Search for syft_ folders
-                results = self.service.files().list(
-                    q="name contains 'syft_' and mimeType='application/vnd.google-apps.folder' and trashed=false",
-                    fields="files(name)"
-                ).execute()
-                
-                # Count unique channels (outgoing only)
-                channels = set()
-                for file in results.get('files', []):
-                    name = file['name']
-                    if name.startswith('syft_') and '_to_' in name and (name.endswith('_pending') or name.endswith('_outbox_inbox')):
-                        # Extract channel identifier
-                        parts = name.split('_to_')
-                        if len(parts) == 2:
-                            channel = parts[1].rsplit('_', 1)[0]  # Remove suffix
-                            channels.add(channel)
-                channel_count = len(channels)
-            except:
-                pass
         
         auth_method = "wallet" if self.target_email else self.auth_method
         
@@ -106,8 +104,7 @@ class GDriveUnifiedClient:
             f"<GDriveUnifiedClient(\n"
             f"  email='{self.my_email}',\n"
             f"  auth_method='{auth_method}',\n"
-            f"  syftbox={syftbox_info},\n"
-            f"  channels={channel_count}\n"
+            f"  syftbox={syftbox_info}\n"
             f")>"
         )
     
@@ -118,6 +115,12 @@ class GDriveUnifiedClient:
             <div style="border: 1px solid #ddd; padding: 10px; margin: 10px 0; border-radius: 5px; background-color: #f9f9f9;">
                 <h3 style="margin-top: 0;">üîê GDriveUnifiedClient</h3>
                 <p style="color: #666;"><em>Not authenticated</em></p>
+                <p style="margin-top: 10px;">
+                    <code style="background: #f0f0f0; padding: 2px 5px; border-radius: 3px;">
+                        client.wizard()
+                    </code> 
+                    to create credentials
+                </p>
             </div>
             """
         
@@ -125,41 +128,13 @@ class GDriveUnifiedClient:
         syftbox_id = None
         syftbox_status = "‚ùå Not created"
         try:
-            results = self.service.files().list(
-                q="name='SyftBoxTransportService' and mimeType='application/vnd.google-apps.folder' and 'root' in parents and trashed=false",
-                fields="files(id)"
-            ).execute()
-            if results.get('files'):
-                syftbox_id = results['files'][0]['id']
+            # Use cached lookup
+            syftbox_id = self._get_syftbox_folder_id()
+            if syftbox_id:
                 syftbox_status = "‚úÖ Created"
         except:
             pass
         
-        # Count communication channels
-        channel_count = 0
-        channel_list = []
-        if syftbox_id:
-            try:
-                # Search for syft_ folders
-                results = self.service.files().list(
-                    q="name contains 'syft_' and mimeType='application/vnd.google-apps.folder' and trashed=false",
-                    fields="files(name)"
-                ).execute()
-                
-                # Count unique channels (outgoing only)
-                channels = set()
-                for file in results.get('files', []):
-                    name = file['name']
-                    if name.startswith('syft_') and '_to_' in name and (name.endswith('_pending') or name.endswith('_outbox_inbox')):
-                        # Extract channel identifier
-                        parts = name.split('_to_')
-                        if len(parts) == 2:
-                            channel = parts[1].rsplit('_', 1)[0]  # Remove suffix
-                            channels.add(channel)
-                channel_count = len(channels)
-                channel_list = sorted(list(channels))
-            except:
-                pass
         
         auth_method = "wallet" if self.target_email else self.auth_method
         
@@ -204,32 +179,13 @@ class GDriveUnifiedClient:
                 </tr>
             """
         
-        html += f"""
-                <tr>
-                    <td style="padding: 5px 10px 5px 0; font-weight: bold; color: #555;">Channels:</td>
-                    <td style="padding: 5px;">{channel_count} active</td>
-                </tr>
+        html += """
             </table>
-        """
-        
-        if channel_list:
-            html += """
-            <details style="margin-top: 10px;">
-                <summary style="cursor: pointer; color: #1a73e8;">Show channels</summary>
-                <ul style="margin: 5px 0; padding-left: 20px;">
-            """
-            for channel in channel_list:
-                html += f"<li style='color: #666;'>{channel}</li>"
-            html += """
-                </ul>
-            </details>
-            """
-        
-        html += "</div>"
+        </div>"""
         
         return html
         
-    def authenticate(self) -> bool:
+    def authenticate(self, known_email: Optional[str] = None) -> bool:
         """
         Authenticate using the appropriate method
         
@@ -254,8 +210,9 @@ class GDriveUnifiedClient:
                 return self._auth_credentials()
             else:
                 if self.verbose:
-                    print(f"‚ùå No stored credentials found for {self.target_email}")
-                    print(f"   Use login('{self.target_email}', 'path/to/credentials.json')")
+                    if self.verbose:
+                        print(f"‚ùå No stored credentials found for {self.target_email}")
+                        print(f"   Use login('{self.target_email}', 'path/to/credentials.json')")
                 return False
         
         if self.auth_method == "auto":
@@ -266,9 +223,10 @@ class GDriveUnifiedClient:
                 return self._auth_credentials()
             else:
                 if self.verbose:
-                    print("‚ùå No authentication method available")
-                    print("   - Not in Google Colab")
-                    print(f"   - No {self.credentials_file} found")
+                    if self.verbose:
+                        print("‚ùå No authentication method available")
+                        print("   - Not in Google Colab")
+                        print(f"   - No {self.credentials_file} found")
                 return False
                 
         elif self.auth_method == "credentials":
@@ -276,24 +234,28 @@ class GDriveUnifiedClient:
             
         else:
             if self.verbose:
-                print(f"‚ùå Unknown auth method: {self.auth_method}")
+                if self.verbose:
+                    print(f"‚ùå Unknown auth method: {self.auth_method}")
             return False
     
     def _auth_colab(self) -> bool:
         """Authenticate using Google Colab"""
         try:
             if self.verbose:
-                print("üîê Authenticating with Google Colab...")
+                if self.verbose:
+                    print("üîê Authenticating with Google Colab...")
             colab_auth.authenticate_user()
             self.service = build('drive', 'v3')
             self.authenticated = True
             self._get_my_email()
             if self.verbose:
-                print("‚úÖ Authenticated via Google Colab")
+                if self.verbose:
+                    print("‚úÖ Authenticated via Google Colab")
             return True
         except Exception as e:
             if self.verbose:
-                print(f"‚ùå Colab authentication failed: {e}")
+                if self.verbose:
+                    print(f"‚ùå Colab authentication failed: {e}")
             return False
     
     def _auth_credentials(self) -> bool:
@@ -301,33 +263,60 @@ class GDriveUnifiedClient:
         try:
             if self.verbose:
                 if self.target_email:
-                    print(f"üîê Authenticating as {self.target_email}...")
+                    if self.verbose:
+                        print(f"üîê Authenticating as {self.target_email}...")
                 else:
-                    print("üîê Authenticating with credentials.json...")
+                    if self.verbose:
+                        print("üîê Authenticating with credentials.json...")
 
             creds = None
             
             # Check if force_relogin is set
             if self.force_relogin and self.verbose:
-                print("üîÑ Force relogin requested - ignoring cached token")
+                if self.verbose:
+                    print("üîÑ Force relogin requested - ignoring cached token")
             
             # First, try to load cached token if we have a target email and not forcing relogin
             if self.target_email and not self.force_relogin:
-                from .auth import _get_stored_token_path, _save_token
+                from .auth import _get_stored_token_path, _save_token, _update_token_timestamp
                 token_path = _get_stored_token_path(self.target_email)
                 
                 if token_path and os.path.exists(token_path):
                     try:
+                        # Check token age from filename
+                        from pathlib import Path
+                        from datetime import datetime
+                        
+                        filename = Path(token_path).name
+                        timestamp_str = filename.replace("token_", "").replace(".json", "")
+                        token_time = datetime.strptime(timestamp_str, "%Y%m%d_%H%M%S")
+                        token_age_minutes = (datetime.now() - token_time).total_seconds() / 60
+                        
                         with open(token_path, 'r') as token:
                             token_data = json.load(token)
                         creds = Credentials.from_authorized_user_info(token_data, self.SCOPES)
                         
-                        # Check if token needs refresh
+                        # Skip refresh check if token is less than 59 minutes old
+                        if token_age_minutes < 59:
+                            if self.verbose:
+                                if self.verbose:
+                                    print(f"‚úÖ Using cached authentication token (created {int(token_age_minutes)} minutes ago)")
+                            self.service = build('drive', 'v3', credentials=creds)
+                            self.creds = creds  # Store for background threads
+                            self.authenticated = True
+                            self._get_my_email(known_email=self.target_email)
+                            # Don't update timestamp for very recent tokens
+                            if token_age_minutes > 30:
+                                _update_token_timestamp(token_path)
+                            return True
+                        
+                        # For older tokens, check if they need refresh
                         if creds and creds.expired and creds.refresh_token:
                             if self.verbose:
-                                print("üîÑ Refreshing expired token...")
+                                if self.verbose:
+                                    print("üîÑ Refreshing expired token...")
                             creds.refresh(Request())
-                            # Save the refreshed token
+                            # Save the refreshed token as a new file
                             _save_token(self.target_email, {
                                 'type': 'authorized_user',
                                 'client_id': creds.client_id,
@@ -340,20 +329,26 @@ class GDriveUnifiedClient:
                         
                         if creds and creds.valid:
                             if self.verbose:
-                                print("‚úÖ Using cached authentication token")
+                                if self.verbose:
+                                    print("‚úÖ Using cached authentication token")
                             self.service = build('drive', 'v3', credentials=creds)
+                            self.creds = creds  # Store for background threads
                             self.authenticated = True
                             self._get_my_email()
+                            # Update the token timestamp since it was successfully used
+                            _update_token_timestamp(token_path)
                             return True
                     except Exception as e:
                         if self.verbose:
-                            print(f"‚ö†Ô∏è  Could not use cached token: {e}")
+                            if self.verbose:
+                                print(f"‚ö†Ô∏è  Could not use cached token: {e}")
                         creds = None
             
             # If no valid cached token, do the full OAuth flow
             if not os.path.exists(self.credentials_file):
                 if self.verbose:
-                    print(f"‚ùå {self.credentials_file} not found")
+                    if self.verbose:
+                        print(f"‚ùå {self.credentials_file} not found")
                 return False
                 
             flow = InstalledAppFlow.from_client_secrets_file(
@@ -361,9 +356,10 @@ class GDriveUnifiedClient:
             
             # Run the OAuth flow
             if self.verbose:
-                print(f"\nüåê Opening browser for authentication...")
-                if self.target_email:
-                    print(f"   üìß Please select or sign in as: {self.target_email}")
+                if self.verbose:
+                    print(f"\nüåê Opening browser for authentication...")
+                    if self.target_email:
+                        print(f"   üìß Please select or sign in as: {self.target_email}")
                     print(f"   ‚ö†Ô∏è  Make sure to choose the correct account!")
             
             # Configure messages based on verbose setting
@@ -382,6 +378,7 @@ class GDriveUnifiedClient:
             )
             
             self.service = build('drive', 'v3', credentials=creds)
+            self.creds = creds  # Store for background threads
             self.authenticated = True
             self._get_my_email()
             
@@ -419,464 +416,1072 @@ class GDriveUnifiedClient:
     
     def _ensure_authenticated(self):
         """Ensure client is authenticated before operations"""
+        # print("ENSUREAUTH-1 " + str(time.time()))
         if not self.authenticated:
             raise RuntimeError("Client not authenticated. Call authenticate() first.")
+        # print("ENSUREAUTH-2 " + str(time.time()))
     
-    def _get_my_email(self):
-        """Get the authenticated user's email address"""
+    def wizard(self):
+        """
+        Launch the credential creation wizard.
+        This helps users create new Google Cloud credentials step by step.
+        """
         try:
-            about = self.service.about().get(fields="user(emailAddress)").execute()
-            self.my_email = about['user']['emailAddress']
+            from .wizard import wizard
+            # Pass the target email if available, otherwise use authenticated email
+            email = self.target_email or self.my_email
+            return wizard(email=email)
+        except ImportError as e:
+            print(f"‚ùå Could not import wizard: {e}")
+            return None
+    
+    @property
+    def form_inbox_metadata(self) -> Dict[str, any]:
+        """
+        Lazy property that returns the SyftBox Inbox Form metadata.
+        Creates the form if it doesn't exist.
+        
+        Returns:
+            Dict with form metadata including URLs and entry mappings
+        """
+        if self._form_inbox_metadata is None:
+            self._ensure_authenticated()
+            
+            # First, try to find an existing form with the expected name
             if self.verbose:
-                print(f"üë§ Authenticated as: {self.my_email}")
+                print("üîç Looking for existing SyftBox Inbox Form...")
             
-            # Create local SyftBox directory after successful authentication
-            self._create_local_syftbox_directory()
+            forms = self.list_forms(query="SyftBox Inbox Form", limit=50)
             
-        except Exception as e:
-            if self.verbose:
-                print(f"‚ö†Ô∏è  Could not get email address: {e}")
-            self.my_email = None
-    
-    def _create_local_syftbox_directory(self):
-        """Create the local SyftBox directory structure"""
-        if not self.my_email:
-            return
+            # Look for exact match
+            existing_form = None
+            for form in forms:
+                if form['name'] == "SyftBox Inbox Form":
+                    existing_form = form
+                    break
             
-        # Create ~/SyftBox_{email} directory
-        home_dir = Path.home()
-        syftbox_dir = home_dir / f"SyftBox_{self.my_email}"
-        
-        if not syftbox_dir.exists():
-            try:
-                syftbox_dir.mkdir(exist_ok=True)
+            if existing_form:
                 if self.verbose:
-                    print(f"üìÅ Created local SyftBox directory: {syftbox_dir}")
+                    print(f"‚úÖ Found existing form: {existing_form['name']}")
+                    print(f"üìã Form ID: {existing_form['id']}")
                 
-                # Create subdirectories
-                subdirs = ["datasites", "apps"]
-                for subdir in subdirs:
-                    (syftbox_dir / subdir).mkdir(exist_ok=True)
+                # Store basic metadata
+                self._form_inbox_metadata = {
+                    'form_id': existing_form['id'],
+                    'form_url': f"https://docs.google.com/forms/d/e/{existing_form['id']}/viewform",
+                    'form_edit_url': existing_form['edit_url'],
+                    'created_at': existing_form.get('created', ''),
+                    'existing': True
+                }
+                
+                # Try to make it public if not already
+                public_url = self.make_form_public(existing_form['id'])
+                if public_url and public_url != False:
+                    self._form_inbox_metadata['form_url'] = public_url
                     
-            except Exception as e:
+            else:
+                # Create a new form - but override the title
                 if self.verbose:
-                    print(f"‚ö†Ô∏è  Could not create SyftBox directory: {e}")
-        else:
-            if self.verbose:
-                print(f"üìÅ Using existing SyftBox directory: {syftbox_dir}")
+                    print("üìù Creating new SyftBox Inbox Form...")
                 
-        # Store the path for later use
-        self.local_syftbox_dir = syftbox_dir
+                try:
+                    # Temporarily patch the create method to use our title
+                    original_form_title = f"SyftBox Inbox [{datetime.now().strftime('%Y-%m-%d %H:%M')}]"
+                    
+                    # We need to modify create_google_form_inbox to accept a title parameter
+                    # For now, we'll create it with the default title and rename if possible
+                    result = self.create_public_google_form_inbox()
+                    
+                    # Update the form title if possible using Drive API
+                    try:
+                        self.service.files().update(
+                            fileId=result['form_id'],
+                            body={'name': 'SyftBox Inbox Form'}
+                        ).execute()
+                        if self.verbose:
+                            print("‚úÖ Renamed form to 'SyftBox Inbox Form'")
+                    except:
+                        pass
+                    
+                    # Store the metadata
+                    self._form_inbox_metadata = result
+                    self._form_inbox_metadata['existing'] = False
+                    
+                    if self.verbose:
+                        print(f"‚úÖ Created new form successfully")
+                        print(f"üìã Form URL: {result['form_url']}")
+                        
+                except HttpError as e:
+                    # Check for project access error first
+                    if "403" in str(e) and ("project" in str(e).lower() or "686245239599" in str(e)):
+                        error_msg = (
+                            "\n‚ùå Forms API access error - your credentials were created with a different Google Cloud project.\n"
+                            "\n"
+                            "To fix this, you need to create new credentials:\n"
+                            "1. Complete the wizard that just launched (or run: syft_client.wizard())\n"
+                            "2. Follow the step-by-step guide to create new credentials\n"
+                            "3. Re-authenticate: client = syft_client.login('your-email@gmail.com', '/path/to/credentials.json')\n"
+                            "4. Clear cache: client.clear_form_inbox_cache()\n"
+                            "5. Try again: client.form_inbox_metadata\n"
+                            "\n"
+                            "Alternative: Manually create a form and use client.set_form_inbox_url(form_url)"
+                        )
+                        
+                        # Store error metadata
+                        self._form_inbox_metadata = {
+                            'error': 'Forms API project access error',
+                            'message': error_msg,
+                            'solution': 'Run syft_client.wizard() to create new credentials'
+                        }
+                        
+                        if self.verbose:
+                            print(error_msg)
+                        
+                        # Try to import and show wizard
+                        try:
+                            from IPython import get_ipython
+                            if get_ipython() is not None:
+                                from .wizard import wizard
+                                if self.verbose:
+                                    print("\nüßô Launching credential wizard...")
+                                email = self.target_email or self.my_email
+                                wizard(email=email)
+                        except:
+                            pass
+                    
+                    elif "SERVICE_DISABLED" in str(e) or "forms.googleapis.com" in str(e):
+                        # Extract the activation URL from the error
+                        import re
+                        activation_url_match = re.search(r'https://console\.developers\.google\.com/apis/api/forms\.googleapis\.com/overview\?project=\d+', str(e))
+                        activation_url = activation_url_match.group(0) if activation_url_match else "https://console.developers.google.com/apis/api/forms.googleapis.com"
+                        
+                        error_msg = (
+                            "\n‚ùå Google Forms API is not enabled for your account.\n"
+                            "   \n"
+                            "   To enable it:\n"
+                            f"   1. Visit: {activation_url}\n"
+                            "   2. Click 'Enable API'\n"
+                            "   3. Wait a few minutes for it to activate\n"
+                            "   4. Try again\n"
+                            "   \n"
+                            "   Note: You only need to do this once per Google account."
+                        )
+                        
+                        # Store error metadata
+                        self._form_inbox_metadata = {
+                            'error': 'Forms API not enabled',
+                            'activation_url': activation_url,
+                            'message': error_msg
+                        }
+                        
+                        if self.verbose:
+                            print(error_msg)
+                        
+                    else:
+                        # Some other error
+                        self._form_inbox_metadata = {
+                            'error': str(e),
+                            'message': f"Failed to create form: {str(e)[:200]}..."
+                        }
+                        if self.verbose:
+                            print(f"‚ùå Failed to create form: {e}")
+                
+                except Exception as e:
+                    # Generic error handling
+                    self._form_inbox_metadata = {
+                        'error': str(e),
+                        'message': f"Unexpected error: {str(e)[:200]}..."
+                    }
+                    if self.verbose:
+                        print(f"‚ùå Unexpected error creating form: {e}")
+        
+        # If we haven't prepared the form submission metadata yet, do it now
+        if not self._form_inbox_prepared and 'form_url' in self._form_inbox_metadata:
+            try:
+                # Prepare the form for fast submission
+                prep_metadata = self.prepare_form_submission(
+                    self._form_inbox_metadata['form_url'], 
+                    debug=False
+                )
+                if 'error' not in prep_metadata:
+                    # Merge the preparation metadata
+                    self._form_inbox_metadata.update(prep_metadata)
+                    self._form_inbox_prepared = True
+                    if self.verbose:
+                        print("‚úÖ Form prepared for fast submission")
+            except Exception as e:
+                if self.verbose:
+                    print(f"‚ö†Ô∏è  Could not prepare form for submission: {e}")
+        
+        return self._form_inbox_metadata
     
-    def get_syftbox_directory(self) -> Optional[Path]:
-        """Get the local SyftBox directory path"""
-        if self.local_syftbox_dir:
-            return self.local_syftbox_dir
-        elif self.my_email:
-            # Calculate the path even if not created yet
-            return Path.home() / f"SyftBox_{self.my_email}"
-        return None
+    def has_forms_api_error(self) -> bool:
+        """
+        Check if there's a Forms API error in the form inbox metadata.
+        
+        Returns:
+            True if there's a Forms API error, False otherwise
+        """
+        if self._form_inbox_metadata and 'error' in self._form_inbox_metadata:
+            error = self._form_inbox_metadata.get('error', '')
+            return 'Forms API' in error or 'project access' in error.lower()
+        return False
     
-    # ========== File Operations ==========
+    def clear_form_inbox_cache(self):
+        """Clear the cached form inbox metadata to force recreation."""
+        self._form_inbox_metadata = None
+        self._form_inbox_prepared = False
+        if self.verbose:
+            print("üóëÔ∏è  Cleared form inbox cache")
     
-    def _create_folder(self, name: str, parent_id: str = 'root') -> Optional[str]:
+    def set_form_inbox_url(self, form_url: str, prepare: bool = True) -> Dict[str, any]:
         """
-        Create a folder
+        Manually set the form inbox URL. Useful when Forms API is not available.
         
         Args:
-            name: Folder name
-            parent_id: Parent folder ID (default: root)
+            form_url: The Google Form URL to use
+            prepare: Whether to prepare the form for fast submission
             
         Returns:
-            Folder ID if successful, None otherwise
+            The form metadata
         """
-        self._ensure_authenticated()
+        import re
         
-        try:
-            file_metadata = {
-                'name': name,
-                'mimeType': 'application/vnd.google-apps.folder',
-                'parents': [parent_id]
-            }
-            
-            folder = self.service.files().create(
-                body=file_metadata,
-                fields='id'
-            ).execute()
+        # Extract form ID
+        form_id_match = re.search(r'/forms/d/(?:e/)?([a-zA-Z0-9_-]+)/', form_url)
+        if not form_id_match:
+            raise ValueError(f"Invalid form URL: {form_url}")
             
-            folder_id = folder.get('id')
-            if self.verbose:
-                print(f"‚úÖ Created folder '{name}' (ID: {folder_id})")
-            return folder_id
+        form_id = form_id_match.group(1)
+        
+        # Set the metadata
+        self._form_inbox_metadata = {
+            'form_id': form_id,
+            'form_url': form_url,
+            'form_edit_url': f"https://docs.google.com/forms/d/{form_id}/edit",
+            'manually_set': True,
+            'existing': True
+        }
+        
+        if prepare:
+            try:
+                # Prepare the form for fast submission
+                prep_metadata = self.prepare_form_submission(form_url, debug=False)
+                if 'error' not in prep_metadata:
+                    self._form_inbox_metadata.update(prep_metadata)
+                    self._form_inbox_prepared = True
+                    if self.verbose:
+                        print("‚úÖ Form prepared for fast submission")
+            except Exception as e:
+                if self.verbose:
+                    print(f"‚ö†Ô∏è  Could not prepare form: {e}")
+        
+        if self.verbose:
+            print(f"‚úÖ Form inbox URL set manually")
+            print(f"üìã Form URL: {form_url}")
             
-        except HttpError as e:
-            if self.verbose:
-                print(f"‚ùå Error creating folder: {e}")
-            return None
+        return self._form_inbox_metadata
     
-    def _folder_exists(self, name: str, parent_id: str = 'root') -> bool:
+    def _get_sheets_service(self):
+        """Get or create cached Google Sheets service"""
+        # print("GETSHEETS-1 " + str(time.time()))
+        self._ensure_authenticated()
+        # print("GETSHEETS-2 " + str(time.time()))
+        if self._sheets_service is None:
+            # print("GETSHEETS-3 " + str(time.time()))
+            self._sheets_service = build('sheets', 'v4', credentials=self.creds)
+            # print("GETSHEETS-4 " + str(time.time()))
+        # print("GETSHEETS-5 " + str(time.time()))
+        return self._sheets_service
+    
+    def _get_syftbox_folder_id(self, use_cache: bool = True) -> Optional[str]:
         """
-        Check if a folder exists
+        Get the SyftBoxTransportService folder ID, using cache if available
         
         Args:
-            name: Folder name to check
-            parent_id: Parent folder ID (default: root)
+            use_cache: Whether to use cached value if available
             
         Returns:
-            True if folder exists, False otherwise
+            Folder ID if found, None otherwise
         """
+        # print("GETFOLDERID-1 " + str(time.time()))
         self._ensure_authenticated()
+        # print("GETFOLDERID-2 " + str(time.time()))
+        
+        # Return cached value if available and cache is enabled
+        if use_cache and self._syftbox_folder_id:
+            # print("GETFOLDERID-3 " + str(time.time()))
+            return self._syftbox_folder_id
         
         try:
+            # Search for SyftBoxTransportService folder
+            # print("GETFOLDERID-4 " + str(time.time()))
             results = self.service.files().list(
-                q=f"name='{name}' and mimeType='application/vnd.google-apps.folder' and '{parent_id}' in parents and trashed=false",
-                fields="files(id,name)"
+                q="name='SyftBoxTransportService' and mimeType='application/vnd.google-apps.folder' and 'root' in parents and trashed=false",
+                fields="files(id)"
             ).execute()
+            # print("GETFOLDERID-5 " + str(time.time()))
             
-            return len(results.get('files', [])) > 0
+            syftbox_folders = results.get('files', [])
             
-        except HttpError as e:
+            if syftbox_folders:
+                # Cache and return the first folder ID
+                self._syftbox_folder_id = syftbox_folders[0]['id']
+                # print("GETFOLDERID-6 " + str(time.time()))
+                return self._syftbox_folder_id
+            
+            # Clear cache if folder not found
+            self._syftbox_folder_id = None
+            # print("GETFOLDERID-7 " + str(time.time()))
+            return None
+            
+        except Exception as e:
             if self.verbose:
-                print(f"‚ùå Error checking folder existence: {e}")
-            return False
+                print(f"‚ùå Error getting SyftBox folder ID: {e}")
+            return None
     
-    def _share_folder_with_email(self, folder_id: str, email: str) -> bool:
+    def _clear_syftbox_cache(self):
+        """Clear the cached SyftBox folder ID"""
+        self._syftbox_folder_id = None
+    
+    def _clear_sheet_cache(self):
+        """Clear the cached sheet lookups"""
+        self._sheet_cache = {}
+        self._sheet_cache_time = {}
+        self._spreadsheet_info_cache = {}
+        self._spreadsheet_info_cache_time = {}
+    
+    def _get_folder_id(self, folder_name: str, parent_id: str = 'root', use_cache: bool = True) -> Optional[str]:
         """
-        Share a folder with a specific email address
+        Get folder ID by name and parent, using cache if available
         
         Args:
-            folder_id: Google Drive folder ID to share
-            email: Email address to share with
+            folder_name: Name of the folder
+            parent_id: Parent folder ID (default: 'root')
+            use_cache: Whether to use cached value if available
             
         Returns:
-            True if sharing successful, False otherwise
+            Folder ID if found, None otherwise
         """
         self._ensure_authenticated()
         
+        # Create cache key from folder path
+        cache_key = f"{parent_id}/{folder_name}"
+        
+        # Return cached value if available and cache is enabled
+        if use_cache and cache_key in self._folder_cache:
+            return self._folder_cache[cache_key]
+        
         try:
-            permission = {
-                'type': 'user',
-                'role': 'writer',
-                'emailAddress': email
-            }
-            
-            self.service.files().permissions().create(
-                fileId=folder_id,
-                body=permission
+            # Query for the folder
+            results = self.service.files().list(
+                q=f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and '{parent_id}' in parents and trashed=false",
+                fields="files(id)"
             ).execute()
             
-            if self.verbose:
-                print(f"‚úÖ Shared folder {folder_id} with {email}")
-            return True
+            folders = results.get('files', [])
+            
+            if folders:
+                # Cache and return the first folder ID
+                folder_id = folders[0]['id']
+                self._folder_cache[cache_key] = folder_id
+                return folder_id
+            
+            # Clear cache entry if folder not found
+            if cache_key in self._folder_cache:
+                del self._folder_cache[cache_key]
+            return None
             
         except Exception as e:
+            # On error, invalidate cache entry
+            if cache_key in self._folder_cache:
+                del self._folder_cache[cache_key]
             if self.verbose:
-                print(f"‚ùå Error sharing folder: {e}")
-            return False
+                print(f"‚ùå Error getting folder ID for {folder_name}: {e}")
+            return None
     
-    def _upload_file(self, local_path: str, name: str = None, 
-                    parent_id: str = 'root', mimetype: str = 'text/plain') -> Optional[str]:
+    def _invalidate_folder_cache(self, folder_name: Optional[str] = None, parent_id: Optional[str] = None):
         """
-        Upload a file
+        Invalidate folder cache entries
         
         Args:
-            local_path: Path to local file
-            name: Name in Drive (default: use local filename)
-            parent_id: Parent folder ID (default: root)
-            mimetype: MIME type of file
-            
-        Returns:
-            File ID if successful, None otherwise
+            folder_name: Specific folder name to invalidate (optional)
+            parent_id: Specific parent ID to invalidate (optional)
+            If both are None, clears entire cache
         """
-        self._ensure_authenticated()
-        
-        if not os.path.exists(local_path):
-            print(f"‚ùå Local file not found: {local_path}")
-            return None
-            
-        if name is None:
-            name = os.path.basename(local_path)
+        if folder_name is None and parent_id is None:
+            # Clear entire cache
+            self._folder_cache.clear()
+        elif folder_name and parent_id:
+            # Clear specific entry
+            cache_key = f"{parent_id}/{folder_name}"
+            if cache_key in self._folder_cache:
+                del self._folder_cache[cache_key]
+        elif parent_id:
+            # Clear all entries under a parent
+            keys_to_delete = [k for k in self._folder_cache.keys() if k.startswith(f"{parent_id}/")]
+            for key in keys_to_delete:
+                del self._folder_cache[key]
+    
+    def _set_folder_cache(self, folder_name: str, folder_id: str, parent_id: str = 'root'):
+        """
+        Set a folder cache entry
+        
+        Args:
+            folder_name: Name of the folder
+            folder_id: ID of the folder
+            parent_id: Parent folder ID (default: 'root')
+        """
+        cache_key = f"{parent_id}/{folder_name}"
+        self._folder_cache[cache_key] = folder_id
+    
+    def _invalidate_friends_cache(self):
+        """
+        Invalidate the friends cache to force a refresh on next access
+        """
+        self._friends_cache = None
+        self._friends_cache_time = None
+    
+    def reset_credentials(self):
+        """
+        Clear all cached credentials to force re-authentication with new scopes
+        """
+        if not self.my_email:
+            print("‚ùå Not authenticated - no credentials to reset")
+            return False
         
         try:
-            file_metadata = {
-                'name': name,
-                'parents': [parent_id]
-            }
-            
-            media = MediaIoBaseUpload(
-                io.FileIO(local_path, 'rb'),
-                mimetype=mimetype
-            )
-            
-            file = self.service.files().create(
-                body=file_metadata,
-                media_body=media,
-                fields='id'
-            ).execute()
+            # Import the auth module functions
+            from .auth import _get_account_dir
             
-            file_id = file.get('id')
-            print(f"‚úÖ Uploaded '{name}' (ID: {file_id})")
-            return file_id
+            # Get the account directory
+            account_dir = _get_account_dir(self.my_email)
             
-        except HttpError as e:
-            print(f"‚ùå Error uploading file: {e}")
-            return None
+            if account_dir.exists():
+                # Remove all token files
+                token_count = 0
+                for token_file in account_dir.glob("token_*.json"):
+                    try:
+                        token_file.unlink()
+                        token_count += 1
+                    except:
+                        pass
+                
+                print(f"üóëÔ∏è  Cleared {token_count} cached token(s) for {self.my_email}")
+                print(f"üìù Please re-authenticate to get new credentials with Sheets access:")
+                print(f"   client = login('{self.my_email}', force_relogin=True)")
+                
+                # Clear the current authentication
+                self.authenticated = False
+                self.service = None
+                self.creds = None
+                
+                return True
+            else:
+                print(f"üìÅ No credentials found for {self.my_email}")
+                return False
+                
+        except Exception as e:
+            print(f"‚ùå Error resetting credentials: {e}")
+            return False
     
-    def _upload_folder_recursive(self, local_folder_path: str, parent_id: str, folder_name: str = None) -> bool:
+    def _archive_message_async(self, msg_file_id: str, archive_id: str, inbox_folder_id: str, msg_id: str, archive_name: str):
         """
-        Recursively upload a folder and its contents to Google Drive
+        Archive a message in a background thread
         
         Args:
-            local_folder_path: Path to local folder
-            parent_id: Parent folder ID in Google Drive
-            folder_name: Name for the folder in Drive (default: use local folder name)
-            
-        Returns:
-            True if successful, False otherwise
+            msg_file_id: File ID of the message to archive
+            archive_id: ID of the archive folder
+            inbox_folder_id: ID of the inbox folder (to remove from)
+            msg_id: Message ID for logging
+            archive_name: Archive folder name for logging
         """
-        self._ensure_authenticated()
+        try:
+            # Note: We need to create a new service instance for thread safety
+            # The Google API client is not thread-safe
+            if hasattr(self, 'creds') and self.creds:
+                from googleapiclient.discovery import build
+                service = build('drive', 'v3', credentials=self.creds)
+                
+                result = service.files().update(
+                    fileId=msg_file_id,
+                    addParents=archive_id,
+                    removeParents=inbox_folder_id,
+                    fields='id, parents',
+                    supportsAllDrives=True
+                ).execute()
+                
+                if self.verbose:
+                    print(f"   ‚úÖ [Background] Archived {msg_id} to {archive_name}")
+            else:
+                if self.verbose:
+                    print(f"   ‚ö†Ô∏è  [Background] Could not archive {msg_id} - no credentials")
+        except Exception as e:
+            if self.verbose:
+                print(f"   ‚ö†Ô∏è  [Background] Failed to archive {msg_id}: {str(e)[:100]}")
+    
+    def get_cache_stats(self) -> Dict[str, int]:
+        """
+        Get cache statistics
         
-        if not os.path.isdir(local_folder_path):
-            print(f"‚ùå Not a directory: {local_folder_path}")
-            return False
-            
-        if folder_name is None:
-            folder_name = os.path.basename(local_folder_path)
+        Returns:
+            Dictionary with cache statistics
+        """
+        friends_cache_age = None
+        if self._friends_cache_time:
+            friends_cache_age = int(time.time() - self._friends_cache_time)
         
+        return {
+            'folder_cache_entries': len(self._folder_cache),
+            'syftbox_cached': 1 if self._syftbox_folder_id else 0,
+            'friends_cached': len(self._friends_cache) if self._friends_cache else 0,
+            'friends_cache_age_seconds': friends_cache_age,
+            'total_cached_items': len(self._folder_cache) + (1 if self._syftbox_folder_id else 0) + (len(self._friends_cache) if self._friends_cache else 0)
+        }
+    
+    def _get_my_email(self, known_email: Optional[str] = None):
+        """Get the authenticated user's email address"""
+        if known_email:
+            self.my_email = known_email
+            return
+
         try:
-            # Create the folder in Google Drive
-            folder_metadata = {
-                'name': folder_name,
-                'mimeType': 'application/vnd.google-apps.folder',
-                'parents': [parent_id]
-            }
+            about = self.service.about().get(fields="user(emailAddress)").execute()
+            self.my_email = about['user']['emailAddress']
+            if self.verbose:
+                print(f"üë§ Authenticated as: {self.my_email}")
             
-            folder = self.service.files().create(
-                body=folder_metadata,
-                fields='id'
-            ).execute()
+            # Create local SyftBox directory after successful authentication
+            self._create_local_syftbox_directory()
             
-            folder_id = folder.get('id')
+        except Exception as e:
             if self.verbose:
-                print(f"   üìÅ Created folder: {folder_name}")
-            
-            # Separate files into regular files and lock files
-            regular_files = []
-            lock_files = []
-            subdirectories = []
+                print(f"‚ö†Ô∏è  Could not get email address: {e}")
+            self.my_email = None
+    
+    def _create_local_syftbox_directory(self):
+        """Create the local SyftBox directory structure"""
+        if not self.my_email:
+            return
             
-            for item in os.listdir(local_folder_path):
-                item_path = os.path.join(local_folder_path, item)
+        # Create ~/SyftBox_{email} directory
+        home_dir = Path.home()
+        syftbox_dir = home_dir / f"SyftBox_{self.my_email}"
+        
+        if not syftbox_dir.exists():
+            try:
+                syftbox_dir.mkdir(exist_ok=True)
+                if self.verbose:
+                    print(f"üìÅ Created local SyftBox directory: {syftbox_dir}")
                 
-                if os.path.isfile(item_path):
-                    # Categorize lock files to upload last
-                    if item in ['lock.json', '.write_lock']:
-                        lock_files.append((item, item_path))
-                    else:
-                        regular_files.append((item, item_path))
-                elif os.path.isdir(item_path):
-                    subdirectories.append((item, item_path))
-            
-            # Upload subdirectories first
-            for item, item_path in subdirectories:
-                success = self._upload_folder_recursive(
-                    local_folder_path=item_path,
-                    parent_id=folder_id,
-                    folder_name=item
-                )
-                if not success:
-                    print(f"   ‚ö†Ô∏è  Failed to upload folder: {item}")
-            
-            # Upload regular files
-            for item, item_path in regular_files:
-                file_id = self._upload_file(
-                    local_path=item_path,
-                    name=item,
-                    parent_id=folder_id,
-                    mimetype='application/octet-stream'
-                )
-                if not file_id:
-                    print(f"   ‚ö†Ô∏è  Failed to upload file: {item}")
-            
-            # Upload lock files last (with lock.json being the very last)
-            # First upload .write_lock if it exists
-            for item, item_path in lock_files:
-                if item == '.write_lock':
-                    file_id = self._upload_file(
-                        local_path=item_path,
-                        name=item,
-                        parent_id=folder_id,
-                        mimetype='application/octet-stream'
-                    )
-                    if not file_id:
-                        print(f"   ‚ö†Ô∏è  Failed to upload file: {item}")
-            
-            # Finally upload lock.json
-            for item, item_path in lock_files:
-                if item == 'lock.json':
-                    file_id = self._upload_file(
-                        local_path=item_path,
-                        name=item,
-                        parent_id=folder_id,
-                        mimetype='application/octet-stream'
-                    )
-                    if not file_id:
-                        print(f"   ‚ö†Ô∏è  Failed to upload file: {item}")
-                    elif self.verbose:
-                        print(f"   üîí Uploaded lock file last: {item}")
-            
-            return True
+                # Create subdirectories
+                subdirs = ["datasites", "apps"]
+                for subdir in subdirs:
+                    (syftbox_dir / subdir).mkdir(exist_ok=True)
+                    
+            except Exception as e:
+                if self.verbose:
+                    print(f"‚ö†Ô∏è  Could not create SyftBox directory: {e}")
+        else:
+            if self.verbose:
+                print(f"üìÅ Using existing SyftBox directory: {syftbox_dir}")
+                
+        # Store the path for later use
+        self.local_syftbox_dir = syftbox_dir
+    
+    def get_syftbox_directory(self) -> Optional[Path]:
+        """Get the local SyftBox directory path"""
+        # print("GETSYFTBOXDIR-1 " + str(time.time()))
+        if self.local_syftbox_dir:
+            # print("GETSYFTBOXDIR-2 " + str(time.time()))
+            return self.local_syftbox_dir
+        elif self.my_email:
+            # Calculate the path even if not created yet
+            # print("GETSYFTBOXDIR-3 " + str(time.time()))
+            return Path.home() / f"SyftBox_{self.my_email}"
+        # print("GETSYFTBOXDIR-4 " + str(time.time()))
+        return None
+    
+    def resolve_syft_path(self, path: str) -> str:
+        """
+        Resolve a syft:// URL to a full file path
+        
+        Supports:
+        - syft://filename.txt -> /path/to/SyftBox_email/datasites/filename.txt
+        - syft://folder/filename.txt -> /path/to/SyftBox_email/datasites/folder/filename.txt
+        - Regular paths are returned unchanged
+        
+        Args:
+            path: Path that may start with syft://
             
-        except Exception as e:
-            print(f"‚ùå Error uploading folder: {e}")
-            return False
+        Returns:
+            Resolved full path
+        """
+        if not path.startswith("syft://"):
+            # Not a syft URL, return as-is
+            return path
+        
+        # Get SyftBox directory
+        syftbox_dir = self.get_syftbox_directory()
+        if not syftbox_dir:
+            raise ValueError("Could not determine SyftBox directory")
+        
+        # Extract the relative path after syft://
+        relative_path = path[7:]  # Remove "syft://"
+        
+        # Build the full path (always in datasites)
+        full_path = syftbox_dir / "datasites" / relative_path
+        
+        return str(full_path)
     
-    def _download_file(self, file_id: str, local_path: str) -> bool:
+    # ========== File Operations ==========
+    
+    def _create_folder(self, name: str, parent_id: str = 'root') -> Optional[str]:
         """
-        Download a file
+        Create a folder
         
         Args:
-            file_id: Google Drive file ID
-            local_path: Where to save the file
+            name: Folder name
+            parent_id: Parent folder ID (default: root)
             
         Returns:
-            True if successful
+            Folder ID if successful, None otherwise
         """
         self._ensure_authenticated()
         
         try:
-            request = self.service.files().get_media(fileId=file_id)
+            file_metadata = {
+                'name': name,
+                'mimeType': 'application/vnd.google-apps.folder',
+                'parents': [parent_id]
+            }
             
-            with io.FileIO(local_path, 'wb') as fh:
-                downloader = MediaIoBaseDownload(fh, request)
-                done = False
-                while not done:
-                    status, done = downloader.next_chunk()
-                    if status:
-                        print(f"Download progress: {int(status.progress() * 100)}%")
+            folder = self.service.files().create(
+                body=file_metadata,
+                fields='id'
+            ).execute()
             
-            print(f"‚úÖ Downloaded to '{local_path}'")
-            return True
+            folder_id = folder.get('id')
+            if folder_id:
+                # Cache the newly created folder
+                self._set_folder_cache(name, folder_id, parent_id)
+            if self.verbose:
+                print(f"‚úÖ Created folder '{name}' (ID: {folder_id})")
+            return folder_id
             
         except HttpError as e:
-            print(f"‚ùå Error downloading file: {e}")
-            return False
+            if self.verbose:
+                print(f"‚ùå Error creating folder: {e}")
+            return None
     
-    def _get_permissions(self, file_id: str) -> List[Dict]:
+    def _folder_exists(self, name: str, parent_id: str = 'root') -> bool:
         """
-        Get all permissions for a file/folder
+        Check if a folder exists
         
         Args:
-            file_id: Google Drive file/folder ID
+            name: Folder name to check
+            parent_id: Parent folder ID (default: root)
             
         Returns:
-            List of permission dictionaries
+            True if folder exists, False otherwise
         """
         self._ensure_authenticated()
         
         try:
-            permissions = self.service.permissions().list(
-                fileId=file_id,
-                fields="permissions(id, type, role, emailAddress)"
+            results = self.service.files().list(
+                q=f"name='{name}' and mimeType='application/vnd.google-apps.folder' and '{parent_id}' in parents and trashed=false",
+                fields="files(id,name)"
             ).execute()
             
-            return permissions.get('permissions', [])
+            return len(results.get('files', [])) > 0
             
         except HttpError as e:
-            print(f"‚ùå Error getting permissions: {e}")
-            return []
+            if self.verbose:
+                print(f"‚ùå Error checking folder existence: {e}")
+            return False
     
-    def _add_permission(self, file_id: str, email: str, role: str = 'reader', verbose: bool = True) -> bool:
+    def _share_folder_with_email(self, folder_id: str, email: str) -> bool:
         """
-        Add permission for a user
+        Share a folder with a specific email address
         
         Args:
-            file_id: Google Drive file/folder ID
-            email: User's email address
-            role: 'reader', 'writer', or 'owner'
-            verbose: Whether to print status messages (default: True)
+            folder_id: Google Drive folder ID to share
+            email: Email address to share with
             
         Returns:
-            True if successful
+            True if sharing successful, False otherwise
         """
         self._ensure_authenticated()
         
-        if role not in ['reader', 'writer', 'owner']:
-            print(f"‚ùå Invalid role: {role}")
-            return False
-        
         try:
             permission = {
                 'type': 'user',
-                'role': role,
+                'role': 'writer',
                 'emailAddress': email
             }
             
-            self.service.permissions().create(
-                fileId=file_id,
-                body=permission,
-                sendNotificationEmail=False
+            self.service.files().permissions().create(
+                fileId=folder_id,
+                body=permission
             ).execute()
             
-            if verbose:
-                print(f"‚úÖ Added {role} permission for {email}")
+            if self.verbose:
+                print(f"‚úÖ Shared folder {folder_id} with {email}")
             return True
             
-        except HttpError as e:
-            print(f"‚ùå Error adding permission: {e}")
+        except Exception as e:
+            if self.verbose:
+                print(f"‚ùå Error sharing folder: {e}")
             return False
     
-    def delete_syftbox(self) -> bool:
+    def _upload_file(self, local_path: str, name: str = None, 
+                    parent_id: str = 'root', mimetype: str = 'text/plain') -> Optional[str]:
         """
-        Delete the SyftBoxTransportService folder and all its contents
+        Upload a file
         
-        Returns:
-            True if successful
+        Args:
+            local_path: Path to local file
+            name: Name in Drive (default: use local filename)
+            parent_id: Parent folder ID (default: root)
+            mimetype: MIME type of file
+            
+        Returns:
+            File ID if successful, None otherwise
         """
+        
         self._ensure_authenticated()
         
-        if self.verbose:
-            print("üóëÔ∏è  Deleting SyftBoxTransportService...")
+        if not os.path.exists(local_path):
+            print(f"‚ùå Local file not found: {local_path}")
+            return None
+        
+        if name is None:
+            name = os.path.basename(local_path)
         
         try:
-            # Search for SyftBoxTransportService folder(s) in root
-            results = self.service.files().list(
-                q="name='SyftBoxTransportService' and mimeType='application/vnd.google-apps.folder' and 'root' in parents and trashed=false",
-                fields="files(id, name)"
+            file_metadata = {
+                'name': name,
+                'parents': [parent_id]
+            }
+            
+            media = MediaIoBaseUpload(
+                io.FileIO(local_path, 'rb'),
+                mimetype=mimetype,
+                resumable=True  # Enable resumable uploads for large files
+            )
+            
+            file = self.service.files().create(
+                body=file_metadata,
+                media_body=media,
+                fields='id'
             ).execute()
             
-            syftbox_folders = results.get('files', [])
+            file_id = file.get('id')
+            if self.verbose:
+                print(f"‚úÖ Uploaded '{name}' (ID: {file_id})")
+            return file_id
+            print("8")
+        except HttpError as e:
+            print(f"‚ùå Error uploading file: {e}")
+            return None
+    
+    def _upload_folder_as_archive(self, local_folder_path: str, parent_id: str, folder_name: str = None) -> Optional[str]:
+        """
+        Upload a folder as a compressed archive to Google Drive
+        
+        Args:
+            local_folder_path: Path to local folder
+            parent_id: Parent folder ID in Google Drive
+            folder_name: Name for the archive in Drive (default: use local folder name + .tar.gz)
+            
+        Returns:
+            File ID if successful, None otherwise
+        """
+        self._ensure_authenticated()
+        
+        if not os.path.isdir(local_folder_path):
+            print(f"‚ùå Not a directory: {local_folder_path}")
+            return None
+            
+        if folder_name is None:
+            folder_name = os.path.basename(local_folder_path)
+        
+        try:
+            # Create a temporary tar.gz file
+            with tempfile.NamedTemporaryFile(suffix='.tar.gz', delete=False) as tmp_file:
+                tmp_path = tmp_file.name
+                
+            # Create the tar.gz archive
+            if self.verbose:
+                print(f"   üì¶ Creating archive for {folder_name}...")
+            
+            with tarfile.open(tmp_path, 'w:gz') as tar:
+                # Add the entire folder to the archive
+                tar.add(local_folder_path, arcname=folder_name)
+            
+            # Get file size for progress reporting
+            file_size = os.path.getsize(tmp_path)
+            if self.verbose:
+                size_mb = file_size / (1024 * 1024)
+                print(f"   üì¶ Archive size: {size_mb:.1f} MB")
+            
+            # Upload the archive as a single file
+            archive_name = f"{folder_name}.tar.gz"
+            if self.verbose:
+                print(f"   üì§ Uploading {archive_name}...")
+            
+            file_id = self._upload_file(
+                local_path=tmp_path,
+                name=archive_name,
+                parent_id=parent_id,
+                mimetype='application/gzip'
+            )
+            
+            # Clean up temporary file
+            try:
+                os.unlink(tmp_path)
+            except:
+                pass
+            
+            if file_id and self.verbose:
+                print(f"   ‚úÖ Uploaded folder as {archive_name}")
+            
+            return file_id
+            
+        except Exception as e:
+            print(f"‚ùå Error creating/uploading archive: {e}")
+            # Clean up temporary file on error
+            try:
+                if 'tmp_path' in locals():
+                    os.unlink(tmp_path)
+            except:
+                pass
+            return None
+    def _download_archive_and_extract(self, file_id: str, local_parent: str, extract_name: str = None) -> bool:
+        """
+        Download a tar.gz archive and extract it
+        
+        Args:
+            file_id: Google Drive file ID of the archive
+            local_parent: Parent directory to extract into
+            extract_name: Name for the extracted folder (optional)
+            
+        Returns:
+            True if successful
+        """
+        self._ensure_authenticated()
+        
+        try:
+            # Create a temporary file for the archive
+            with tempfile.NamedTemporaryFile(suffix='.tar.gz', delete=False) as tmp_file:
+                tmp_path = tmp_file.name
+            
+            # Download the archive file
+            if self.verbose:
+                print(f"      üì• Downloading tar.gz file...")
+            
+            request = self.service.files().get_media(fileId=file_id)
+            with io.FileIO(tmp_path, 'wb') as fh:
+                downloader = MediaIoBaseDownload(fh, request)
+                done = False
+                while not done:
+                    status, done = downloader.next_chunk()
+                    if status and self.verbose:
+                        print(f"      üìä Download progress: {int(status.progress() * 100)}%")
+            
+            # Extract the archive
+            if self.verbose:
+                print(f"      üì¶ Extracting files...")
+            
+            with tarfile.open(tmp_path, 'r:gz') as tar:
+                # If extract_name is provided, extract to that specific folder
+                if extract_name:
+                    # Get the first member to find the archive's root folder
+                    members = tar.getmembers()
+                    if members:
+                        # Find the common prefix (root folder in archive)
+                        root_folder = members[0].name.split('/')[0]
+                        
+                        # Extract to a temporary location first
+                        with tempfile.TemporaryDirectory() as temp_dir:
+                            tar.extractall(temp_dir)
+                            
+                            # Move the extracted folder to the desired location with new name
+                            src_path = os.path.join(temp_dir, root_folder)
+                            dst_path = os.path.join(local_parent, extract_name)
+                            
+                            # Remove destination if it exists
+                            if os.path.exists(dst_path):
+                                shutil.rmtree(dst_path)
+                            
+                            # Move to final location
+                            shutil.move(src_path, dst_path)
+                else:
+                    # Extract directly to parent directory
+                    tar.extractall(local_parent)
+            
+            # Clean up temporary file
+            try:
+                os.unlink(tmp_path)
+            except:
+                pass
+            
+            if self.verbose:
+                print(f"      ‚úÖ Extraction complete")
+            
+            return True
+            
+        except Exception as e:
+            print(f"‚ùå Error downloading/extracting archive: {e}")
+            # Clean up temporary file on error
+            try:
+                if 'tmp_path' in locals():
+                    os.unlink(tmp_path)
+            except:
+                pass
+            return False
+    
+    def _download_file(self, file_id: str, local_path: str) -> bool:
+        """
+        Download a file
+        
+        Args:
+            file_id: Google Drive file ID
+            local_path: Where to save the file
+            
+        Returns:
+            True if successful
+        """
+        self._ensure_authenticated()
+        
+        try:
+            request = self.service.files().get_media(fileId=file_id)
+            
+            with io.FileIO(local_path, 'wb') as fh:
+                downloader = MediaIoBaseDownload(fh, request)
+                done = False
+                while not done:
+                    status, done = downloader.next_chunk()
+                    if status and self.verbose:
+                        print(f"Download progress: {int(status.progress() * 100)}%")
+            if self.verbose:
+                print(f"‚úÖ Downloaded to '{local_path}'")
+            return True
+            
+        except HttpError as e:
+            print(f"‚ùå Error downloading file: {e}")
+            return False
+    
+    def _get_permissions(self, file_id: str) -> List[Dict]:
+        """
+        Get all permissions for a file/folder
+        
+        Args:
+            file_id: Google Drive file/folder ID
+            
+        Returns:
+            List of permission dictionaries
+        """
+        self._ensure_authenticated()
+        
+        try:
+            permissions = self.service.permissions().list(
+                fileId=file_id,
+                fields="permissions(id, type, role, emailAddress)"
+            ).execute()
+            
+            return permissions.get('permissions', [])
+            
+        except HttpError as e:
+            print(f"‚ùå Error getting permissions: {e}")
+            return []
+    
+    def _add_permission(self, file_id: str, email: str, role: str = 'reader', verbose: bool = True) -> bool:
+        """
+        Add permission for a user
+        
+        Args:
+            file_id: Google Drive file/folder ID
+            email: User's email address
+            role: 'reader', 'writer', or 'owner'
+            verbose: Whether to print status messages (default: True)
+            
+        Returns:
+            True if successful
+        """
+        # print("ADDPERM-1 " + str(time.time()))
+        self._ensure_authenticated()
+        # print("ADDPERM-2 " + str(time.time()))
+        
+        if role not in ['reader', 'writer', 'owner']:
+            print(f"‚ùå Invalid role: {role}")
+            return False
+        
+        try:
+            # print("ADDPERM-3 " + str(time.time()))
+            permission = {
+                'type': 'user',
+                'role': role,
+                'emailAddress': email
+            }
+            
+            # print("ADDPERM-4 " + str(time.time()))
+            self.service.permissions().create(
+                fileId=file_id,
+                body=permission,
+                sendNotificationEmail=False
+            ).execute()
+            # print("ADDPERM-5 " + str(time.time()))
+            
+            if verbose:
+                print(f"‚úÖ Added {role} permission for {email}")
+            # print("ADDPERM-6 " + str(time.time()))
+            return True
+            
+        except HttpError as e:
+            print(f"‚ùå Error adding permission: {e}")
+            return False
+    
+    def delete_syftbox(self) -> bool:
+        """
+        Delete the SyftBoxTransportService folder and all its contents
+        
+        Returns:
+            True if successful
+        """
+        self._ensure_authenticated()
+        
+        if self.verbose:
+            print("üóëÔ∏è  Deleting SyftBoxTransportService...")
+        
+        try:
+            # Get folder ID using cache
+            folder_id = self._get_syftbox_folder_id()
             
-            if not syftbox_folders:
+            if not folder_id:
                 if self.verbose:
                     print("üìÅ No SyftBoxTransportService folder found to delete")
                 return True
             
-            # Delete all SyftBox folders found
-            deleted_count = 0
-            for folder in syftbox_folders:
-                folder_id = folder['id']
-                folder_name = folder['name']
-                
-                if self.verbose:
-                    print(f"üóëÔ∏è  Deleting {folder_name} (ID: {folder_id})...")
-                
-                try:
-                    self.service.files().delete(fileId=folder_id).execute()
-                    deleted_count += 1
-                    if self.verbose:
-                        print(f"   ‚úÖ Deleted successfully")
-                except HttpError as e:
-                    if self.verbose:
-                        print(f"   ‚ùå Error deleting: {e}")
+            if self.verbose:
+                print(f"üóëÔ∏è  Deleting SyftBoxTransportService (ID: {folder_id})...")
+            
+            try:
+                self.service.files().delete(fileId=folder_id).execute()
             
-            if deleted_count > 0:
+                # Clear the cache after successful deletion
+                self._clear_syftbox_cache()
+                # Also invalidate all folders under SyftBox
+                self._invalidate_folder_cache(parent_id=folder_id)
+                
                 if self.verbose:
-                    print(f"\n‚úÖ Delete complete! Deleted {deleted_count} SyftBoxTransportService folder(s)")
+                    print(f"   ‚úÖ Deleted successfully")
+                    print(f"\n‚úÖ Delete complete! Deleted SyftBoxTransportService folder")
                 return True
-            else:
+                
+            except HttpError as e:
                 if self.verbose:
-                    print("\n‚ùå No folders were deleted")
+                    print(f"   ‚ùå Error deleting: {e}")
                 return False
                 
         except HttpError as e:
@@ -899,8 +1504,11 @@ class GDriveUnifiedClient:
         # First delete existing SyftBox
         self.delete_syftbox()
         
-        # Then create a new one
-        folder_id = self.setup_syftbox()
+        # Then create a new one¬†‚Äî¬†skip existence check since we just deleted it
+        folder_id = self.setup_syftbox(skip_syftbox_existence_check=True)
+        
+        # Ensure local SyftBox directory structure exists
+        self._create_local_syftbox_directory()
         
         # Always print success message for reset
         if folder_id:
@@ -951,7 +1559,7 @@ class GDriveUnifiedClient:
             print("üìÅ No credential files found to delete")
             return False
     
-    def setup_syftbox(self) -> Optional[str]:
+    def setup_syftbox(self, skip_syftbox_existence_check: bool = False) -> Optional[str]:
         """
         Set up SyftBoxTransportService folder structure (creates only if doesn't exist)
         
@@ -961,25 +1569,20 @@ class GDriveUnifiedClient:
         self._ensure_authenticated()
         
         try:
-            # Check if SyftBoxTransportService folder already exists
-            results = self.service.files().list(
-                q="name='SyftBoxTransportService' and mimeType='application/vnd.google-apps.folder' and 'root' in parents and trashed=false",
-                fields="files(id, name)"
-            ).execute()
-            
-            syftbox_folders = results.get('files', [])
-            
-            if syftbox_folders:
-                # Folder already exists
-                syftbox_id = syftbox_folders[0]['id']
+            if not skip_syftbox_existence_check:
+                # Try to get folder ID from cache first
+                syftbox_id = self._get_syftbox_folder_id()
+                
+                if syftbox_id:
+                    # Folder already exists
+                    if self.verbose:
+                        print(f"‚úÖ SyftBoxTransportService folder already exists (ID: {syftbox_id})")
+                        print(f"üîó Open in Google Drive: https://drive.google.com/drive/folders/{syftbox_id}")
+                    return syftbox_id
+                
+                # Create SyftBoxTransportService folder
                 if self.verbose:
-                    print(f"‚úÖ SyftBoxTransportService folder already exists (ID: {syftbox_id})")
-                    print(f"üîó Open in Google Drive: https://drive.google.com/drive/folders/{syftbox_id}")
-                return syftbox_id
-            
-            # Create SyftBoxTransportService folder
-            if self.verbose:
-                print("üöÄ Creating SyftBoxTransportService folder...\n")
+                    print("üöÄ Creating SyftBoxTransportService folder...\n")
             
             syftbox_id = self._create_folder("SyftBoxTransportService")
             if not syftbox_id:
@@ -987,6 +1590,11 @@ class GDriveUnifiedClient:
                     print("‚ùå Failed to create SyftBoxTransportService folder")
                 return None
             
+            # Cache the folder ID
+            self._syftbox_folder_id = syftbox_id
+            
+            # Ensure local SyftBox directory structure exists
+            self._create_local_syftbox_directory()
             
             if self.verbose:
                 print(f"\n‚úÖ SyftBoxTransportService setup complete!")
@@ -1046,34 +1654,27 @@ class GDriveUnifiedClient:
             }
             
             # Create/check pending folder (private to sender)
-            results = self.service.files().list(
-                q=f"name='{pending_name}' and mimeType='application/vnd.google-apps.folder' and '{syftbox_id}' in parents and trashed=false",
-                fields="files(id)"
-            ).execute()
+            pending_id = self._get_folder_id(pending_name, parent_id=syftbox_id)
             
-            pending_folders = results.get('files', [])
-            if pending_folders:
-                folder_ids['pending'] = pending_folders[0]['id']
+            if pending_id:
+                folder_ids['pending'] = pending_id
                 if verbose:
                     print(f"‚úÖ Pending folder already exists: {pending_name}")
             else:
                 pending_id = self._create_folder(pending_name, parent_id=syftbox_id)
                 if pending_id:
                     folder_ids['pending'] = pending_id
+                    # Cache the newly created folder
+                    self._set_folder_cache(pending_name, pending_id, parent_id=syftbox_id)
                     if verbose:
                         print(f"üìÅ Created pending folder: {pending_name}")
                         print(f"   ‚è≥ For preparing messages (private)")
             
             # Create/check outbox_inbox folder (shared with receiver)
-            results = self.service.files().list(
-                q=f"name='{outbox_inbox_name}' and mimeType='application/vnd.google-apps.folder' and '{syftbox_id}' in parents and trashed=false",
-                fields="files(id)"
-            ).execute()
+            outbox_id = self._get_folder_id(outbox_inbox_name, parent_id=syftbox_id)
             
-            outbox_folders = results.get('files', [])
-            if outbox_folders:
-                folder_ids['outbox_inbox'] = outbox_folders[0]['id']
-                outbox_id = outbox_folders[0]['id']
+            if outbox_id:
+                folder_ids['outbox_inbox'] = outbox_id
                 created = False
                 if verbose:
                     print(f"‚úÖ Outbox/Inbox folder already exists: {outbox_inbox_name}")
@@ -1081,6 +1682,8 @@ class GDriveUnifiedClient:
                 outbox_id = self._create_folder(outbox_inbox_name, parent_id=syftbox_id)
                 if outbox_id:
                     folder_ids['outbox_inbox'] = outbox_id
+                    # Cache the newly created folder
+                    self._set_folder_cache(outbox_inbox_name, outbox_id, parent_id=syftbox_id)
                     created = True
                     if verbose:
                         print(f"üìÅ Created outbox/inbox folder: {outbox_inbox_name}")
@@ -1108,14 +1711,10 @@ class GDriveUnifiedClient:
             
             # Check for incoming archive folder (created by the other party)
             archive_name = f"syft_{their_email}_to_{my_email}_archive"
-            results = self.service.files().list(
-                q=f"name='{archive_name}' and mimeType='application/vnd.google-apps.folder' and '{syftbox_id}' in parents and trashed=false",
-                fields="files(id)"
-            ).execute()
+            archive_id = self._get_folder_id(archive_name, parent_id=syftbox_id)
             
-            archive_folders = results.get('files', [])
-            if archive_folders:
-                folder_ids['archive'] = archive_folders[0]['id']
+            if archive_id:
+                folder_ids['archive'] = archive_id
                 if verbose:
                     print(f"‚úÖ Archive folder found: {archive_name}")
             else:
@@ -1252,113 +1851,425 @@ class GDriveUnifiedClient:
             else:
                 print(f"‚úÖ Added {friend_email} as a friend")
             
+            # Invalidate friends cache
+            self._invalidate_friends_cache()
+            
             return True
             
         except Exception as e:
             print(f"‚ùå Error adding friend: {e}")
             return False
     
-    def send_file_or_folder(self, path: str, recipient_email: str) -> bool:
+    def send_file_or_folder_auto(self, path: str, recipient_email: str) -> bool:
         """
-        Send a file or folder to a friend by creating a SyftMessage
+        Send a file or folder automatically choosing the best transport method
+        
+        Small files (<37.5KB compressed) use sheets for faster delivery
+        Large files use direct Google Drive upload
         
         Args:
-            path: Path to the file or folder to send
+            path: Path to the file or folder to send (supports syft:// URLs)
             recipient_email: Email address of the recipient (must be a friend)
             
         Returns:
             bool: True if successful, False otherwise
         """
-        from .syft_message import SyftMessage
         import tempfile
         
         self._ensure_authenticated()
         
+        # Resolve syft:// URLs
+        resolved_path = self.resolve_syft_path(path)
+        
+        # Check if recipient is in friends list
+        if recipient_email not in self.friends:
+            print(f"‚ùå We don't have an outbox for {recipient_email}")
+            return False
+        
+        # Create a temporary directory to check size
+        with tempfile.TemporaryDirectory() as temp_dir:
+            # Prepare the message to check size
+            result = self._prepare_message(resolved_path, recipient_email, temp_dir)
+            if not result:
+                return False
+            
+            message_id, archive_path, archive_size = result
+            
+            # Decide which method to use based on size
+            # Google Sheets has a 50,000 character limit per cell
+            # Base64 encoding increases size by ~33% (4/3 ratio)
+            # So max raw size = 50,000 / (4/3) = 37,500 bytes
+            max_sheets_size = 37_500  # Conservative limit to stay under 50k chars
+            if archive_size <= max_sheets_size:
+                if self.verbose:
+                    print(f"üìä Using sheets transport (size: {archive_size:,} bytes)")
+                # Small file - use sheets (faster)
+                return self.send_file_or_folder_via_sheets(resolved_path, recipient_email)
+            else:
+                if self.verbose:
+                    if archive_size < 1024 * 1024:
+                        print(f"üì¶ Using direct upload (size: {archive_size:,} bytes)")
+                    else:
+                        print(f"üì¶ Using direct upload (size: {archive_size / (1024*1024):.1f}MB)")
+                # Large file - use direct upload
+                return self.send_file_or_folder(resolved_path, recipient_email)
+    
+    def send_file_or_folder_to_friends(self, path: str) -> Dict[str, bool]:
+        """
+        Send a file or folder to all friends using the best transport method
+        
+        Args:
+            path: Path to the file or folder to send (supports syft:// URLs)
+            
+        Returns:
+            Dict mapping friend emails to success status
+        """
+        self._ensure_authenticated()
+        
+        # Resolve syft:// URLs
+        resolved_path = self.resolve_syft_path(path)
+        
+        # Check if path exists
+        if not os.path.exists(resolved_path):
+            print(f"‚ùå Path not found: {resolved_path}")
+            if path.startswith("syft://"):
+                print(f"   (resolved from: {path})")
+            return {}
+        
+        # Get list of friends
+        friends_list = self.friends
+        if not friends_list:
+            print("‚ùå No friends to send to. Add friends first with add_friend()")
+            return {}
+        
+        if self.verbose:
+            print(f"üì§ Sending {os.path.basename(resolved_path)} to {len(friends_list)} friend(s)...")
+        
+        results = {}
+        successful = 0
+        failed = 0
+        
+        for i, friend_email in enumerate(friends_list, 1):
+            if self.verbose:
+                print(f"\n[{i}/{len(friends_list)}] Sending to {friend_email}...")
+            
+            try:
+                # Use auto method to choose best transport
+                success = self.send_file_or_folder_auto(resolved_path, friend_email)
+                results[friend_email] = success
+                
+                if success:
+                    if self.verbose:
+                        print(f"   ‚úÖ Successfully sent to {friend_email}")
+                    successful += 1
+                else:
+                    if self.verbose:
+                        print(f"   ‚ùå Failed to send to {friend_email}")
+                    failed += 1
+                    
+            except Exception as e:
+                if self.verbose:
+                    print(f"   ‚ùå Error sending to {friend_email}: {str(e)}")
+                results[friend_email] = False
+                failed += 1
+        
+        # Summary
+        if self.verbose:
+            print(f"\nüìä Summary:")
+            print(f"   ‚úÖ Successful: {successful}")
+            print(f"   ‚ùå Failed: {failed}")
+            print(f"   üì® Total: {len(friends_list)}")
+        
+        return results
+    
+    def send_deletion(self, path: str, recipient_email: str) -> bool:
+        """
+        Send a deletion message for a file to a specific recipient
+        
+        Args:
+            path: Path to the deleted file (supports syft:// URLs)
+            recipient_email: Email address of the recipient
+            
+        Returns:
+            bool: True if successful, False otherwise
+        """
+        self._ensure_authenticated()
+        
+        # Resolve syft:// URLs
+        resolved_path = self.resolve_syft_path(path)
+        
         # Check if recipient is in friends list
         if recipient_email not in self.friends:
             print(f"‚ùå We don't have an outbox for {recipient_email}")
             return False
         
+        # Extract path relative to datasites
+        abs_path = os.path.abspath(resolved_path)
+        datasites_marker = os.sep + "datasites" + os.sep
+        
+        if datasites_marker not in abs_path:
+            print(f"‚ùå Error: Path must be within a SyftBox datasites folder")
+            return False
+        
+        # Get the syftbox path (e.g., "datasites/user/project/file.txt")
+        parts = abs_path.split(datasites_marker, 1)
+        if len(parts) == 2:
+            syftbox_path = f"datasites/{parts[1]}"
+        else:
+            print(f"‚ùå Error: Could not determine syftbox path")
+            return False
+        
+        if self.verbose:
+            print(f"üóëÔ∏è  Sending deletion of {os.path.basename(resolved_path)} to {recipient_email}...")
+        
+        # Create deletion message
+        from .syft_message import SyftMessage
+        import tempfile
+        
+        with tempfile.TemporaryDirectory() as temp_dir:
+            temp_path = Path(temp_dir)
+            
+            # Create SyftMessage
+            message = SyftMessage.create(
+                sender_email=self.my_email,
+                recipient_email=recipient_email,
+                message_root=temp_path
+            )
+            
+            # Set deletion metadata
+            metadata = message.get_metadata()
+            metadata["action"] = "delete"
+            metadata["files"] = [{
+                "path": syftbox_path,
+                "deleted_at": time.time(),
+                "hash": None  # Could compute if file still existed
+            }]
+            message.set_metadata(metadata)
+            
+            # Create archive
+            archive_path = message.create_archive(temp_path / f"{message.message_id}.tar.gz")
+            
+            # Send via sheets (deletions are always small)
+            return self._send_via_sheets(archive_path, recipient_email, message.message_id)
+    
+    def send_deletion_to_friends(self, path: str) -> Dict[str, bool]:
+        """
+        Send a deletion message for a file to all friends
+        
+        Args:
+            path: Path to the deleted file (supports syft:// URLs)
+            
+        Returns:
+            Dict mapping friend emails to success status
+        """
+        self._ensure_authenticated()
+        
+        # Get list of friends
+        friends_list = self.friends
+        if not friends_list:
+            print("‚ùå No friends to send to. Add friends first with add_friend()")
+            return {}
+        
+        if self.verbose:
+            print(f"üóëÔ∏è  Sending deletion of {os.path.basename(path)} to {len(friends_list)} friend(s)...")
+        
+        results = {}
+        successful = 0
+        failed = 0
+        
+        for i, friend_email in enumerate(friends_list, 1):
+            if self.verbose:
+                print(f"\n[{i}/{len(friends_list)}] Sending deletion to {friend_email}...")
+            
+            try:
+                success = self.send_deletion(path, friend_email)
+                results[friend_email] = success
+                
+                if success:
+                    successful += 1
+                    if self.verbose:
+                        print(f"   ‚úÖ Success")
+                else:
+                    failed += 1
+                    
+            except Exception as e:
+                if self.verbose:
+                    print(f"   ‚ùå Error: {str(e)}")
+                results[friend_email] = False
+                failed += 1
+        
+        # Summary
+        if self.verbose:
+            print(f"\nüìä Summary:")
+            print(f"   ‚úÖ Successful: {successful}")
+            print(f"   ‚ùå Failed: {failed}")
+            print(f"   üì® Total: {len(friends_list)}")
+        
+        return results
+    
+    def _prepare_message(self, path: str, recipient_email: str, temp_dir: str) -> Optional[tuple]:
+        """
+        Prepare a SyftMessage archive for sending
+        
+        Args:
+            path: Path to the file or folder to send
+            recipient_email: Email address of the recipient
+            temp_dir: Temporary directory to create the message in
+            
+        Returns:
+            Tuple of (message_id, archive_path, archive_size) if successful, None otherwise
+        """
+        from .syft_message import SyftMessage
+        
         # Check if path exists
         if not os.path.exists(path):
             print(f"‚ùå Path not found: {path}")
-            return False
+            return None
+        
+        # Validate that the file is within THIS client's SyftBox folder
+        abs_path = os.path.abspath(path)
+        expected_syftbox = self.get_syftbox_directory()
+        
+        if expected_syftbox is None:
+            print(f"‚ùå Error: Could not determine SyftBox directory")
+            return None
+        
+        expected_syftbox_str = str(expected_syftbox)
+        
+        # Check if the file is within this specific client's SyftBox
+        if not abs_path.startswith(expected_syftbox_str + os.sep):
+            print(f"‚ùå Error: Files must be within YOUR SyftBox folder to be sent")
+            print(f"   Your SyftBox: {expected_syftbox_str}")
+            print(f"   File path: {path}")
+            print(f"   Tip: Move your file to {expected_syftbox_str}/datasites/ or use syft:// URLs")
+            print(f"   Example: syft://filename.txt")
+            return None
         
         is_directory = os.path.isdir(path)
+        temp_path = Path(temp_dir)
+        
+        # Create SyftMessage
+        message = SyftMessage.create(
+            sender_email=self.my_email,
+            recipient_email=recipient_email,
+            message_root=temp_path
+        )
+        
+        if self.verbose:
+            print(f"üì¶ Creating message: {message.message_id}")
+        
+        # Check if the path is within a datasites directory
+        datasites_marker = os.sep + "datasites" + os.sep
+        
+        if datasites_marker not in abs_path:
+            print(f"‚ùå Error: Files must be within a SyftBox datasites folder to be sent")
+            print(f"   Path: {path}")
+            print(f"   Tip: Move your file to {self.get_syftbox_directory()}/datasites/")
+            return None
+        
+        # Extract the path relative to datasites
+        parts = abs_path.split(datasites_marker, 1)
+        if len(parts) == 2:
+            relative_to_datasites = parts[1]
+        else:
+            relative_to_datasites = os.path.basename(path)
+        
+        # Add files to the message
+        if is_directory:
+            # For directories, use the relative path if within datasites
+            if datasites_marker in abs_path:
+                self._add_folder_to_message(message, path, None, parent_path=relative_to_datasites)
+            else:
+                # Not in datasites, use directory name as base
+                base_name = os.path.basename(path.rstrip('/'))
+                self._add_folder_to_message(message, path, base_name)
+        else:
+            # Add single file with correct datasites path
+            syftbox_path = f"datasites/{relative_to_datasites}"
+            message.add_file(
+                source_path=Path(path),
+                path=syftbox_path,
+                permissions={
+                    "read": [recipient_email],
+                    "write": [self.my_email]
+                }
+            )
+            
+            if self.verbose:
+                print(f"   üìÑ Added file: {relative_to_datasites}")
+        
+        # Finalize the message
+        message.finalize()
+        
+        # Create tar.gz archive
+        archive_path = os.path.join(temp_dir, f"{message.message_id}.tar.gz")
+        with tarfile.open(archive_path, 'w:gz') as tar:
+            tar.add(str(message.path), arcname=message.message_id)
+        
+        # Get archive size
+        archive_size = os.path.getsize(archive_path)
+        
+        return (message.message_id, archive_path, archive_size)
+    
+    def send_file_or_folder(self, path: str, recipient_email: str) -> bool:
+        """
+        Send a file or folder to a friend by creating a SyftMessage
+        
+        Args:
+            path: Path to the file or folder to send
+            recipient_email: Email address of the recipient (must be a friend)
+            
+        Returns:
+            bool: True if successful, False otherwise
+        """
+        import tempfile
+        
+        self._ensure_authenticated()
+        
+        # Check if recipient is in friends list
+        if recipient_email not in self.friends:
+            print(f"‚ùå We don't have an outbox for {recipient_email}")
+            return False
         
         # Get the outbox folder ID
         if not self.my_email:
             print("‚ùå Could not determine your email address")
             return False
-            
+        
         outbox_inbox_name = f"syft_{self.my_email}_to_{recipient_email}_outbox_inbox"
         
         try:
-            # Get SyftBox ID first
-            results = self.service.files().list(
-                q="name='SyftBoxTransportService' and mimeType='application/vnd.google-apps.folder' and 'root' in parents and trashed=false",
-                fields="files(id)"
-            ).execute()
+            # Get SyftBox ID using cache
+            syftbox_id = self._get_syftbox_folder_id()
             
-            if not results.get('files'):
+            if not syftbox_id:
                 print("‚ùå SyftBoxTransportService not found")
                 return False
-                
-            syftbox_id = results['files'][0]['id']
             
-            # Find the outbox folder
-            results = self.service.files().list(
-                q=f"name='{outbox_inbox_name}' and mimeType='application/vnd.google-apps.folder' and '{syftbox_id}' in parents and trashed=false",
-                fields="files(id)"
-            ).execute()
+            # Find the outbox folder using cache
+            outbox_id = self._get_folder_id(outbox_inbox_name, parent_id=syftbox_id)
             
-            if not results.get('files'):
+            if not outbox_id:
                 print(f"‚ùå Outbox folder not found for {recipient_email}")
                 return False
-                
-            outbox_id = results['files'][0]['id']
             
             # Create a temporary directory for the SyftMessage
             with tempfile.TemporaryDirectory() as temp_dir:
-                temp_path = Path(temp_dir)
-                
-                # Create SyftMessage
-                message = SyftMessage.create(
-                    sender_email=self.my_email,
-                    recipient_email=recipient_email,
-                    message_root=temp_path
-                )
+                # Prepare the message
+                result = self._prepare_message(path, recipient_email, temp_dir)
+                if not result:
+                    return False
                 
-                if self.verbose:
-                    print(f"üì¶ Creating message: {message.message_id}")
+                message_id, archive_path, archive_size = result
                 
-                # Add files to the message
-                if is_directory:
-                    # Add all files from the directory recursively
-                    base_name = os.path.basename(path.rstrip('/'))
-                    self._add_folder_to_message(message, path, base_name)
-                else:
-                    # Add single file
-                    filename = os.path.basename(path)
-                    syftbox_path = f"/{self.my_email}/shared/{filename}"
-                    message.add_file(
-                        source_path=Path(path),
-                        path=syftbox_path,
-                        permissions={
-                            "read": [recipient_email],
-                            "write": [self.my_email]
-                        }
-                    )
+                # Check size before uploading (5MB limit for sheets)
+                if archive_size > 5 * 1024 * 1024:
                     if self.verbose:
-                        print(f"   üìÑ Added file: {filename}")
-                
-                # Finalize the message
-                message.finalize()
+                        print(f"üì¶ Message size: {archive_size / (1024*1024):.1f}MB - using direct upload")
                 
                 # Check if there's already a message with this ID and delete it
-                message_folder_name = message.message_id
                 existing_messages = self.service.files().list(
-                    q=f"name='{message_folder_name}' and '{outbox_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false",
+                    q=f"name='{message_id}' and '{outbox_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false",
                     fields="files(id, name)"
                 ).execute()
                 
@@ -1366,16 +2277,17 @@ class GDriveUnifiedClient:
                     try:
                         self.service.files().delete(fileId=existing['id']).execute()
                         if self.verbose:
-                            print(f"   ‚ôªÔ∏è  Replacing existing message: {message_folder_name}")
+                            print(f"   ‚ôªÔ∏è  Replacing existing message: {message_id}")
                     except Exception as e:
                         if self.verbose:
                             print(f"   ‚ö†Ô∏è  Could not delete existing message: {e}")
                 
                 # Upload the entire SyftMessage folder
-                success = self._upload_folder_recursive(str(message.path), outbox_id, message_folder_name)
+                file_id = self._upload_folder_as_archive(str(Path(temp_dir) / message_id), outbox_id, message_id)
                 
-                if success:
-                    print(f"‚úÖ Message sent to {recipient_email}")
+                if file_id:
+                    if self.verbose:
+                        print(f"‚úÖ Message sent to {recipient_email}")
                     return True
                 else:
                     print(f"‚ùå Failed to upload message")
@@ -1398,14 +2310,20 @@ class GDriveUnifiedClient:
         for item in os.listdir(folder_path):
             item_path = os.path.join(folder_path, item)
             
-            # Skip hidden files
+            # Skip hidden files and directories
             if item.startswith('.'):
                 continue
                 
             if os.path.isfile(item_path):
                 # Calculate relative path for syftbox
                 relative_path = os.path.join(parent_path, item) if parent_path else item
-                syftbox_path = f"/{message.sender_email}/shared/{base_path}/{relative_path}"
+                
+                # Build syftbox path based on whether we have a base_path
+                if base_path:
+                    syftbox_path = f"datasites/{base_path}/{relative_path}"
+                else:
+                    # No base path, parent_path contains the full relative path
+                    syftbox_path = f"datasites/{relative_path}"
                 
                 try:
                     message.add_file(
@@ -1426,505 +2344,4759 @@ class GDriveUnifiedClient:
                 # Recursively add subdirectory
                 new_parent = os.path.join(parent_path, item) if parent_path else item
                 self._add_folder_to_message(message, item_path, base_path, new_parent)
-    
-    @property
-    def friends(self) -> List[str]:
+
+    def update_inbox(self, inbox_dir: str = None, archive_messages: bool = True, fast_mode: bool = False) -> Dict[str, List[str]]:
         """
-        List all friends (people you have set up outgoing channels to)
+        Check all friend inboxes for new SyftMessage objects and download them
         
+        Args:
+            inbox_dir: Local directory to store messages (default: {syftbox_dir}/inbox)
+            archive_messages: Whether to archive messages after downloading (default: True)
+            fast_mode: Skip validation and download everything (default: False)
+            
         Returns:
-            List of email addresses you've added as friends
+            Dict mapping friend emails to list of downloaded message IDs
         """
-        if not self.authenticated:
-            return []
+        from .syft_message import SyftMessage
+        from googleapiclient.http import BatchHttpRequest
+        
+        self._ensure_authenticated()
+        
+        # Set default inbox directory using get_syftbox_directory
+        if inbox_dir is None:
+            syftbox_dir = self.get_syftbox_directory()
+            if syftbox_dir is None:
+                print("‚ùå Could not determine SyftBox directory")
+                return {}
+            inbox_dir = str(syftbox_dir / "inbox")
+        
+        # Create inbox directory if it doesn't exist
+        os.makedirs(inbox_dir, exist_ok=True)
         
         if not self.my_email:
-            return []
+            print("‚ùå Could not determine your email address")
+            return {}
+        
+        # Get list of friends
+        friends_list = self.friends
+        if not friends_list:
+            if self.verbose:
+                print("No friends found - nothing to check")
+            return {}
         
+        if self.verbose:
+            print(f"üì• Checking inboxes from {len(friends_list)} friend(s)...")
+        
+        # Get SyftBox folder ID
         try:
-            # First check if SyftBoxTransportService exists
-            syftbox_id = None
-            try:
-                results = self.service.files().list(
-                    q="name='SyftBoxTransportService' and mimeType='application/vnd.google-apps.folder' and 'root' in parents and trashed=false",
-                    fields="files(id)"
-                ).execute()
-                if results.get('files'):
-                    syftbox_id = results['files'][0]['id']
-            except:
-                pass
-            
-            if not syftbox_id:
-                # No SyftBoxTransportService = no friends
-                return []
-            
-            friends_set = set()
+            results = self.service.files().list(
+                q="name='SyftBoxTransportService' and mimeType='application/vnd.google-apps.folder' and 'root' in parents and trashed=false",
+                fields="files(id)"
+            ).execute()
             
-            # Get folders inside SyftBoxTransportService
-            try:
-                results = self.service.files().list(
-                    q=f"'{syftbox_id}' in parents and name contains 'syft_' and mimeType='application/vnd.google-apps.folder' and trashed=false",
-                    fields="files(name)"
-                ).execute()
+            if not results.get('files'):
+                print("‚ùå SyftBoxTransportService not found")
+                return {}
                 
-                for folder in results.get('files', []):
-                    name = folder['name']
-                    # Look for your outgoing folders
-                    if name.startswith(f'syft_{self.my_email}_to_'):
-                        # Extract the recipient email
-                        parts = name.split('_to_')
-                        if len(parts) == 2:
-                            # Remove the suffix (_pending, _outbox_inbox, etc)
-                            email_with_suffix = parts[1]
-                            # Handle both _outbox_inbox and _outbox suffixes
-                            if '_outbox_inbox' in email_with_suffix:
-                                email_part = email_with_suffix.replace('_outbox_inbox', '')
-                            elif '_outbox' in email_with_suffix:
-                                email_part = email_with_suffix.replace('_outbox', '')
-                            elif '_pending' in email_with_suffix:
-                                email_part = email_with_suffix.replace('_pending', '')
-                            elif '_archive' in email_with_suffix:
-                                email_part = email_with_suffix.replace('_archive', '')
+            syftbox_id = results['files'][0]['id']
+        except Exception as e:
+            print(f"‚ùå Error finding SyftBox folder: {e}")
+            return {}
+        
+        # Prepare batch request to check all inboxes
+        downloaded_messages = {}
+        
+        def process_batch_in_chunks(friends, chunk_size=100):
+            """Process friends in chunks of 100 (batch request limit)"""
+            for i in range(0, len(friends), chunk_size):
+                chunk = friends[i:i + chunk_size]
+                
+                # Create batch request
+                batch = self.service.new_batch_http_request()
+                callbacks = {}
+                
+                # Add requests for each friend's inbox
+                for friend_email in chunk:
+                    # Look for the inbox folder shared by this friend
+                    inbox_name = f"syft_{friend_email}_to_{self.my_email}_outbox_inbox"
+                    
+                    def make_callback(email, inbox):
+                        def callback(request_id, response, exception):
+                            if exception is None:
+                                callbacks[email] = (inbox, response)
                             else:
-                                # No known suffix, try generic approach
-                                email_part = email_with_suffix.rsplit('_', 1)[0]
-                            friends_set.add(email_part)
-            except:
-                pass
+                                if self.verbose:
+                                    print(f"   ‚ö†Ô∏è  Error checking {email}: {exception}")
+                                callbacks[email] = (inbox, None)
+                        return callback
+                    
+                    # First get the inbox folder ID, then search within it
+                    def make_inbox_callback(email, inbox):
+                        def callback(request_id, response, exception):
+                            if exception is None and response.get('files'):
+                                file_info = response['files'][0]
+                                inbox_id = file_info['id']
+                                
+                                # If it's a shortcut, get the target ID
+                                if file_info.get('mimeType') == 'application/vnd.google-apps.shortcut':
+                                    shortcut_details = file_info.get('shortcutDetails', {})
+                                    target_id = shortcut_details.get('targetId')
+                                    if target_id:
+                                        inbox_id = target_id
+                                        if self.verbose:
+                                            print(f"   üìé Found inbox shortcut for {email}, using target: {target_id}")
+                                
+                                callbacks[email] = (inbox, inbox_id)
+                            else:
+                                if self.verbose and exception:
+                                    print(f"   ‚ö†Ô∏è  Error finding inbox for {email}: {exception}")
+                                callbacks[email] = (inbox, None)
+                        return callback
+                    
+                    # Find the inbox folder first (could be a folder or shortcut)
+                    batch.add(
+                        self.service.files().list(
+                            q=f"name='{inbox_name}' and (mimeType='application/vnd.google-apps.folder' or mimeType='application/vnd.google-apps.shortcut') and trashed=false",
+                            fields="files(id, mimeType, shortcutDetails)",
+                            pageSize=1
+                        ),
+                        callback=make_inbox_callback(friend_email, inbox_name)
+                    )
+                
+                # Execute batch request
+                try:
+                    batch.execute()
+                except Exception as e:
+                    print(f"‚ùå Batch request failed: {e}")
+                    continue
+                
+                # Process results - now we need to search within each inbox
+                for friend_email, (inbox_name, inbox_folder_id) in callbacks.items():
+                    if inbox_folder_id is None:
+                        continue
+                    
+                    # Now search for messages within this specific inbox folder
+                    try:
+                        # Just get ALL files in the folder - no filtering at all (fastest query)
+                        messages_response = self.service.files().list(
+                            q=f"'{inbox_folder_id}' in parents",
+                            fields="files(id, name)",
+                            pageSize=1000  # Get more at once
+                        ).execute()
+                        
+                        # Filter locally for tar.gz syft_message files
+                        all_files = messages_response.get('files', [])
+                        inbox_messages = [
+                            f for f in all_files 
+                            if f.get('name', '').startswith('syft_message_') and 
+                               f.get('name', '').endswith('.tar.gz')
+                        ]
+                        
+                        if inbox_messages:
+                            if self.verbose:
+                                print(f"\nüì¨ Found {len(inbox_messages)} message(s) from {friend_email}")
+                            downloaded_messages[friend_email] = []
+                            
+                            # Download each message
+                            for msg in inbox_messages:
+                                msg_filename = msg['name']  # e.g., syft_message_12345.tar.gz
+                                msg_file_id = msg['id']
+                                
+                                # Extract message ID from filename (remove .tar.gz)
+                                msg_id = msg_filename.replace('.tar.gz', '')
+                                
+                                # Note: Archives are already finalized, no need to check for lock.json
+                                
+                                # Check if already extracted
+                                local_msg_path = os.path.join(inbox_dir, msg_id)
+                                already_downloaded = os.path.exists(local_msg_path)
+                                
+                                # In fast mode, skip if already downloaded
+                                if already_downloaded and (not archive_messages or fast_mode):
+                                    if self.verbose:
+                                        print(f"   ‚è≠Ô∏è  Skipping {msg_id} - already downloaded")
+                                    continue
+                                
+                                # Download if not already downloaded
+                                download_success = True
+                                if not already_downloaded:
+                                    if self.verbose:
+                                        print(f"   üì• Processing {msg_id}...")
+                                    
+                                    # Download and extract the archive
+                                    download_success = self._download_archive_and_extract(msg_file_id, inbox_dir, msg_id)
+                                    if download_success:
+                                        downloaded_messages[friend_email].append(msg_id)
+                                else:
+                                    if self.verbose:
+                                        print(f"   üì• Already downloaded {msg_id}, checking for archiving...")
+                                
+                                if download_success:
+                                    # Validate the downloaded message (skip in fast mode)
+                                    is_valid = fast_mode  # In fast mode, assume valid
+                                    if not fast_mode:
+                                        try:
+                                            received_msg = SyftMessage(Path(local_msg_path))
+                                            is_valid, error = received_msg.validate()
+                                            if is_valid:
+                                                if self.verbose:
+                                                    print(f"   ‚úÖ Valid message from {received_msg.sender_email}")
+                                            else:
+                                                print(f"   ‚ùå Invalid message: {error}")
+                                        except Exception as e:
+                                            print(f"   ‚ùå Error validating message: {e}")
+                                    
+                                    # Archive the message if it was valid and archiving is enabled
+                                    if is_valid and archive_messages:
+                                        # Archive folder follows pattern: syft_{sender}_to_{receiver}_archive
+                                        archive_name = f"syft_{friend_email}_to_{self.my_email}_archive"
+                                        
+                                        # Check if archive folder exists, create if not
+                                        try:
+                                            archive_results = self.service.files().list(
+                                                q=f"name='{archive_name}' and mimeType='application/vnd.google-apps.folder' and '{syftbox_id}' in parents and trashed=false",
+                                                fields="files(id)",
+                                                pageSize=1
+                                            ).execute()
+                                            
+                                            if archive_results.get('files'):
+                                                archive_id = archive_results['files'][0]['id']
+                                            else:
+                                                # Create archive folder
+                                                archive_id = self._create_folder(archive_name, parent_id=syftbox_id)
+                                                if self.verbose and archive_id:
+                                                    print(f"   üìÅ Created archive folder: {archive_name}")
+                                            
+                                            if archive_id:
+                                                # Move message archive file from inbox to archive folder (non-blocking)
+                                                if self.verbose:
+                                                    print(f"   üì¶ Scheduling background archive for {msg_id}...")
+                                                
+                                                # Create and start background thread for archiving
+                                                archive_thread = threading.Thread(
+                                                    target=self._archive_message_async,
+                                                    args=(msg_file_id, archive_id, inbox_folder_id, msg_id, archive_name),
+                                                    daemon=True  # Daemon thread will not block program exit
+                                                )
+                                                archive_thread.start()
+                                        except Exception as e:
+                                            if self.verbose:
+                                                print(f"   ‚ö†Ô∏è  Error creating archive: {e}")
+                                else:
+                                    print(f"   ‚ùå Failed to download {msg_id}")
+                        else:
+                            if self.verbose:
+                                print(f"   üì≠ No messages from {friend_email}")
+                    except Exception as e:
+                        if self.verbose:
+                            print(f"   ‚ö†Ô∏è  Error checking messages from {friend_email}: {e}")
+        
+        # Process all friends (in chunks if > 100)
+        process_batch_in_chunks(friends_list)
+        
+        # Summary
+        total_messages = sum(len(msgs) for msgs in downloaded_messages.values())
+        if total_messages > 0 and self.verbose:
+            print(f"\n‚úÖ Downloaded {total_messages} message(s) to {inbox_dir}")
+        elif total_messages == 0 and self.verbose:
+            print("‚úÖ No messages to download")
+        
+        return downloaded_messages
+    
+    def autoapprove_inbox(self, syftbox_dir: Optional[Path] = None) -> Dict[str, int]:
+        """
+        Automatically approve all messages in the inbox by moving them to the approved folder
+        
+        Args:
+            syftbox_dir: Optional SyftBox directory path (defaults to get_syftbox_directory())
+            
+        Returns:
+            Dict mapping message types to counts of approved messages
+        """
+        import shutil
+        from collections import defaultdict
+        
+        # print("AUTOAPPROVE-1 " + str(time.time()))
+        self._ensure_authenticated()
+        # print("AUTOAPPROVE-2 " + str(time.time()))
+        
+        # Get SyftBox directory
+        if syftbox_dir is None:
+            # print("AUTOAPPROVE-3 " + str(time.time()))
+            syftbox_dir = self.get_syftbox_directory()
+            # print("AUTOAPPROVE-4 " + str(time.time()))
+            if syftbox_dir is None:
+                print("‚ùå Could not determine SyftBox directory")
+                return {}
+        
+        # Ensure we're working with the correct user's SyftBox
+        expected_dir_name = f"SyftBox_{self.my_email}"
+        if syftbox_dir.name != expected_dir_name:
+            print(f"‚ùå SyftBox directory name mismatch. Expected '{expected_dir_name}' but got '{syftbox_dir.name}'")
+            return {}
+        
+        inbox_dir = syftbox_dir / "inbox"
+        approved_dir = syftbox_dir / "approved"
+        
+        # Check if inbox exists
+        # print("AUTOAPPROVE-5 " + str(time.time()))
+        if not inbox_dir.exists():
+            print(f"üì• No inbox found at {inbox_dir}")
+            return {}
+        
+        # Create approved directory if it doesn't exist
+        # print("AUTOAPPROVE-6 " + str(time.time()))
+        approved_dir.mkdir(exist_ok=True)
+        
+        # Count messages by type
+        approved_counts = defaultdict(int)
+        total_moved = 0
+        
+        if self.verbose:
+            print(f"üì• Auto-approving messages from {inbox_dir}")
+        
+        # List all items in inbox
+        # print("AUTOAPPROVE-7 " + str(time.time()))
+        try:
+            # print("AUTOAPPROVE-8 " + str(time.time()))
+            for item in inbox_dir.iterdir():
+                if item.is_dir() and not item.name.startswith('.'):
+                    # Determine message type
+                    if item.name.startswith("syft_message_"):
+                        message_type = "syft_message"
+                    elif item.name.startswith("syft_") and "_to_" in item.name:
+                        message_type = "syft_folder"
+                    else:
+                        message_type = "other"
+                    
+                    # Move to approved folder
+                    # print("AUTOAPPROVE-9 " + str(time.time()))
+                    dest_path = approved_dir / item.name
+                    
+                    # If destination exists, remove it first
+                    if dest_path.exists():
+                        if dest_path.is_dir():
+                            shutil.rmtree(dest_path)
+                        else:
+                            dest_path.unlink()
+                    
+                    # Move the folder
+                    # print("AUTOAPPROVE-10 " + str(time.time()))
+                    shutil.move(str(item), str(dest_path))
+                    # print("AUTOAPPROVE-11 " + str(time.time()))
+                    
+                    approved_counts[message_type] += 1
+                    total_moved += 1
+                    
+                    if self.verbose:
+                        print(f"   ‚úì Approved: {item.name}")
+            
+            # Print summary
+            # print("AUTOAPPROVE-12 " + str(time.time()))
+            if total_moved > 0:
+                if self.verbose:
+                    print(f"\n‚úÖ Auto-approved {total_moved} message(s):")
+                    for msg_type, count in approved_counts.items():
+                        print(f"   - {msg_type}: {count}")
+            else:
+                print("‚úÖ No messages to approve")
+                
+        except Exception as e:
+            print(f"‚ùå Error during auto-approval: {e}")
+        
+        # print("AUTOAPPROVE-13 " + str(time.time()))
+        return dict(approved_counts)
+    
+    def _get_sync_history_path(self, file_path: Path) -> Path:
+        """
+        Get the sync history directory path for a file
+        
+        Args:
+            file_path: Path to the file in datasites
+            
+        Returns:
+            Path to the sync history directory
+        """
+        # Create .sync_history directory in the same directory as the file
+        return file_path.parent / ".sync_history" / file_path.name
+    
+    def _get_sync_timestamp(self, message_path: Path) -> Optional[float]:
+        """
+        Get the timestamp from a SyftMessage
+        
+        Args:
+            message_path: Path to the message directory
+            
+        Returns:
+            Timestamp as float or None if not found
+        """
+        # Try to get from cached metadata first
+        message_id = str(message_path.name)
+        if message_id in self._metadata_cache:
+            metadata = self._metadata_cache[message_id]
+            return metadata.get("timestamp")
+        
+        # Try reading metadata files
+        for metadata_file in ["metadata.json", "metadata.yaml"]:
+            metadata_path = message_path / metadata_file
+            if metadata_path.exists():
+                try:
+                    if metadata_file.endswith(".json"):
+                        with open(metadata_path, 'r') as f:
+                            metadata = json.load(f)
+                    else:
+                        with open(metadata_path, 'r') as f:
+                            metadata = yaml.safe_load(f) or {}
+                    return metadata.get("timestamp")
+                except:
+                    continue
+        
+        return None
+    
+    def _should_apply_sync(self, file_path: Path, message_path: Path) -> bool:
+        """
+        Check if a sync should be applied based on history
+        
+        Args:
+            file_path: Path to the file in datasites
+            message_path: Path to the incoming message
+            
+        Returns:
+            True if sync should be applied, False otherwise
+        """
+        history_path = self._get_sync_history_path(file_path)
+        
+        # If no history exists, always apply
+        if not history_path.exists():
+            return True
+        
+        # Get timestamp of incoming message
+        incoming_timestamp = self._get_sync_timestamp(message_path)
+        if incoming_timestamp is None:
+            # If no timestamp, apply it (for backward compatibility)
+            return True
+        
+        # Check existing syncs in history
+        try:
+            for entry in os.listdir(history_path):
+                entry_path = history_path / entry
+                if entry_path.is_dir() and entry.endswith(".syftmessage"):
+                    # Get timestamp of existing sync
+                    existing_timestamp = self._get_sync_timestamp(entry_path)
+                    if existing_timestamp and existing_timestamp >= incoming_timestamp:
+                        # We already have a sync that's newer or equal
+                        if self.verbose:
+                            print(f"      ‚è≠Ô∏è  Skipping older sync for: {file_path.name}")
+                        return False
+        except:
+            # If we can't read history, apply the sync
+            return True
+        
+        return True
+    
+    def _store_sync_history(self, file_path: Path, message_path: Path) -> None:
+        """
+        Store a copy of the SyftMessage in sync history
+        
+        Args:
+            file_path: Path to the file in datasites
+            message_path: Path to the message directory
+        """
+        history_path = self._get_sync_history_path(file_path)
+        
+        # Create history directory
+        history_path.mkdir(parents=True, exist_ok=True)
+        
+        # Create unique name for this sync
+        timestamp = self._get_sync_timestamp(message_path) or time.time()
+        sync_name = f"{timestamp}_{message_path.name}.syftmessage"
+        sync_dest = history_path / sync_name
+        
+        # Copy the message directory to history
+        try:
+            if not sync_dest.exists():
+                shutil.copytree(message_path, sync_dest)
+        except Exception as e:
+            if self.verbose:
+                print(f"      ‚ö†Ô∏è  Could not store sync history: {e}")
+    
+    def _compute_file_hash(self, file_path: Union[str, Path]) -> Optional[str]:
+        """
+        Compute SHA256 hash of a file
+        
+        Args:
+            file_path: Path to the file
+            
+        Returns:
+            Hex string of file hash or None if error
+        """
+        import hashlib
+        try:
+            sha256_hash = hashlib.sha256()
+            with open(file_path, "rb") as f:
+                # Read in chunks to handle large files
+                for byte_block in iter(lambda: f.read(4096), b""):
+                    sha256_hash.update(byte_block)
+            return sha256_hash.hexdigest()
+        except Exception:
+            return None
+    
+    def _is_file_from_recent_sync(self, file_path: Union[str, Path], threshold_seconds: int = 60) -> bool:
+        """
+        Check if a file's current content matches the most recent sync
+        
+        Args:
+            file_path: Path to the file to check
+            threshold_seconds: How recent the sync must be (default: 60 seconds)
+            
+        Returns:
+            True if file matches the most recent sync within threshold, False otherwise
+        """
+        file_path = Path(file_path)
+        
+        # Get current file hash
+        current_hash = self._compute_file_hash(file_path)
+        if not current_hash:
+            return False
+        
+        # Get sync history path
+        history_path = self._get_sync_history_path(file_path)
+        if not history_path.exists():
+            return False
+        
+        current_time = time.time()
+        
+        try:
+            # Collect all sync entries with their timestamps
+            syncs = []
+            for sync_entry in history_path.iterdir():
+                if sync_entry.is_dir() and sync_entry.name.endswith(".syftmessage"):
+                    try:
+                        # Filename format: <timestamp>_<message_id>.syftmessage
+                        timestamp_str = sync_entry.name.split('_')[0]
+                        sync_timestamp = float(timestamp_str)
+                        syncs.append((sync_timestamp, sync_entry))
+                    except (ValueError, IndexError):
+                        continue
+            
+            # Sort by timestamp to get most recent first
+            syncs.sort(key=lambda x: x[0], reverse=True)
+            
+            # Check only the most recent sync
+            if syncs:
+                sync_timestamp, sync_entry = syncs[0]
+                
+                # Check if the most recent sync is within threshold
+                if current_time - sync_timestamp > threshold_seconds:
+                    # Most recent sync is too old
+                    return False
+                
+                # Check if the most recent sync matches current content
+                sync_files_dir = sync_entry / "data" / "files"
+                if not sync_files_dir.exists():
+                    return False
+                
+                # Read metadata to find the internal name
+                metadata = None
+                for metadata_file in ["metadata.json", "metadata.yaml"]:
+                    metadata_path = sync_entry / metadata_file
+                    if metadata_path.exists():
+                        try:
+                            if metadata_file.endswith(".json"):
+                                with open(metadata_path, 'r') as f:
+                                    metadata = json.load(f)
+                            else:
+                                with open(metadata_path, 'r') as f:
+                                    metadata = yaml.safe_load(f) or {}
+                            break
+                        except:
+                            continue
+                
+                if not metadata:
+                    return False
+                
+                # Find the file entry
+                files_info = metadata.get("files", [])
+                for file_entry in files_info:
+                    if file_entry.get("path", "").endswith(file_path.name):
+                        internal_name = file_entry.get("_internal_name", file_path.name)
+                        sync_file_path = sync_files_dir / internal_name
+                        
+                        if sync_file_path.exists():
+                            sync_hash = self._compute_file_hash(sync_file_path)
+                            if sync_hash == current_hash:
+                                if self.verbose:
+                                    age_seconds = current_time - sync_timestamp
+                                    print(f"üîÑ File {file_path.name} matches most recent sync from {age_seconds:.0f}s ago")
+                                return True
+                            else:
+                                # Most recent sync doesn't match - file has been edited
+                                if self.verbose:
+                                    print(f"‚úèÔ∏è  File {file_path.name} has been edited since last sync")
+                                return False
+            
+        except Exception as e:
+            if self.verbose:
+                print(f"‚ö†Ô∏è  Error checking sync history: {e}")
+            return False
+        
+        return False
+    
+    def _get_recent_sync_info(self, file_path: Union[str, Path], threshold_seconds: Optional[int] = None) -> Optional[Dict[str, any]]:
+        """
+        Get information about the most recent sync for a file
+        
+        Args:
+            file_path: Path to the file
+            threshold_seconds: If provided, only return info if sync is within this threshold
+            
+        Returns:
+            Dict with sync info or None if no sync found (or too old if threshold provided)
+        """
+        file_path = Path(file_path)
+        history_path = self._get_sync_history_path(file_path)
+        
+        if not history_path.exists():
+            return None
+        
+        current_time = time.time()
+        
+        try:
+            # Collect all sync entries with their timestamps
+            syncs = []
+            for sync_entry in history_path.iterdir():
+                if sync_entry.is_dir() and sync_entry.name.endswith(".syftmessage"):
+                    try:
+                        timestamp_str = sync_entry.name.split('_')[0]
+                        sync_timestamp = float(timestamp_str)
+                        syncs.append((sync_timestamp, sync_entry))
+                    except:
+                        continue
+            
+            if not syncs:
+                return None
+            
+            # Sort by timestamp to get most recent first
+            syncs.sort(key=lambda x: x[0], reverse=True)
+            sync_timestamp, sync_entry = syncs[0]
+            
+            # Check threshold if provided
+            age_seconds = current_time - sync_timestamp
+            if threshold_seconds is not None and age_seconds > threshold_seconds:
+                return None
+            
+            return {
+                "timestamp": sync_timestamp,
+                "age_seconds": age_seconds,
+                "sync_path": sync_entry,
+                "sync_id": sync_entry.name,
+                "is_most_recent": True
+            }
+        except:
+            pass
+        
+        return None
+
+    def _clean_sync_history_for_datasite(self, datasite_path: Path, keep_latest: bool = True) -> int:
+        """
+        Clean up sync history for a datasite when receiving a full update
+        
+        Args:
+            datasite_path: Path to the datasite directory
+            keep_latest: Whether to keep the latest sync (default: True)
+            
+        Returns:
+            Number of sync history entries cleaned
+        """
+        cleaned_count = 0
+        
+        # Walk through all .sync_history directories in the datasite
+        for root, dirs, files in os.walk(datasite_path):
+            if ".sync_history" in dirs:
+                history_dir = Path(root) / ".sync_history"
+                
+                # Process each file's history
+                for file_history in history_dir.iterdir():
+                    if file_history.is_dir():
+                        syncs = []
+                        
+                        # Collect all syncs for this file
+                        for sync_entry in file_history.iterdir():
+                            if sync_entry.is_dir() and sync_entry.name.endswith(".syftmessage"):
+                                timestamp = self._get_sync_timestamp(sync_entry)
+                                if timestamp:
+                                    syncs.append((timestamp, sync_entry))
+                        
+                        # Sort by timestamp
+                        syncs.sort(key=lambda x: x[0])
+                        
+                        # Remove all but the latest if keep_latest is True
+                        to_remove = syncs[:-1] if keep_latest and syncs else syncs
+                        
+                        for _, sync_path in to_remove:
+                            try:
+                                shutil.rmtree(sync_path)
+                                cleaned_count += 1
+                            except Exception as e:
+                                if self.verbose:
+                                    print(f"‚ö†Ô∏è  Could not remove sync history: {e}")
+        
+        if self.verbose and cleaned_count > 0:
+            print(f"üßπ Cleaned {cleaned_count} old sync history entries")
+        
+        return cleaned_count
+
+    def _extract_message_directly(self, message_path: Path, datasites_dir: Path) -> Dict[str, int]:
+        """
+        Extract files directly from a message without creating SyftMessage object
+        
+        Args:
+            message_path: Path to the message directory
+            datasites_dir: Path to datasites directory
+            
+        Returns:
+            Dict with counts of files processed
+        """
+        # print("MERGE-8a " + str(time.time()))
+        stats = {
+            "files_merged": 0,
+            "files_overwritten": 0,
+            "errors": 0
+        }
+        
+        # Check memory cache first
+        message_id = str(message_path.name)
+        metadata = None
+        
+        # print("MERGE-8a1 " + str(time.time()))
+        if message_id in self._metadata_cache:
+            # Use cached metadata (instant!)
+            metadata = self._metadata_cache[message_id]
+            # print("MERGE-8b-cached " + str(time.time()))
+        else:
+            # Need to read from disk
+            json_metadata_path = str(message_path) + "/metadata.json"  # String ops
+            yaml_metadata_path = str(message_path) + "/metadata.yaml"
+            
+            # print("MERGE-8b " + str(time.time()))
+            
+            # Try JSON first (no existence check - just try to open)
+            try:
+                with open(json_metadata_path, 'r') as f:
+                    # print("MERGE-8b-json-opened " + str(time.time()))
+                    metadata = json.load(f)
+                    # print("MERGE-8b2-json " + str(time.time()))
+                    # Cache it
+                    self._metadata_cache[message_id] = metadata
+            except FileNotFoundError:
+                # print("MERGE-8b-json-not-found " + str(time.time()))
+                # JSON doesn't exist, try YAML
+                try:
+                    # print("MERGE-8b1-yaml-start " + str(time.time()))
+                    with open(yaml_metadata_path, 'r') as f:
+                        metadata = yaml.safe_load(f) or {}
+                    # print("MERGE-8b2-yaml " + str(time.time()))
+                    # Cache it
+                    self._metadata_cache[message_id] = metadata
+                    
+                    # Convert to JSON for next time (write in background to not block)
+                    try:
+                        def write_json_cache():
+                            time.sleep(0.2)  # Delay to avoid I/O contention
+                            with open(json_metadata_path, 'w') as f:
+                                json.dump(metadata, f, indent=2)
+                        
+                        # Start background thread to write JSON cache
+                        cache_thread = threading.Thread(target=write_json_cache)
+                        cache_thread.daemon = True
+                        cache_thread.start()
+                    except:
+                        pass  # Ignore cache write errors
+                except FileNotFoundError:
+                    # Neither file exists
+                    return stats
+            except Exception as e:
+                stats["errors"] += 1
+                return stats
+        
+        if not metadata:
+            return stats
+        
+        # print("MERGE-8c " + str(time.time()))
+        # Get sender for logging
+        sender = metadata.get("from", "unknown")
+        # print("MERGE-8c1 " + str(time.time()))
+        if self.verbose:
+            print(f"\n   üì¶ Processing message from {sender}")
+        
+        # print("MERGE-8c2 " + str(time.time()))
+        
+        # Check if this is a deletion message
+        action = metadata.get("action", "update")
+        
+        if action == "delete":
+            # Handle deletion
+            files_info = metadata.get("files", [])
+            stats["files_deleted"] = 0
+            
+            for file_entry in files_info:
+                try:
+                    file_path = file_entry["path"]
+                    
+                    # Check if path starts with "datasites/"
+                    if not file_path.startswith("datasites/"):
+                        print(f"      ‚ö†Ô∏è  Skipping deletion with non-datasites path: {file_path}")
+                        continue
+                    
+                    # Calculate local path
+                    relative_path = file_path[len("datasites/"):]
+                    dest_path = Path(datasites_dir) / relative_path
+                    
+                    if dest_path.exists():
+                        # Optional: verify hash if provided
+                        expected_hash = file_entry.get("hash")
+                        if expected_hash:
+                            actual_hash = self._compute_file_hash(dest_path)
+                            if actual_hash != expected_hash:
+                                print(f"      ‚ö†Ô∏è  Skipping deletion - file has different content: {relative_path}")
+                                continue
+                        
+                        # Store in sync history before deleting
+                        self._store_sync_history(dest_path, message_path)
+                        
+                        # Delete the file
+                        dest_path.unlink()
+                        stats["files_deleted"] += 1
+                        
+                        if self.verbose:
+                            print(f"      üóëÔ∏è  Deleted: {relative_path}")
+                    else:
+                        if self.verbose:
+                            print(f"      ‚è≠Ô∏è  File already deleted: {relative_path}")
+                            
+                except Exception as e:
+                    print(f"      ‚ùå Error deleting file: {e}")
+                    stats["errors"] += 1
+            
+            # Return early for deletion messages
+            return stats
+        
+        # Process files directly (for create/update messages)
+        files_info = metadata.get("files", [])
+        # print("MERGE-8c3 " + str(time.time()))
+        
+        # Use string operations instead of Path objects
+        files_dir_str = str(message_path) + "/data/files"
+        datasites_dir_str = str(datasites_dir)
+        
+        # print("MERGE-8d " + str(time.time()))
+        
+        # First pass: validate and prepare all operations
+        operations = []
+        for file_entry in files_info:
+            try:
+                file_path = file_entry["path"]
+                
+                # Check if path starts with "datasites/"
+                if not file_path.startswith("datasites/"):
+                    print(f"      ‚ö†Ô∏è  Skipping file with non-datasites path: {file_path}")
+                    continue
+                
+                # Get source and destination paths using strings
+                internal_name = file_entry.get("_internal_name", os.path.basename(file_path))
+                source_path_str = files_dir_str + "/" + internal_name
+                
+                # Calculate destination
+                relative_path = file_path[len("datasites/"):]
+                dest_path_str = datasites_dir_str + "/" + relative_path
+                
+                operations.append({
+                    'source': source_path_str,
+                    'dest': dest_path_str,
+                    'relative_path': relative_path
+                })
+            except Exception as e:
+                print(f"      ‚ùå Error preparing file: {e}")
+                stats["errors"] += 1
+        
+        # print("MERGE-8e " + str(time.time()))
+        
+        # Pre-compute unique parent directories using string operations
+        unique_parents = set()
+        for op in operations:
+            parent_dir = os.path.dirname(op['dest'])
+            unique_parents.add(parent_dir)
+        
+        # Create directories only if not already created
+        for parent_dir in unique_parents:
+            if parent_dir not in self._dir_structure:
+                try:
+                    os.makedirs(parent_dir, exist_ok=True)
+                    self._dir_structure.add(parent_dir)
+                except:
+                    pass  # Directory might already exist
+        
+        # print("MERGE-8e2 " + str(time.time()))
+        
+        # Second pass: Use hard links (instant!) instead of move
+        for op in operations:
+            try:
+                # Check sync history before applying
+                dest_path = Path(op['dest'])
+                if not self._should_apply_sync(dest_path, message_path):
+                    stats["messages_skipped"] = stats.get("messages_skipped", 0) + 1
+                    continue
+                
+                # Try hard link first (instant operation)
+                try:
+                    os.link(op['source'], op['dest'])
+                    stats["files_merged"] += 1
+                    if self.verbose:
+                        print(f"      ‚úì Linked: {op['relative_path']}")
+                    # Store in sync history after successful merge
+                    self._store_sync_history(dest_path, message_path)
+                except FileExistsError:
+                    # Destination exists, remove and retry
+                    os.unlink(op['dest'])
+                    os.link(op['source'], op['dest'])
+                    stats["files_overwritten"] += 1
+                    if self.verbose:
+                        print(f"      ‚úì Re-linked: {op['relative_path']}")
+                    # Store in sync history after successful merge
+                    self._store_sync_history(dest_path, message_path)
+                except OSError as e:
+                    # Hard link failed (maybe cross-filesystem), fall back to move
+                    shutil.move(op['source'], op['dest'])
+                    stats["files_merged"] += 1
+                    if self.verbose:
+                        print(f"      ‚úì Moved: {op['relative_path']}")
+                    # Store in sync history after successful merge
+                    self._store_sync_history(dest_path, message_path)
+                        
+            except FileNotFoundError:
+                print(f"      ‚ùå Source file not found: {op['source']}")
+                stats["errors"] += 1
+            except Exception as e:
+                print(f"      ‚ùå Error linking file: {e}")
+                stats["errors"] += 1
+        
+        # print("MERGE-8f " + str(time.time()))
+        return stats
+    
+    def merge_new_syncs(self, syftbox_dir: Optional[Path] = None) -> Dict[str, int]:
+        """
+        Merge approved SyftMessages into the datasites directory
+        
+        This method:
+        1. Reads all SyftMessage folders from the approved directory
+        2. Validates each message
+        3. Extracts files to their correct locations in datasites
+        4. Overwrites existing files if they exist
+        
+        Args:
+            syftbox_dir: Optional SyftBox directory path (defaults to get_syftbox_directory())
+            
+        Returns:
+            Dict with counts of processed messages and files
+        """
+        from .syft_message import SyftMessage
+        import shutil
+        from collections import defaultdict
+        
+        # print("MERGE-1 " + str(time.time()))
+        self._ensure_authenticated()
+        # print("MERGE-2 " + str(time.time()))
+        
+        # Get SyftBox directory
+        if syftbox_dir is None:
+            # print("MERGE-3 " + str(time.time()))
+            syftbox_dir = self.get_syftbox_directory()
+            # print("MERGE-4 " + str(time.time()))
+            if syftbox_dir is None:
+                print("‚ùå Could not determine SyftBox directory")
+                return {}
+        
+        # Ensure we're working with the correct user's SyftBox
+        expected_dir_name = f"SyftBox_{self.my_email}"
+        if syftbox_dir.name != expected_dir_name:
+            print(f"‚ùå SyftBox directory name mismatch. Expected '{expected_dir_name}' but got '{syftbox_dir.name}'")
+            return {}
+        
+        approved_dir = syftbox_dir / "approved"
+        datasites_dir = syftbox_dir / "datasites"
+        
+        # Check if approved directory exists
+        # print("MERGE-5 " + str(time.time()))
+        if not approved_dir.exists():
+            print(f"üì• No approved directory found at {approved_dir}")
+            return {}
+        
+        # Create datasites directory if it doesn't exist
+        # print("MERGE-6 " + str(time.time()))
+        datasites_dir.mkdir(exist_ok=True)
+        
+        # Track statistics
+        stats = {
+            "messages_processed": 0,
+            "messages_skipped": 0,
+            "files_merged": 0,
+            "files_overwritten": 0,
+            "errors": 0
+        }
+        if self.verbose:
+            print(f"üîÑ Merging approved syncs to {datasites_dir}")
+        
+        # Process each item in approved directory using faster os.scandir
+        # print("MERGE-7 " + str(time.time()))
+        items_processed = 0
+        with os.scandir(str(approved_dir)) as entries:
+            for entry in entries:
+                
+                try:
+                    # Skip non-directories
+                    if not entry.is_dir():
+                        continue
+                    
+                    items_processed += 1
+                    if items_processed == 1:
+                        # print("MERGE-7a-first-item " + str(time.time()))
+                        pass
+                    
+                    # print("MERGE-8 " + str(time.time()))
+                    
+                    # Convert DirEntry to Path for compatibility
+                    item = Path(entry.path)
+                    
+                    # Use optimized direct extraction (no SyftMessage object)
+                    file_stats = self._extract_message_directly(item, datasites_dir)
+                    
+                    # print("MERGE-9 " + str(time.time()))
+                    
+                    # Update overall stats
+                    stats["files_merged"] += file_stats["files_merged"]
+                    stats["files_overwritten"] += file_stats["files_overwritten"]
+                    stats["errors"] += file_stats["errors"]
+                    if "files_deleted" in file_stats:
+                        stats["files_deleted"] = stats.get("files_deleted", 0) + file_stats["files_deleted"]
+                    
+                    # Check if any files were skipped due to sync history
+                    files_skipped_due_to_history = file_stats.get("messages_skipped", 0)
+                    
+                    if file_stats["files_merged"] > 0 or file_stats["files_overwritten"] > 0:
+                        stats["messages_processed"] += 1
+                    elif files_skipped_due_to_history > 0:
+                        # Message was skipped due to sync history
+                        stats["messages_skipped"] += 1
+                    else:
+                        stats["messages_skipped"] += 1
+                    
+                    # Move processed message to merged_archive
+                    # print("MERGE-10 " + str(time.time()))
+                    merged_archive_dir = syftbox_dir / "merged_archive"
+                    merged_archive_dir.mkdir(exist_ok=True)
+                    
+                    try:
+                        archive_path = merged_archive_dir / item.name
+                    
+                        # If archive already exists, remove it first
+                        if archive_path.exists():
+                            if archive_path.is_dir():
+                                shutil.rmtree(archive_path)
+                            else:
+                                archive_path.unlink()
+                        
+                        # Move to archive (instant operation)
+                        # print("MERGE-11 " + str(time.time()))
+                        shutil.move(str(item), str(archive_path))
+                        # print("MERGE-12 " + str(time.time()))
+                        
+                        # The original folder is now empty (files were moved)
+                        # Schedule async re-extraction from the archive file if it exists
+                        archive_file = None
+                        # Look for corresponding .tar.gz file in archive or inbox
+                        for archive_dir in [syftbox_dir / "archive", syftbox_dir / "inbox"]:
+                            if archive_dir.exists():
+                                potential_archive = archive_dir / f"{item.name}.tar.gz"
+                                if potential_archive.exists():
+                                    archive_file = potential_archive
+                                    break
+                        
+                        # Since we used hard links, the files still exist in approved
+                        # We don't need to restore from archive immediately
+                        # Just clean up if the directory is truly empty
+                        try:
+                            # Check if directory has any remaining files/subdirs
+                            if not any(item.iterdir()):
+                                item.rmdir()  # Remove if empty
+                        except:
+                            pass  # Directory not empty or other error
+                        
+                        if self.verbose:
+                            print(f"   üìÅ Moved to merged_archive/{item.name}")
+                            
+                    except Exception as archive_error:
+                        print(f"   ‚ö†Ô∏è  Could not archive {item.name}: {archive_error}")
+                    
+                except Exception as e:
+                    print(f"   ‚ùå Error processing {item.name}: {e}")
+                    stats["errors"] += 1
+        
+        # Print summary
+        # print("MERGE-13 " + str(time.time()))
+        if self.verbose:
+            print(f"\n‚úÖ Merge completed:")
+            print(f"   - Messages processed: {stats['messages_processed']}")
+            print(f"   - Messages skipped: {stats['messages_skipped']}")
+            print(f"   - Files merged: {stats['files_merged']}")
+            print(f"   - Files overwritten: {stats['files_overwritten']}")
+            if "files_deleted" in stats and stats['files_deleted'] > 0:
+                print(f"   - Files deleted: {stats['files_deleted']}")
+            if stats['errors'] > 0:
+                print(f"   - Errors: {stats['errors']}")
+        
+        # print("MERGE-14 " + str(time.time()))
+        return stats
+    
+    def _download_folder_recursive(self, folder_id: str, local_parent: str, folder_name: str) -> bool:
+        """
+        Recursively download a folder and its contents from Google Drive
+        
+        Args:
+            folder_id: Google Drive folder ID
+            local_parent: Local parent directory
+            folder_name: Name for the local folder
+            
+        Returns:
+            True if successful, False otherwise
+        """
+        self._ensure_authenticated()
+        
+        local_folder_path = os.path.join(local_parent, folder_name)
+        
+        try:
+            # Create local folder
+            os.makedirs(local_folder_path, exist_ok=True)
+            
+            # List all items in the folder
+            results = self.service.files().list(
+                q=f"'{folder_id}' in parents and trashed=false",
+                fields="files(id, name, mimeType)"
+            ).execute()
+            
+            items = results.get('files', [])
+            
+            # Separate items into folders and files
+            folders = []
+            files = []
+            
+            for item in items:
+                if item['mimeType'] == 'application/vnd.google-apps.folder':
+                    folders.append(item)
+                else:
+                    files.append(item)
+            
+            # Download subfolders
+            for item in folders:
+                if not self._download_folder_recursive(item['id'], local_folder_path, item['name']):
+                    print(f"   ‚ö†Ô∏è  Failed to download folder: {item['name']}")
+            
+            # Download files
+            for item in files:
+                local_file_path = os.path.join(local_folder_path, item['name'])
+                if not self._download_file(item['id'], local_file_path):
+                    print(f"   ‚ö†Ô∏è  Failed to download file: {item['name']}")
+            
+            return True
+            
+        except Exception as e:
+            print(f"‚ùå Error downloading folder: {e}")
+            return False                
+
+    @property
+    def friends(self) -> List[str]:
+        """
+        List all friends (people you have set up outgoing channels to)
+        
+        Returns:
+            List of email addresses you've added as friends
+        """
+        if not self.authenticated:
+            return []
+        
+        if not self.my_email:
+            return []
+        
+        # Check if cache is valid (less than 1 hour old)
+        current_time = time.time()
+        if (self._friends_cache is not None and 
+            self._friends_cache_time is not None and 
+            current_time - self._friends_cache_time < 3600):  # 3600 seconds = 1 hour
+            return self._friends_cache
+        
+        try:
+            # First check if SyftBoxTransportService exists using cache
+            syftbox_id = self._get_syftbox_folder_id()
+            
+            if not syftbox_id:
+                # No SyftBoxTransportService = no friends
+                return []
+            
+            friends_set = set()
+            
+            # Get folders inside SyftBoxTransportService
+            try:
+                results = self.service.files().list(
+                    q=f"'{syftbox_id}' in parents and name contains 'syft_' and mimeType='application/vnd.google-apps.folder' and trashed=false",
+                    fields="files(name)"
+                ).execute()
+                
+                for folder in results.get('files', []):
+                    name = folder['name']
+                    # Look for your outgoing folders
+                    if name.startswith(f'syft_{self.my_email}_to_'):
+                        # Extract the recipient email
+                        parts = name.split('_to_')
+                        if len(parts) == 2:
+                            # Remove the suffix (_pending, _outbox_inbox, etc)
+                            email_with_suffix = parts[1]
+                            # Handle both _outbox_inbox and _outbox suffixes
+                            if '_outbox_inbox' in email_with_suffix:
+                                email_part = email_with_suffix.replace('_outbox_inbox', '')
+                            elif '_outbox' in email_with_suffix:
+                                email_part = email_with_suffix.replace('_outbox', '')
+                            elif '_pending' in email_with_suffix:
+                                email_part = email_with_suffix.replace('_pending', '')
+                            elif '_archive' in email_with_suffix:
+                                email_part = email_with_suffix.replace('_archive', '')
+                            else:
+                                # No known suffix, try generic approach
+                                email_part = email_with_suffix.rsplit('_', 1)[0]
+                            friends_set.add(email_part)
+            except:
+                pass
+            
+            # Cache the results
+            self._friends_cache = sorted(list(friends_set))
+            self._friends_cache_time = time.time()
+            return self._friends_cache
+            
+        except Exception as e:
+            if self.verbose:
+                print(f"‚ùå Error listing friends: {e}")
+            # Return cached value if available, even if expired
+            if self._friends_cache is not None:
+                return self._friends_cache
+            return []
+    
+    @property
+    def friend_requests(self) -> List[str]:
+        """
+        List emails of people who have shared folders with you but you haven't shared back
+        
+        Returns:
+            List of email addresses with pending friend requests
+        """
+        if not self.authenticated:
+            return []
+        
+        if not self.my_email:
+            return []
+        
+        try:
+            # Get all syft folders
+            all_folders = self._list_syft_folders()
+            
+            # Track who has shared with us
+            shared_with_me = set()
+            # Track who we've shared with
+            shared_by_me = set()
+            
+            # Check folders in "Shared with me" - these are folders others created
+            for folder in all_folders['shared_with_me']:
+                name = folder['name']
+                if '_to_' in name and name.startswith('syft_'):
+                    parts = name.split('_to_')
+                    if len(parts) == 2:
+                        sender = parts[0].replace('syft_', '')
+                        recipient_with_suffix = parts[1]
+                        
+                        # Remove suffixes
+                        if '_outbox_inbox' in recipient_with_suffix:
+                            recipient = recipient_with_suffix.replace('_outbox_inbox', '')
+                        elif '_outbox' in recipient_with_suffix:
+                            recipient = recipient_with_suffix.replace('_outbox', '')
+                        elif '_pending' in recipient_with_suffix:
+                            recipient = recipient_with_suffix.replace('_pending', '')
+                        elif '_archive' in recipient_with_suffix:
+                            recipient = recipient_with_suffix.replace('_archive', '')
+                        else:
+                            recipient = recipient_with_suffix.rsplit('_', 1)[0]
+                        
+                        # If they're sharing with us, track them
+                        if recipient == self.my_email:
+                            shared_with_me.add(sender)
+            
+            # Check if SyftBoxTransportService exists using cache
+            syftbox_id = self._get_syftbox_folder_id()
+            
+            if syftbox_id:
+                # Get folders inside SyftBoxTransportService
+                try:
+                    results = self.service.files().list(
+                        q=f"'{syftbox_id}' in parents and name contains 'syft_' and mimeType='application/vnd.google-apps.folder' and trashed=false",
+                        fields="files(name)"
+                    ).execute()
+                    
+                    for folder in results.get('files', []):
+                        name = folder['name']
+                        # Look for folders we created (either outgoing or archive for incoming)
+                        if name.startswith(f'syft_{self.my_email}_to_'):
+                            # This is our outgoing folder
+                            parts = name.split('_to_')
+                            if len(parts) == 2:
+                                email_with_suffix = parts[1]
+                                
+                                # Remove suffixes
+                                if '_outbox_inbox' in email_with_suffix:
+                                    email_part = email_with_suffix.replace('_outbox_inbox', '')
+                                elif '_outbox' in email_with_suffix:
+                                    email_part = email_with_suffix.replace('_outbox', '')
+                                elif '_pending' in email_with_suffix:
+                                    email_part = email_with_suffix.replace('_pending', '')
+                                elif '_archive' in email_with_suffix:
+                                    email_part = email_with_suffix.replace('_archive', '')
+                                else:
+                                    email_part = email_with_suffix.rsplit('_', 1)[0]
+                                
+                                shared_by_me.add(email_part)
+                        elif '_to_' in name and name.endswith(f'_to_{self.my_email}_archive'):
+                            # This is an archive folder we created for someone else's messages
+                            parts = name.split('_to_')
+                            if len(parts) == 2:
+                                sender = parts[0].replace('syft_', '')
+                                # We have an archive for them, so we've reciprocated
+                                shared_by_me.add(sender)
+                except:
+                    pass
+            
+            # Friend requests = people who shared with us but we haven't shared back
+            friend_requests = shared_with_me - shared_by_me
+            
+            return sorted(list(friend_requests))
+            
+        except Exception as e:
+            if self.verbose:
+                print(f"‚ùå Error listing friend requests: {e}")
+            return []
+    
+    def _list_syft_folders(self, print_summary: bool = False) -> Dict[str, List[Dict]]:
+        """
+        List all folders starting with 'syft_' in both My Drive and Shared with me
+        
+        Args:
+            print_summary: Whether to print a summary of found folders (default: False)
+            
+        Returns:
+            Dictionary with 'my_drive' and 'shared_with_me' lists
+        """
+        self._ensure_authenticated()
+        
+        result = {
+            'my_drive': [],
+            'shared_with_me': []
+        }
+        
+        try:
+            # First, find all syft_ folders in My Drive
+            if print_summary:
+                print("üîç Searching for syft_ folders in My Drive...")
+            my_drive_results = self.service.files().list(
+                q="name contains 'syft_' and mimeType='application/vnd.google-apps.folder' and trashed=false",
+                fields="files(id, name, parents, permissions, owners)",
+                pageSize=100
+            ).execute()
+            
+            for folder in my_drive_results.get('files', []):
+                # Only include folders that START with syft_
+                if not folder['name'].startswith('syft_'):
+                    continue
+                    
+                # Get parent folder name
+                parent_name = "root"
+                if folder.get('parents'):
+                    try:
+                        parent = self.service.files().get(
+                            fileId=folder['parents'][0],
+                            fields='name'
+                        ).execute()
+                        parent_name = parent.get('name', 'unknown')
+                    except:
+                        parent_name = "unknown"
+                
+                folder_info = {
+                    'id': folder['id'],
+                    'name': folder['name'],
+                    'parent': parent_name,
+                    'owner': folder.get('owners', [{}])[0].get('emailAddress', 'unknown')
+                }
+                result['my_drive'].append(folder_info)
+            
+            # Now search in Shared with me
+            if print_summary:
+                print("\nüîç Searching for syft_ folders in Shared with me...")
+            shared_results = self.service.files().list(
+                q="name contains 'syft_' and mimeType='application/vnd.google-apps.folder' and sharedWithMe and trashed=false",
+                fields="files(id, name, permissions, owners)",
+                pageSize=100
+            ).execute()
+            
+            for folder in shared_results.get('files', []):
+                # Only include folders that START with syft_
+                if not folder['name'].startswith('syft_'):
+                    continue
+                    
+                folder_info = {
+                    'id': folder['id'],
+                    'name': folder['name'],
+                    'owner': folder.get('owners', [{}])[0].get('emailAddress', 'unknown'),
+                    'shared': True
+                }
+                result['shared_with_me'].append(folder_info)
+            
+            # Print summary if requested
+            if print_summary and self.verbose:
+                print(f"\nüìÅ Found {len(result['my_drive'])} syft_ folders in My Drive:")
+                for folder in result['my_drive']:
+                    print(f"   - {folder['name']}")
+                    print(f"     Parent: {folder['parent']}")
+                    print(f"     Owner: {folder['owner']}")
+                    print(f"     ID: {folder['id']}")
+                
+                print(f"\nü§ù Found {len(result['shared_with_me'])} syft_ folders in Shared with me:")
+                for folder in result['shared_with_me']:
+                    print(f"   - {folder['name']}")
+                    print(f"     Owner: {folder['owner']}")
+                    print(f"     ID: {folder['id']}")
+                
+                # Check for incoming channels without shortcuts
+                if result['shared_with_me']:
+                    print("\nüí° Incoming channels that might need shortcuts:")
+                    for folder in result['shared_with_me']:
+                        if '_to_' in folder['name'] and self.my_email:
+                            if f"_to_{self.my_email}_" in folder['name']:
+                                print(f"   - {folder['name']} (from {folder['owner']})")
+            
+            return result
+            
+        except HttpError as e:
+            if print_summary:
+                print(f"‚ùå Error listing syft folders: {e}")
+            return result
+    
+    def _create_shortcuts_for_friend(self, friend_email: str, syftbox_id: Optional[str] = None) -> Dict[str, int]:
+        """
+        Create shortcuts in SyftBoxTransportService for folders shared by a specific friend
+        
+        Args:
+            friend_email: Email of the friend whose folders to create shortcuts for
+            syftbox_id: Optional SyftBoxTransportService folder ID (will find if not provided)
+            
+        Returns:
+            Dictionary with counts of shortcuts created, skipped, and failed
+        """
+        self._ensure_authenticated()
+        
+        results = {
+            'created': 0,
+            'skipped': 0,
+            'failed': 0
+        }
+        
+        try:
+            # Get or find SyftBox folder
+            if not syftbox_id:
+                syftbox_id = self.setup_syftbox()
+                if not syftbox_id:
+                    return results
+            
+            # Find folders shared by this friend
+            shared_results = self.service.files().list(
+                q=f"name contains 'syft_{friend_email}_to_' and mimeType='application/vnd.google-apps.folder' and sharedWithMe and trashed=false",
+                fields="files(id, name)",
+                pageSize=100
+            ).execute()
+            
+            # Get existing shortcuts in SyftBox to avoid duplicates
+            existing_shortcuts = {}
+            try:
+                existing_results = self.service.files().list(
+                    q=f"'{syftbox_id}' in parents and mimeType='application/vnd.google-apps.shortcut' and trashed=false",
+                    fields="files(name, shortcutDetails)"
+                ).execute()
+                
+                for shortcut in existing_results.get('files', []):
+                    target_id = shortcut.get('shortcutDetails', {}).get('targetId')
+                    if target_id:
+                        existing_shortcuts[target_id] = shortcut['name']
+            except:
+                pass
+            
+            # Create shortcuts for each shared folder
+            for folder in shared_results.get('files', []):
+                if not folder['name'].startswith('syft_'):
+                    continue
+                    
+                folder_id = folder['id']
+                folder_name = folder['name']
+                
+                # Check if shortcut already exists
+                if folder_id in existing_shortcuts:
+                    results['skipped'] += 1
+                    continue
+                
+                # Create shortcut
+                try:
+                    shortcut_metadata = {
+                        'name': folder_name,
+                        'mimeType': 'application/vnd.google-apps.shortcut',
+                        'parents': [syftbox_id],
+                        'shortcutDetails': {
+                            'targetId': folder_id
+                        }
+                    }
+                    
+                    self.service.files().create(
+                        body=shortcut_metadata,
+                        fields='id'
+                    ).execute()
+                    
+                    results['created'] += 1
+                    
+                except Exception as e:
+                    results['failed'] += 1
+            
+            return results
+            
+        except Exception as e:
+            return results
+    
+    def _create_shortcuts_for_shared_folders(self, verbose: bool = True) -> Dict[str, int]:
+        """
+        Create shortcuts in SyftBoxTransportService for all syft_ folders in 'Shared with me'
+        
+        Args:
+            verbose: Whether to print detailed progress messages (default: True)
+        
+        Returns:
+            Dictionary with counts of shortcuts created, skipped, and failed
+        """
+        self._ensure_authenticated()
+        
+        results = {
+            'created': 0,
+            'skipped': 0,
+            'failed': 0
+        }
+        
+        try:
+            # First ensure SyftBox exists
+            syftbox_id = self.setup_syftbox()
+            if not syftbox_id:
+                print("‚ùå Could not create/find SyftBoxTransportService folder")
+                return results
+            
+            # Get list of all syft_ folders (default is silent)
+            all_folders = self._list_syft_folders()
+            shared_folders = all_folders['shared_with_me']
+            
+            if not shared_folders:
+                if verbose:
+                    print("‚úÖ No shared syft_ folders found that need shortcuts")
+                return results
+            
+            if verbose:
+                print(f"\nüîó Creating shortcuts for {len(shared_folders)} shared folders...")
+            
+            # Get existing shortcuts in SyftBoxTransportService to avoid duplicates
+            existing_shortcuts = {}
+            try:
+                existing = self.service.files().list(
+                    q=f"'{syftbox_id}' in parents and mimeType='application/vnd.google-apps.shortcut' and trashed=false",
+                    fields="files(id, name, shortcutDetails)"
+                ).execute()
+                
+                for shortcut in existing.get('files', []):
+                    details = shortcut.get('shortcutDetails', {})
+                    target_id = details.get('targetId')
+                    if target_id:
+                        existing_shortcuts[target_id] = shortcut['name']
+            except:
+                pass
+            
+            # Create shortcuts for each shared folder
+            for folder in shared_folders:
+                folder_name = folder['name']
+                folder_id = folder['id']
+                folder_owner = folder['owner']
+                
+                # Check if shortcut already exists
+                if folder_id in existing_shortcuts:
+                    if verbose:
+                        print(f"‚è≠Ô∏è  Skipping {folder_name} - shortcut already exists")
+                    results['skipped'] += 1
+                    continue
+                
+                # Check if folder name already exists in SyftBox (non-shortcut)
+                try:
+                    existing_folder = self.service.files().list(
+                        q=f"name='{folder_name}' and '{syftbox_id}' in parents and trashed=false",
+                        fields="files(id, mimeType)"
+                    ).execute()
+                    
+                    if existing_folder.get('files'):
+                        if verbose:
+                            print(f"‚è≠Ô∏è  Skipping {folder_name} - folder/shortcut with same name already exists")
+                        results['skipped'] += 1
+                        continue
+                except:
+                    pass
+                
+                # Create the shortcut
+                try:
+                    shortcut_metadata = {
+                        'name': folder_name,
+                        'mimeType': 'application/vnd.google-apps.shortcut',
+                        'parents': [syftbox_id],
+                        'shortcutDetails': {
+                            'targetId': folder_id,
+                            'targetMimeType': 'application/vnd.google-apps.folder'
+                        }
+                    }
+                    
+                    shortcut = self.service.files().create(
+                        body=shortcut_metadata,
+                        fields='id, name'
+                    ).execute()
+                    
+                    if verbose:
+                        print(f"‚úÖ Created shortcut for {folder_name} (from {folder_owner})")
+                    results['created'] += 1
+                    
+                except HttpError as e:
+                    if verbose:
+                        print(f"‚ùå Failed to create shortcut for {folder_name}: {e}")
+                    results['failed'] += 1
+            
+            # Summary - only show if verbose
+            if verbose and (results['created'] > 0 or results['failed'] > 0 or results['skipped'] > 0):
+                print(f"\nüìä Shortcut creation summary:")
+                print(f"   ‚úÖ Created: {results['created']}")
+                print(f"   ‚è≠Ô∏è  Skipped: {results['skipped']}")
+                print(f"   ‚ùå Failed: {results['failed']}")
+                
+                if results['created'] > 0:
+                    print(f"\nüéâ Successfully linked {results['created']} shared folders to SyftBoxTransportService!")
+                    print(f"üîó View in Google Drive: https://drive.google.com/drive/folders/{syftbox_id}")
+            
+            return results
+            
+        except HttpError as e:
+            print(f"‚ùå Error creating shortcuts: {e}")
+            return results
+
+# Convenience function for quick setup
+    # ========== Google Sheets Transport Methods ==========
+    
+    def _archive_sheet_messages_async(self, sheet_id: str, row_numbers: List[int]):
+        """
+        Move downloaded messages to Archive tab in background
+        
+        Args:
+            sheet_id: The spreadsheet ID
+            row_numbers: List of row numbers to archive
+        """
+        # print("ARCHIVE-1 " + str(time.time()))
+        def archive_worker():
+            # print("ARCHIVE-2 " + str(time.time()))
+            try:
+                # print("ARCHIVE-3 " + str(time.time()))
+                sheets_service = build('sheets', 'v4', credentials=self.creds)
+                # print("ARCHIVE-4 " + str(time.time()))
+                
+                # First, ensure Archive tab exists
+                try:
+                    # Check cache for spreadsheet info
+                    # print("ARCHIVE-5 " + str(time.time()))
+                    spreadsheet = None
+                    if sheet_id in self._spreadsheet_info_cache and sheet_id in self._spreadsheet_info_cache_time:
+                        cache_age_minutes = (datetime.now() - self._spreadsheet_info_cache_time[sheet_id]).total_seconds() / 60
+                        if cache_age_minutes < 60:  # Cache valid for 1 hour
+                            spreadsheet = self._spreadsheet_info_cache[sheet_id]
+                    
+                    # If not cached, fetch from API
+                    if not spreadsheet:
+                        # print("ARCHIVE-6 " + str(time.time()))
+                        spreadsheet = sheets_service.spreadsheets().get(
+                            spreadsheetId=sheet_id,
+                            fields='sheets.properties'
+                        ).execute()
+                        # print("ARCHIVE-7 " + str(time.time()))
+                        # Cache the result
+                        self._spreadsheet_info_cache[sheet_id] = spreadsheet
+                        self._spreadsheet_info_cache_time[sheet_id] = datetime.now()
+                    
+                    # Check if Archive sheet exists and get messages sheet ID
+                    archive_exists = False
+                    messages_sheet_id = None
+                    for sheet in spreadsheet.get('sheets', []):
+                        if sheet['properties']['title'] == 'archive':
+                            archive_exists = True
+                        elif sheet['properties']['title'] == 'messages':
+                            messages_sheet_id = sheet['properties']['sheetId']
+                    
+                    # Create Archive sheet if it doesn't exist
+                    # print("ARCHIVE-8 " + str(time.time()))
+                    if not archive_exists:
+                        request = {
+                            'addSheet': {
+                                'properties': {
+                                    'title': 'archive',
+                                    'gridProperties': {
+                                        'columnCount': 4,
+                                        'frozenRowCount': 1
+                                    }
+                                }
+                            }
+                        }
+                        
+                        # print("ARCHIVE-9 " + str(time.time()))
+                        sheets_service.spreadsheets().batchUpdate(
+                            spreadsheetId=sheet_id,
+                            body={'requests': [request]}
+                        ).execute()
+                        # print("ARCHIVE-10 " + str(time.time()))
+                        
+                        # No header row in archive either
+                        
+                        if self.verbose:
+                            print(f"   üìÅ Created Archive tab")
+                        
+                        # Invalidate the spreadsheet cache since we modified it
+                        if sheet_id in self._spreadsheet_info_cache:
+                            del self._spreadsheet_info_cache[sheet_id]
+                            del self._spreadsheet_info_cache_time[sheet_id]
+                
+                except Exception as e:
+                    print(f"   ‚ö†Ô∏è  Error creating archive tab: {e}")
+                    return
+                
+                # Get the rows to archive
+                # print("ARCHIVE-11 " + str(time.time()))
+                ranges = [f'messages!A{row}:E{row}' for row in sorted(row_numbers)]
+                
+                # Batch get all rows
+                # print("ARCHIVE-12 " + str(time.time()))
+                result = sheets_service.spreadsheets().values().batchGet(
+                    spreadsheetId=sheet_id,
+                    ranges=ranges
+                ).execute()
+                # print("ARCHIVE-13 " + str(time.time()))
+                
+                rows_to_archive = []
+                for value_range in result.get('valueRanges', []):
+                    values = value_range.get('values', [])
+                    if values:
+                        rows_to_archive.extend(values)
+                
+                if rows_to_archive:
+                    # Append to archive
+                    # print("ARCHIVE-14 " + str(time.time()))
+                    sheets_service.spreadsheets().values().append(
+                        spreadsheetId=sheet_id,
+                        range='archive!A:D',
+                        valueInputOption='USER_ENTERED',
+                        insertDataOption='INSERT_ROWS',
+                        body={'values': rows_to_archive}
+                    ).execute()
+                    # print("ARCHIVE-15 " + str(time.time()))
+                    
+                    # Clear the original rows - batch all deletes into one request
+                    if messages_sheet_id is not None:
+                        # Sort row numbers and group consecutive rows for efficient deletion
+                        sorted_rows = sorted(row_numbers, reverse=True)
+                        delete_requests = []
+                        
+                        # Create a delete request for each row (from bottom to top)
+                        for row_num in sorted_rows:
+                            delete_requests.append({
+                                'deleteDimension': {
+                                    'range': {
+                                        'sheetId': messages_sheet_id,
+                                        'dimension': 'ROWS',
+                                        'startIndex': row_num - 1,  # 0-based
+                                        'endIndex': row_num
+                                    }
+                                }
+                            })
+                        
+                        # Execute all deletes in a single batch
+                        if delete_requests:
+                            # print("ARCHIVE-16 " + str(time.time()))
+                            sheets_service.spreadsheets().batchUpdate(
+                                spreadsheetId=sheet_id,
+                                body={'requests': delete_requests}
+                            ).execute()
+                            # print("ARCHIVE-17 " + str(time.time()))
+                        
+                        if self.verbose:
+                            print(f"   üóÑÔ∏è  Archived {len(rows_to_archive)} messages to Archive tab")
+                    else:
+                        print(f"   ‚ö†Ô∏è  Could not find messages sheet ID for archiving")
+                        
+            except Exception as e:
+                print(f"   ‚ö†Ô∏è  Error archiving messages: {e}")
+        
+        # Start background thread with a small delay to avoid GIL contention
+        # print("ARCHIVE-18 " + str(time.time()))
+        def delayed_start():
+            time.sleep(0.1)  # Small delay to let main operation complete
+            archive_worker()
+        
+        thread = threading.Thread(target=delayed_start, daemon=True)
+        thread.start()
+        # print("ARCHIVE-19 " + str(time.time()))
+    
+    def _find_message_sheet(self, sheet_name: str, from_email: str = None) -> Optional[str]:
+        """
+        Find an existing Google Sheet for messages (without creating)
+        
+        Args:
+            sheet_name: Name of the sheet to find
+            from_email: Email of the sender (to search in shared files)
+            
+        Returns:
+            Spreadsheet ID if found, None otherwise
+        """
+        # print("FINDSHEET-1 " + str(time.time()))
+        self._ensure_authenticated()
+        # print("FINDSHEET-2 " + str(time.time()))
+        
+        # Check cache first
+        # print("FINDSHEET-3 " + str(time.time()))
+        cache_key = f"{sheet_name}:{from_email or 'none'}"
+        if cache_key in self._sheet_cache and cache_key in self._sheet_cache_time:
+            cache_age_minutes = (datetime.now() - self._sheet_cache_time[cache_key]).total_seconds() / 60
+            if cache_age_minutes < 60:  # Cache valid for 1 hour
+                cached_id = self._sheet_cache[cache_key]
+                if self.verbose:
+                    print(f"   üìã Using cached sheet ID: {cached_id}")
+                return cached_id
+        
+        try:
+            # First, search in SyftBox folder (for shortcuts or owned sheets)
+        # print("FINDSHEET-4 " + str(time.time()))
+            syftbox_id = self._get_syftbox_folder_id()
+        # print("FINDSHEET-5 " + str(time.time()))
+            if syftbox_id:
+                # Search for existing sheet or shortcut
+        # print("FINDSHEET-6 " + str(time.time()))
+                results = self.service.files().list(
+                    q=f"name='{sheet_name}' and '{syftbox_id}' in parents and trashed=false",
+                    fields="files(id, mimeType, shortcutDetails)",
+                    pageSize=1
+                ).execute()
+        # print("FINDSHEET-7 " + str(time.time()))
+                
+                if results.get('files'):
+                    file_info = results['files'][0]
+                    # If it's a shortcut, return the target ID
+                    if file_info.get('shortcutDetails'):
+                        sheet_id = file_info['shortcutDetails']['targetId']
+                    else:
+                        sheet_id = file_info['id']
+                    
+                    # Cache the result
+                    self._sheet_cache[cache_key] = sheet_id
+                    self._sheet_cache_time[cache_key] = datetime.now()
+        # print("FINDSHEET-8 " + str(time.time()))
+                    return sheet_id
+            
+            # If not found in SyftBox folder and we have a sender email, 
+            # search in "Shared with me" from that specific user
+        # print("FINDSHEET-9 " + str(time.time()))
+            if from_email:
+                if self.verbose:
+                    print(f"   üîç Searching in files shared by {from_email}...")
+                
+                # Search for sheets shared by the sender
+        # print("FINDSHEET-10 " + str(time.time()))
+                results = self.service.files().list(
+                    q=f"name='{sheet_name}' and '{from_email}' in owners and mimeType='application/vnd.google-apps.spreadsheet' and sharedWithMe and trashed=false",
+                    fields="files(id, name)",
+                    pageSize=1
+                ).execute()
+        # print("FINDSHEET-11 " + str(time.time()))
+                
+                if results.get('files'):
+                    shared_sheet_id = results['files'][0]['id']
+                    if self.verbose:
+                        print(f"   ‚úÖ Found shared sheet: {shared_sheet_id}")
+                    
+                    # Create a shortcut in SyftBox folder if we have one
+                    if syftbox_id:
+                        try:
+                            shortcut_metadata = {
+                                'name': sheet_name,
+                                'mimeType': 'application/vnd.google-apps.shortcut',
+                                'shortcutDetails': {
+                                    'targetId': shared_sheet_id
+                                },
+                                'parents': [syftbox_id]
+                            }
+                            
+                            shortcut = self.service.files().create(
+                                body=shortcut_metadata,
+                                fields='id'
+                            ).execute()
+                            
+                            if self.verbose:
+                                print(f"   üîó Created shortcut in SyftBox folder")
+                        except Exception as e:
+                            if self.verbose:
+                                print(f"   ‚ö†Ô∏è  Could not create shortcut: {e}")
+                    
+                    # Cache the result
+                    self._sheet_cache[cache_key] = shared_sheet_id
+                    self._sheet_cache_time[cache_key] = datetime.now()
+        # print("FINDSHEET-12 " + str(time.time()))
+                    return shared_sheet_id
+            
+        # print("FINDSHEET-13 " + str(time.time()))
+            return None
+            
+        except Exception as e:
+            if self.verbose:
+                print(f"‚ùå Error finding sheet: {e}")
+            return None
+    
+    def _get_or_create_message_sheet(self, sheet_name: str, recipient_email: str = None) -> Optional[str]:
+        """
+        Get or create a Google Sheet for messages
+        
+        Args:
+            sheet_name: Name of the sheet (e.g., syft_alice_to_bob_messages)
+            recipient_email: Email of recipient to grant write access (optional)
+            
+        Returns:
+            Spreadsheet ID if successful
+        """
+        # print("GETSHEET-1 " + str(time.time()))
+        self._ensure_authenticated()
+        # print("GETSHEET-2 " + str(time.time()))
+        
+        # Check cache first for owned sheets
+        cache_key = f"owned:{sheet_name}"
+        if cache_key in self._sheet_cache and cache_key in self._sheet_cache_time:
+            cache_age_minutes = (datetime.now() - self._sheet_cache_time[cache_key]).total_seconds() / 60
+            if cache_age_minutes < 60:  # Cache valid for 1 hour
+                cached_id = self._sheet_cache[cache_key]
+                if self.verbose:
+                    print(f"   üìã Using cached owned sheet ID: {cached_id}")
+                return cached_id
+        
+        try:
+            # First check if sheet already exists in SyftBox folder
+            syftbox_id = self._get_syftbox_folder_id()
+            if not syftbox_id:
+                print("‚ùå SyftBox folder not found")
+                return None
+            # Search for existing sheet
+            results = self.service.files().list(
+                q=f"name='{sheet_name}' and '{syftbox_id}' in parents and mimeType='application/vnd.google-apps.spreadsheet' and trashed=false",
+                fields="files(id)",
+                pageSize=1
+            ).execute()
+            if results.get('files'):
+                sheet_id = results['files'][0]['id']
+                # Cache the result
+                self._sheet_cache[cache_key] = sheet_id
+                self._sheet_cache_time[cache_key] = datetime.now()
+                return sheet_id
+            # Create new sheet
+            try:
+                sheets_service = self._get_sheets_service()
+            except Exception as e:
+                print("‚ùå Google Sheets API not available. You may need to re-authenticate with sheets scope.")
+                print("   Run: client = login(email, force_relogin=True)")
+                return None
+            spreadsheet = {
+                'properties': {
+                    'title': sheet_name
+                },
+                'sheets': [{
+                    'properties': {
+                        'title': 'messages',
+                        'gridProperties': {
+                            'columnCount': 4
+                        }
+                    },
+                    # No initial data - no header row
+                }]
+            }
+            # Create the spreadsheet
+            sheet = sheets_service.spreadsheets().create(body=spreadsheet).execute()
+            sheet_id = sheet['spreadsheetId']
+            # Move to SyftBox folder
+            self.service.files().update(
+                fileId=sheet_id,
+                addParents=syftbox_id,
+                removeParents='root',
+                fields='id, parents'
+            ).execute()
+            # Grant recipient write access if specified
+            if recipient_email:
+                try:
+                    self._add_permission(sheet_id, recipient_email, role='writer', verbose=False)
+                    if self.verbose:
+                        print(f"   ‚úÖ Granted write access to {recipient_email}")
+                except Exception as e:
+                    if self.verbose:
+                        print(f"   ‚ö†Ô∏è  Could not grant access to {recipient_email}: {e}")
+            if self.verbose:
+                print(f"üìä Created message sheet: {sheet_name}")
+            
+            # Cache the newly created sheet
+            self._sheet_cache[cache_key] = sheet_id
+            self._sheet_cache_time[cache_key] = datetime.now()
+            
+            return sheet_id
+        except Exception as e:
+            print(f"‚ùå Error creating sheet: {e}")
+            return None
+    
+    def send_file_or_folder_via_sheets(self, path: str, recipient_email: str) -> bool:
+        """
+        Send a file or folder using Google Sheets as transport
+        
+        Args:
+            path: Path to file/folder to send
+            recipient_email: Recipient's email address
+            
+        Returns:
+            True if successful
+        """
+        import base64
+        # print("SEND-1 " + str(time.time()))
+        self._ensure_authenticated()
+        # print("SEND-2 " + str(time.time()))
+        if recipient_email.lower() not in [f.lower() for f in self.friends]:
+            print(f"‚ùå {recipient_email} is not in your friends list")
+            return False
+        try:
+            # print("SEND-5 " + str(time.time()))
+            with tempfile.TemporaryDirectory() as temp_dir:
+                # print("SEND-6 " + str(time.time()))
+                # Prepare the message (shared logic)
+                result = self._prepare_message(path, recipient_email, temp_dir)
+                if not result:
+                    return False
+                
+                message_id, archive_path, archive_size = result
+                
+                # Check size limit for sheets (50k char limit per cell)
+                max_sheets_size = 37_500  # Conservative limit to stay under 50k chars after base64
+                if archive_size > max_sheets_size:
+                    print(f"‚ùå File too large for sheets transport: {archive_size:,} bytes (limit: {max_sheets_size:,} bytes)")
+                    print(f"   Consider using send_file_or_folder() instead for larger files")
+                    return False
+                
+                # print("SEND-18 " + str(time.time()))
+                # Read and encode archive
+                # print("SEND-19 " + str(time.time()))
+                with open(archive_path, 'rb') as f:
+                    archive_data = f.read()
+                # print("SEND-20 " + str(time.time()))
+                # Base64 encode for sheets
+                encoded_data = base64.b64encode(archive_data).decode('utf-8')
+                # print("SEND-21 " + str(time.time()))
+                # Get or create sheet (permissions are handled in the method)
+                # print("SEND-22 " + str(time.time()))
+                sheet_name = f"syft_{self.my_email}_to_{recipient_email}_messages"
+                # print("SEND-23 " + str(time.time()))
+                sheet_id = self._get_or_create_message_sheet(sheet_name, recipient_email)
+                # print("SEND-24 " + str(time.time()))
+                if not sheet_id:
+                    return False
+                # Prepare row data
+                # print("SEND-25 " + str(time.time()))
+                timestamp = datetime.now().isoformat()
+                # print("SEND-26 " + str(time.time()))
+                message_data = {
+                    'values': [[
+                        timestamp,
+                        message_id,
+                        str(len(archive_data)),
+                        encoded_data
+                    ]]
+                }
+                # print("SEND-27 " + str(time.time()))
+                # Append to sheet in one API call
+                # print("SEND-28 " + str(time.time()))
+                sheets_service = self._get_sheets_service()
+                # print("SEND-29 " + str(time.time()))
+                sheets_service.spreadsheets().values().append(
+                    spreadsheetId=sheet_id,
+                    range='messages!A:D',
+                    valueInputOption='USER_ENTERED',
+                    insertDataOption='INSERT_ROWS',
+                    body=message_data
+                ).execute()
+                # print("SEND-30 " + str(time.time()))
+                if self.verbose:
+                    print(f"üìä Sent message via sheets: {message_id}")
+                    print(f"   Size: {len(archive_data)} bytes")
+                # print("SEND-31 " + str(time.time()))
+                return True
+                
+        except Exception as e:
+            print(f"‚ùå Error sending via sheets: {e}")
+            return False
+    
+    
+    
+    def update_inbox_from_sheets(self, inbox_dir: str = None) -> Dict[str, List[str]]:
+        """
+        Check all friend sheets for new messages
+        
+        Args:
+            inbox_dir: Directory to extract messages to
+            
+        Returns:
+            Dict mapping friend emails to downloaded message IDs
+        """
+        import base64
+        # print("UPDATEINBOX-1 " + str(time.time()))
+        self._ensure_authenticated()
+        # print("UPDATEINBOX-2 " + str(time.time()))
+        # Set default inbox directory
+        if inbox_dir is None:
+            # print("UPDATEINBOX-3 " + str(time.time()))
+            syftbox_dir = self.get_syftbox_directory()
+            # print("UPDATEINBOX-4 " + str(time.time()))
+            if syftbox_dir is None:
+                print("‚ùå Could not determine SyftBox directory")
+                return {}
+            inbox_dir = str(syftbox_dir / "inbox")
+        # print("UPDATEINBOX-5 " + str(time.time()))
+        os.makedirs(inbox_dir, exist_ok=True)
+        if not self.friends:
+            return {}
+        downloaded_messages = {}
+        # print("UPDATEINBOX-6 " + str(time.time()))
+        sheets_service = self._get_sheets_service()
+        # print("UPDATEINBOX-7 " + str(time.time()))
+        # Build batch request for all friends
+        # print("UPDATEINBOX-8 " + str(time.time()))
+        ranges = []
+        friend_sheets = {}
+        for friend_email in self.friends:
+            sheet_name = f"syft_{friend_email}_to_{self.my_email}_messages"
+            if self.verbose:
+                print(f"üîç Looking for sheet: {sheet_name}")
+            # Pass the friend's email to search in shared files
+            # print("UPDATEINBOX-9 " + str(time.time()))
+            sheet_id = self._find_message_sheet(sheet_name, from_email=friend_email)
+            # print("UPDATEINBOX-10 " + str(time.time()))
+            if sheet_id:
+                ranges.append(f"messages!A:E")
+                friend_sheets[friend_email] = sheet_id
+                if self.verbose:
+                    print(f"   ‚úÖ Found sheet ID: {sheet_id}")
+            else:
+                if self.verbose:
+                    print(f"   ‚ùå Sheet not found")
+        if not ranges:
+            return {}
+        # print("UPDATEINBOX-11 " + str(time.time()))
+        try:
+            # Single batch get for all sheets
+            if self.verbose:
+                print(f"üìä Checking {len(friend_sheets)} friend sheets...")
+            for friend_email, sheet_id in friend_sheets.items():
+                try:
+                    # Get all rows from this friend's sheet
+                    # print("UPDATEINBOX-12 " + str(time.time()))
+                    result = sheets_service.spreadsheets().values().get(
+                        spreadsheetId=sheet_id,
+                        range='messages!A:D'
+                    ).execute()
+                    # print("UPDATEINBOX-13 " + str(time.time()))
+                    rows = result.get('values', [])
+                    if self.verbose:
+                        if len(rows) == 0:
+                            print(f"   üì≠ No messages")
+                        else:
+                            print(f"   üìã Found {len(rows)} message(s)")
+                    if len(rows) == 0:  # No messages
+                        continue
+                    # Process all messages (no header to skip)
+                    # print("UPDATEINBOX-14 " + str(time.time()))
+                    pending_messages = []
+                    for i, row in enumerate(rows, start=1):
+                        if self.verbose and len(row) >= 2:
+                            print(f"   Row {i}: msg_id = '{row[1] if len(row) > 1 else 'N/A'}'")
+                        if len(row) >= 4:  # timestamp, msg_id, size, data
+                            pending_messages.append((i, row))
+                    if pending_messages:
+                        if self.verbose:
+                            print(f"\nüì¨ Found {len(pending_messages)} message(s) from {friend_email}")
+                        downloaded_messages[friend_email] = []
+                        rows_to_archive = []
+                        # print("UPDATEINBOX-15 " + str(time.time()))
+                        for row_num, row in pending_messages:
+                            timestamp, msg_id, size, encoded_data = row[:4]
+                            # Check if already downloaded
+                            local_path = os.path.join(inbox_dir, msg_id)
+                            if os.path.exists(local_path):
+                                if self.verbose:
+                                    print(f"   ‚è≠Ô∏è  Skipping {msg_id} - already downloaded")
+                                continue
+                            try:
+                                if self.verbose:
+                                    print(f"   üì• Processing {msg_id}...")
+                                # Decode and extract
+                                # print("UPDATEINBOX-16 " + str(time.time()))
+                                archive_data = base64.b64decode(encoded_data)
+                                # print("UPDATEINBOX-17 " + str(time.time()))
+                                # Save to temp file and extract
+                                with tempfile.NamedTemporaryFile(suffix='.tar.gz', delete=False) as tmp:
+                                    tmp.write(archive_data)
+                                    tmp_path = tmp.name
+                                # Extract archive
+                                # print("UPDATEINBOX-18 " + str(time.time()))
+                                with tarfile.open(tmp_path, 'r:gz') as tar:
+                                    tar.extractall(inbox_dir)
+                                # print("UPDATEINBOX-19 " + str(time.time()))
+                                os.unlink(tmp_path)
+                                
+                                # Pre-cache metadata if it's JSON
+                                extracted_path = Path(inbox_dir) / msg_id
+                                json_metadata_path = extracted_path / "metadata.json"
+                                if json_metadata_path.exists():
+                                    try:
+                                        with open(json_metadata_path, 'r') as f:
+                                            self._metadata_cache[msg_id] = json.load(f)
+                                    except:
+                                        pass  # Ignore cache errors
+                                
+                                downloaded_messages[friend_email].append(msg_id)
+                                rows_to_archive.append(row_num)
+                                if self.verbose:
+                                    print(f"   ‚úÖ Downloaded {msg_id}")
+                                    
+                            except Exception as e:
+                                if self.verbose:
+                                    print(f"   ‚ùå Error processing {msg_id}: {e}")
+                        
+                        # Dispatch archiving task if we downloaded any messages
+                        if rows_to_archive:
+                            if self.verbose:
+                                print(f"   üóÑÔ∏è  Dispatching archive task for {len(rows_to_archive)} messages...")
+                            # print("UPDATEINBOX-20 " + str(time.time()))
+                            self._archive_sheet_messages_async(sheet_id, rows_to_archive)
+                            # print("UPDATEINBOX-21 " + str(time.time()))
+                    
+                except Exception as e:
+                    if self.verbose:
+                        print(f"   ‚ö†Ô∏è  Error checking {friend_email}: {e}")
+            
+            # print("UPDATEINBOX-22 " + str(time.time()))
+            return downloaded_messages
+            
+        except Exception as e:
+            if self.verbose:
+                print(f"‚ùå Error updating from sheets: {e}")
+            return {}
+    
+    def create_google_form_inbox(self) -> str:
+        """
+        Creates a Google Form inbox that matches the Google Sheets messaging schema.
+        This provides an alternative message submission method to avoid rate limits.
+        
+        The form collects:
+        - From Email (sender)
+        - To Email (recipient)
+        - Message ID
+        - Message Size (bytes)
+        - Message Data (Base64-encoded tar.gz)
+        - File Path (optional)
+        
+        Returns:
+            str: URL of the created Google Form
+        """
+        self._ensure_authenticated()
+        
+        # Build Google Forms service
+        forms_service = build('forms', 'v1', credentials=self.creds)
+        
+        # Create form structure
+        form_title = f"SyftBox Messages - {self.my_email}"
+        form_description = "Submit messages to SyftBox. Messages should be base64-encoded tar.gz archives."
+        
+        # Define questions matching the schema
+        questions = [
+            {
+                "title": "From Email",
+                "description": "Sender's email address",
+                "questionItem": {
+                    "question": {
+                        "required": True,
+                        "textQuestion": {
+                            "paragraph": False
+                        }
+                    }
+                }
+            },
+            {
+                "title": "To Email",
+                "description": "Recipient's email address",
+                "questionItem": {
+                    "question": {
+                        "required": True,
+                        "textQuestion": {
+                            "paragraph": False
+                        }
+                    }
+                }
+            },
+            {
+                "title": "Message ID",
+                "description": "Unique message ID (syft_message_timestamp_hash)",
+                "questionItem": {
+                    "question": {
+                        "required": True,
+                        "textQuestion": {
+                            "paragraph": False
+                        }
+                    }
+                }
+            },
+            {
+                "title": "Message Size (bytes)",
+                "description": "Size of encoded message in bytes",
+                "questionItem": {
+                    "question": {
+                        "required": True,
+                        "textQuestion": {
+                            "paragraph": False
+                        }
+                    }
+                }
+            },
+            {
+                "title": "Message Data (Base64)",
+                "description": "Base64-encoded tar.gz archive",
+                "questionItem": {
+                    "question": {
+                        "required": True,
+                        "textQuestion": {
+                            "paragraph": True  # This is a paragraph field
+                        }
+                    }
+                }
+            },
+            {
+                "title": "File Path (Optional)",
+                "description": "Path within datasites/ directory",
+                "questionItem": {
+                    "question": {
+                        "required": False,
+                        "textQuestion": {
+                            "paragraph": False
+                        }
+                    }
+                }
+            }
+        ]
+        
+        # Create form request - only title can be set on creation
+        form_request = {
+            "info": {
+                "title": form_title
+            }
+        }
+        
+        try:
+            # Create the form
+            if self.verbose:
+                print("üìù Creating Google Form inbox...")
+            
+            result = forms_service.forms().create(body=form_request).execute()
+            form_id = result["formId"]
+            
+            # Create batch update request for description and questions
+            requests = []
+            
+            # First update the form description
+            requests.append({
+                "updateFormInfo": {
+                    "info": {
+                        "description": form_description
+                    },
+                    "updateMask": "description"
+                }
+            })
+            
+            # Then add the questions
+            for index, question in enumerate(questions):
+                requests.append({
+                    "createItem": {
+                        "item": question,
+                        "location": {
+                            "index": index
+                        }
+                    }
+                })
+            
+            # Apply batch updates to add questions
+            batch_update_request = {
+                "requests": requests
+            }
+            
+            forms_service.forms().batchUpdate(
+                formId=form_id,
+                body=batch_update_request
+            ).execute()
+            
+            # Link form responses to a spreadsheet
+            # Note: The Forms API doesn't directly support creating linked spreadsheets
+            # Users will need to manually link responses or we can create a sheet separately
+            
+            # Get form URL
+            form_url = result.get('responderUri', f"https://docs.google.com/forms/d/{form_id}/viewform")
+            
+            if self.verbose:
+                print(f"‚úÖ Form created successfully!")
+                print(f"üìã Form URL: {form_url}")
+                print(f"üìù Form ID: {form_id}")
+                print(f"üìã Edit URL: https://docs.google.com/forms/d/{form_id}/edit")
+                print("\n‚ö†Ô∏è  Note: You'll need to manually link form responses to a Google Sheet")
+                print("    or use the form ID to programmatically retrieve responses.")
+                
+            # Store form info for later use
+            self._last_created_form = {
+                'form_id': form_id,
+                'form_url': form_url,
+                'edit_url': f"https://docs.google.com/forms/d/{form_id}/edit"
+            }
+            
+            return form_url
+            
+        except HttpError as e:
+            # Check for project access error
+            if "403" in str(e) and ("project" in str(e).lower() or "686245239599" in str(e)):
+                error_msg = (
+                    "\n‚ùå Forms API access error - your credentials were created with a different Google Cloud project.\n"
+                    "\n"
+                    "To fix this, you need to create new credentials:\n"
+                    "1. Complete the wizard that just launched (or run: syft_client.wizard())\n"
+                    "2. Follow the step-by-step guide to create new credentials\n"
+                    "3. Re-authenticate: client = syft_client.login('your-email@gmail.com', '/path/to/credentials.json')\n"
+                    "4. Clear cache: client.clear_form_inbox_cache()\n"
+                    "5. Try again: client.form_inbox_metadata\n"
+                    "\n"
+                    "Alternative: Manually create a form and use client.set_form_inbox_url(form_url)"
+                )
+                if self.verbose:
+                    print(error_msg)
+                # Try to import and show wizard
+                try:
+                    from IPython import get_ipython
+                    if get_ipython() is not None:
+                        from .wizard import wizard
+                        if self.verbose:
+                            print("\nüßô Launching credential wizard...")
+                        email = self.target_email or self.my_email
+                        wizard(email=email)
+                except:
+                    pass
+                raise Exception("Forms API project access error - run syft_client.wizard() to create new credentials") from e
+            else:
+                error_msg = f"‚ùå Error creating form: {e}"
+                if self.verbose:
+                    print(error_msg)
+                raise Exception(error_msg) from e
+    
+    def create_public_google_form_inbox(self) -> Dict[str, str]:
+        """
+        Creates a publicly accessible Google Form inbox that matches the Google Sheets messaging schema.
+        This form can be submitted to without authentication and automatically creates a linked spreadsheet.
+        
+        Returns:
+            Dict with:
+                - 'form_url': URL of the created public Google Form (with proper /d/e/ format)
+                - 'spreadsheet_url': URL of the linked Google Sheets spreadsheet
+                - 'spreadsheet_id': ID of the linked spreadsheet
+                - 'form_id': ID of the form
+        """
+        self._ensure_authenticated()
+        
+        # First create the form using the existing method
+        form_url = self.create_google_form_inbox()
+        
+        # Extract form ID
+        import re
+        form_id_match = re.search(r'/forms/d/(?:e/)?([a-zA-Z0-9_-]+)/', form_url)
+        if not form_id_match:
+            raise ValueError(f"Could not extract form ID from URL: {form_url}")
+        
+        form_id = form_id_match.group(1)
+        
+        # Create a linked spreadsheet for responses
+        if self.verbose:
+            print(f"üìä Creating linked spreadsheet for form responses...")
+            
+        try:
+            # Create a new spreadsheet with the same name as the form
+            form_title = f"SyftBox Inbox [{datetime.now().strftime('%Y-%m-%d %H:%M')}]"
+            spreadsheet_title = f"{form_title} (Responses)"
+            
+            # Create spreadsheet
+            spreadsheet_metadata = {
+                'properties': {
+                    'title': spreadsheet_title
+                }
+            }
+            
+            # Build sheets service if not already done
+            if not self._sheets_service:
+                self._sheets_service = build('sheets', 'v4', credentials=self.creds)
+                
+            spreadsheet = self._sheets_service.spreadsheets().create(
+                body=spreadsheet_metadata,
+                fields='spreadsheetId,spreadsheetUrl'
+            ).execute()
+            
+            spreadsheet_id = spreadsheet.get('spreadsheetId')
+            spreadsheet_url = spreadsheet.get('spreadsheetUrl')
+            
+            if self.verbose:
+                print(f"‚úÖ Created spreadsheet: {spreadsheet_title}")
+                print(f"üìä Spreadsheet URL: {spreadsheet_url}")
+                
+            # Unfortunately, the Forms API v1 doesn't support programmatically linking
+            # a spreadsheet to collect responses. This is a limitation.
+            # Users will need to manually link it or we need to use the form's
+            # response data via API instead.
+            
+            if self.verbose:
+                print(f"‚ö†Ô∏è  Note: Forms API v1 doesn't support auto-linking spreadsheets.")
+                print(f"    To link manually: Open form ‚Üí Responses tab ‚Üí Link to Sheets ‚Üí Select existing")
+                print(f"    Or use the form's API to retrieve responses programmatically")
+                
+        except HttpError as e:
+            if self.verbose:
+                print(f"‚ö†Ô∏è  Could not create spreadsheet: {e}")
+            spreadsheet_id = None
+            spreadsheet_url = None
+        
+        # Now make the form public and get the correct public URL
+        if self.verbose:
+            print(f"üîÑ Making form public...")
+            
+        public_form_url = self.make_form_public(form_url)
+        
+        # If make_form_public failed, it returns False
+        if not public_form_url:
+            if self.verbose:
+                print(f"‚ö†Ô∏è  Could not make form fully public, returning standard URL")
+            public_form_url = form_url
+            
+        return {
+            'form_url': public_form_url,
+            'form_id': form_id,
+            'spreadsheet_url': spreadsheet_url,
+            'spreadsheet_id': spreadsheet_id,
+            'form_edit_url': f"https://docs.google.com/forms/d/{form_id}/edit",
+            'note': 'Spreadsheet created but needs manual linking via Forms UI'
+        }
+    
+    def check_form_public_access(self, form_url: str) -> Dict[str, any]:
+        """
+        Check if a form is truly public (anyone with link can respond).
+        
+        Args:
+            form_url: URL of the Google Form to check
+            
+        Returns:
+            Dict with access status and details
+        """
+        import re
+        
+        # Extract form ID
+        form_id_match = re.search(r'/forms/d/(?:e/)?([a-zA-Z0-9_-]+)/', form_url)
+        if not form_id_match:
+            return {"error": "Could not extract form ID from URL"}
+        
+        form_id = form_id_match.group(1)
+        
+        try:
+            drive_service = build('drive', 'v3', credentials=self.creds)
+            
+            # Check permissions
+            permissions_result = drive_service.permissions().list(
+                fileId=form_id,
+                fields="permissions(id,type,role,domain,emailAddress)",
+                includePermissionsForView="published"
+            ).execute()
+            
+            permissions = permissions_result.get("permissions", [])
+            
+            # Analyze permissions
+            has_anyone_permission = False
+            has_domain_restriction = False
+            domain_name = None
+            
+            for perm in permissions:
+                if perm.get("type") == "anyone":
+                    has_anyone_permission = True
+                elif perm.get("type") == "domain":
+                    has_domain_restriction = True
+                    domain_name = perm.get("domain", "unknown")
+            
+            # Try to access form without auth
+            import requests
+            response = requests.get(form_url)
+            requires_auth = 'accounts.google.com' in response.url or response.status_code == 401
+            
+            return {
+                "form_id": form_id,
+                "has_anyone_permission": has_anyone_permission,
+                "has_domain_restriction": has_domain_restriction,
+                "restricted_domain": domain_name,
+                "requires_authentication": requires_auth,
+                "is_truly_public": has_anyone_permission and not has_domain_restriction and not requires_auth,
+                "permissions": permissions,
+                "recommendation": self._get_access_recommendation(has_anyone_permission, has_domain_restriction, requires_auth)
+            }
+            
+        except Exception as e:
+            return {"error": str(e)}
+    
+    def _get_access_recommendation(self, has_anyone: bool, has_domain: bool, requires_auth: bool) -> str:
+        """Get recommendation for fixing form access."""
+        if not has_anyone and has_domain:
+            return "Form is domain-restricted. To make it public, manually: 1) Open form 2) Click Send 3) Under 'Responders', click 'Manage' 4) Select 'Anyone with the link' 5) Save"
+        elif has_anyone and requires_auth:
+            return "Form has 'anyone' permission but still requires auth. Check form settings for 'Collect email addresses' or 'Restrict to organization' options."
+        elif has_anyone and not requires_auth:
+            return "Form appears to be properly configured for public access."
+        else:
+            return "Unknown configuration. Please check form settings manually."
+    
+    def get_form_responses_api(self, form_id: str, limit: int = 100) -> List[Dict[str, any]]:
+        """
+        Retrieve responses from a Google Form using the Forms API.
+        
+        Args:
+            form_id: The Google Form ID
+            limit: Maximum number of responses to retrieve
+            
+        Returns:
+            List of form responses as dictionaries
+        """
+        self._ensure_authenticated()
+        
+        try:
+            forms_service = build('forms', 'v1', credentials=self.creds)
+            
+            # Get form responses
+            responses = forms_service.forms().responses().list(
+                formId=form_id,
+                pageSize=limit
+            ).execute()
+            
+            form_responses = []
+            
+            # Get the form structure to map question IDs to titles
+            form = forms_service.forms().get(formId=form_id).execute()
+            
+            # Create a mapping of item IDs to question titles
+            item_map = {}
+            for item in form.get('items', []):
+                item_id = item.get('itemId')
+                title = item.get('title', '')
+                item_map[item_id] = title
+            
+            # Process each response
+            for response in responses.get('responses', []):
+                response_data = {
+                    'responseId': response.get('responseId'),
+                    'createTime': response.get('createTime'),
+                    'lastSubmittedTime': response.get('lastSubmittedTime'),
+                    'answers': {}
+                }
+                
+                # Extract answers
+                for item_id, answer_data in response.get('answers', {}).items():
+                    question_title = item_map.get(item_id, item_id)
+                    text_answers = answer_data.get('textAnswers', {}).get('answers', [])
+                    if text_answers:
+                        response_data['answers'][question_title] = text_answers[0].get('value', '')
+                
+                form_responses.append(response_data)
+            
+            if self.verbose:
+                print(f"üìä Retrieved {len(form_responses)} responses from form")
+                
+            return form_responses
+            
+        except HttpError as e:
+            if self.verbose:
+                print(f"‚ùå Error retrieving form responses: {e}")
+            return []
+    
+    def get_results_from_form(self, form_id_or_url: Optional[str] = None, limit: int = 100, format: str = 'list') -> Union[List[Dict[str, any]], Dict[str, any]]:
+        """
+        Get results/responses from a Google Form using either form ID or URL.
+        
+        Args:
+            form_id_or_url: Optional Google Form ID or URL. If None, uses cached form_inbox_metadata
+            limit: Maximum number of responses to retrieve (default 100)
+            format: Return format - 'list' for list of responses, 'summary' for aggregated results
+            
+        Returns:
+            List of responses or summary dict depending on format parameter
+        """
+        import re
+        from datetime import datetime
+        
+        self._ensure_authenticated()
+        
+        # Use cached form_inbox_metadata if not provided
+        if form_id_or_url is None:
+            form_metadata = self.form_inbox_metadata
+            if 'error' in form_metadata:
+                if self.verbose:
+                    print(f"‚ùå Cannot get results - form metadata has error: {form_metadata['error']}")
+                return [] if format == 'list' else {'error': form_metadata['error']}
+            
+            # Try to get form_id or form_url from metadata
+            form_id_or_url = form_metadata.get('form_id') or form_metadata.get('form_url')
+            if not form_id_or_url:
+                if self.verbose:
+                    print("‚ùå No form ID or URL found in cached metadata")
+                return [] if format == 'list' else {'error': 'No form ID or URL in cached metadata'}
+            
+            if self.verbose:
+                print("üìã Using form from cached form_inbox_metadata")
+        
+        # Extract form ID if URL was provided
+        form_id = form_id_or_url
+        if form_id_or_url.startswith('http'):
+            form_id_match = re.search(r'/forms/d/(?:e/)?([a-zA-Z0-9_-]+)/', form_id_or_url)
+            if form_id_match:
+                form_id = form_id_match.group(1)
+                if self.verbose:
+                    print(f"üìã Extracted form ID: {form_id}")
+            else:
+                if self.verbose:
+                    print(f"‚ùå Could not extract form ID from URL: {form_id_or_url}")
+                return [] if format == 'list' else {'error': 'Invalid form URL'}
+        
+        if self.verbose:
+            print(f"üîç Getting responses for form ID: {form_id}")
+        
+        # Get the responses using the Forms API method
+        responses = self.get_form_responses_api(form_id, limit)
+        
+        if format == 'list':
+            return responses
+        elif format == 'summary':
+            # Create summary statistics
+            summary = {
+                'form_id': form_id,
+                'total_responses': len(responses),
+                'responses': responses,
+                'field_summary': {},
+                'latest_response': None,
+                'oldest_response': None
+            }
+            
+            if responses:
+                # Get latest and oldest responses
+                sorted_responses = sorted(responses, key=lambda x: x.get('lastSubmittedTime', ''))
+                summary['oldest_response'] = sorted_responses[0] if sorted_responses else None
+                summary['latest_response'] = sorted_responses[-1] if sorted_responses else None
+                
+                # Aggregate field data
+                field_counts = {}
+                for response in responses:
+                    for field, value in response.get('answers', {}).items():
+                        if field not in field_counts:
+                            field_counts[field] = {
+                                'total': 0,
+                                'non_empty': 0,
+                                'values': []
+                            }
+                        field_counts[field]['total'] += 1
+                        if value:
+                            field_counts[field]['non_empty'] += 1
+                            field_counts[field]['values'].append(value)
+                
+                summary['field_summary'] = field_counts
+                
+            if self.verbose:
+                print(f"\nüìä Form Results Summary:")
+                print(f"   Total responses: {summary['total_responses']}")
+                if summary['latest_response']:
+                    print(f"   Latest: {summary['latest_response'].get('lastSubmittedTime', 'unknown')}")
+                if summary['oldest_response']:
+                    print(f"   Oldest: {summary['oldest_response'].get('lastSubmittedTime', 'unknown')}")
+                    
+            return summary
+        else:
+            if self.verbose:
+                print(f"‚ùå Unknown format '{format}'. Use 'list' or 'summary'")
+            return []
+    
+    def test_form_rate_limits(self, form_id_or_url: str, duration_seconds: int = 60) -> Dict[str, any]:
+        """
+        Test the rate limits for getting form responses.
+        
+        Args:
+            form_id_or_url: The Google Form ID or URL to test
+            duration_seconds: How long to run the test (default 60 seconds)
+            
+        Returns:
+            Dict with rate limit test results including successful calls, errors, and estimated limits
+        """
+        import time
+        import random
+        from collections import defaultdict
+        import re
+        
+        self._ensure_authenticated()
+        
+        # Extract form ID if URL was provided
+        form_id = form_id_or_url
+        if form_id_or_url.startswith('http'):
+            # Try to extract form ID from URL
+            form_id_match = re.search(r'/forms/d/(?:e/)?([a-zA-Z0-9_-]+)/', form_id_or_url)
+            if form_id_match:
+                form_id = form_id_match.group(1)
+                print(f"üìã Extracted form ID from URL: {form_id}")
+            else:
+                print(f"‚ùå Could not extract form ID from URL: {form_id_or_url}")
+                return {
+                    'error': 'Invalid form URL',
+                    'message': 'Could not extract form ID from the provided URL'
+                }
+        
+        print(f"üß™ Testing Forms API rate limits for {duration_seconds} seconds...")
+        print(f"üìù Form ID: {form_id}")
+        print(f"‚è±Ô∏è  Starting at: {datetime.now().strftime('%H:%M:%S')}")
+        print("-" * 50)
+        
+        start_time = time.time()
+        end_time = start_time + duration_seconds
+        
+        # Track metrics
+        metrics = {
+            'total_requests': 0,
+            'successful_requests': 0,
+            'rate_limit_errors': 0,
+            'other_errors': 0,
+            'requests_per_minute': defaultdict(int),
+            'errors_per_minute': defaultdict(int),
+            'response_times': [],
+            'rate_limit_timestamps': []
+        }
+        
+        request_count = 0
+        last_print_time = start_time
+        
+        try:
+            while time.time() < end_time:
+                request_start = time.time()
+                current_minute = int((request_start - start_time) / 60)
+                
+                try:
+                    # Make the API call using get_results_from_form
+                    # Use limit=1 to minimize data transfer, same as pageSize=1 before
+                    response = self.get_results_from_form(form_id, limit=1, format='list')
+                    
+                    # Record success (if we got here, the call succeeded)
+                    metrics['total_requests'] += 1
+                    metrics['successful_requests'] += 1
+                    metrics['requests_per_minute'][current_minute] += 1
+                    
+                    response_time = time.time() - request_start
+                    metrics['response_times'].append(response_time)
+                    
+                    request_count += 1
+                    
+                    # Print progress every 5 seconds
+                    if time.time() - last_print_time >= 5:
+                        elapsed = time.time() - start_time
+                        rate = request_count / (elapsed / 60)
+                        print(f"‚úÖ {request_count} requests | Rate: {rate:.1f}/min | "
+                              f"Elapsed: {elapsed:.1f}s | Last response: {response_time:.3f}s")
+                        last_print_time = time.time()
+                    
+                    # Small delay to avoid overwhelming the API
+                    time.sleep(0.1)
+                    
+                except HttpError as e:
+                    metrics['total_requests'] += 1
+                    
+                    if e.resp.status == 429:
+                        # Rate limit error
+                        metrics['rate_limit_errors'] += 1
+                        metrics['errors_per_minute'][current_minute] += 1
+                        metrics['rate_limit_timestamps'].append(time.time() - start_time)
+                        
+                        # Extract retry-after if available
+                        retry_after = e.resp.headers.get('Retry-After', '60')
+                        
+                        print(f"‚ùå Rate limit hit at {request_count} requests "
+                              f"({(time.time() - start_time):.1f}s elapsed)")
+                        print(f"   Retry-After: {retry_after}s")
+                        print(f"   Current rate: {request_count / ((time.time() - start_time) / 60):.1f}/min")
+                        
+                        # Wait before retrying
+                        wait_time = min(float(retry_after), 10) + random.uniform(0, 1)
+                        print(f"   Waiting {wait_time:.1f}s before continuing...")
+                        time.sleep(wait_time)
+                        
+                    else:
+                        # Other error
+                        metrics['other_errors'] += 1
+                        print(f"‚ö†Ô∏è  Error {e.resp.status}: {str(e)[:100]}")
+                        time.sleep(1)
+                        
+                except Exception as e:
+                    metrics['other_errors'] += 1
+                    print(f"‚ö†Ô∏è  Unexpected error: {str(e)[:100]}")
+                    time.sleep(1)
+                    
+        except KeyboardInterrupt:
+            print("\n‚èπÔ∏è  Test interrupted by user")
+            
+        # Calculate final metrics
+        total_duration = time.time() - start_time
+        
+        # Analyze rate limits
+        max_requests_per_minute = max(metrics['requests_per_minute'].values()) if metrics['requests_per_minute'] else 0
+        avg_requests_per_minute = metrics['successful_requests'] / (total_duration / 60)
+        avg_response_time = sum(metrics['response_times']) / len(metrics['response_times']) if metrics['response_times'] else 0
+        
+        # Print summary
+        print("\n" + "=" * 50)
+        print("üìä RATE LIMIT TEST RESULTS")
+        print("=" * 50)
+        print(f"‚è±Ô∏è  Duration: {total_duration:.1f} seconds")
+        print(f"üìà Total requests: {metrics['total_requests']}")
+        print(f"‚úÖ Successful: {metrics['successful_requests']}")
+        print(f"‚ùå Rate limited: {metrics['rate_limit_errors']}")
+        print(f"‚ö†Ô∏è  Other errors: {metrics['other_errors']}")
+        print(f"\nüìä Performance:")
+        print(f"   Average rate: {avg_requests_per_minute:.1f} requests/min")
+        print(f"   Peak rate: {max_requests_per_minute} requests/min")
+        print(f"   Avg response time: {avg_response_time:.3f}s")
+        
+        if metrics['rate_limit_errors'] > 0:
+            print(f"\nüö¶ Rate Limit Analysis:")
+            print(f"   First limit hit after: {metrics['rate_limit_timestamps'][0]:.1f}s")
+            print(f"   Estimated limit: ~{request_count} requests/minute")
+            
+        # Return detailed results
+        return {
+            'duration_seconds': total_duration,
+            'total_requests': metrics['total_requests'],
+            'successful_requests': metrics['successful_requests'],
+            'rate_limit_errors': metrics['rate_limit_errors'],
+            'other_errors': metrics['other_errors'],
+            'average_requests_per_minute': avg_requests_per_minute,
+            'peak_requests_per_minute': max_requests_per_minute,
+            'average_response_time_ms': avg_response_time * 1000,
+            'requests_per_minute_breakdown': dict(metrics['requests_per_minute']),
+            'rate_limit_timestamps': metrics['rate_limit_timestamps'],
+            'estimated_rate_limit': request_count if metrics['rate_limit_errors'] > 0 else None
+        }
+    
+    def list_forms(self, query: str = "", limit: int = 10) -> List[Dict[str, str]]:
+        """
+        List Google Forms accessible by the authenticated user.
+        
+        Args:
+            query: Optional search query for form names
+            limit: Maximum number of forms to return (default 10)
+            
+        Returns:
+            List of dictionaries containing form information
+        """
+        self._ensure_authenticated()
+        
+        # Build query for Google Forms
+        q_parts = ["mimeType='application/vnd.google-apps.form'"]
+        if query:
+            q_parts.append(f"name contains '{query}'")
+        q_parts.append("trashed=false")
+        
+        q = " and ".join(q_parts)
+        
+        try:
+            results = self.service.files().list(
+                q=q,
+                pageSize=limit,
+                fields="files(id, name, createdTime, modifiedTime, webViewLink, owners)",
+                orderBy="modifiedTime desc"
+            ).execute()
+            
+            forms = results.get('files', [])
+            
+            # Format the results
+            form_list = []
+            for form in forms:
+                form_info = {
+                    'id': form['id'],
+                    'name': form['name'],
+                    'created': form.get('createdTime', ''),
+                    'modified': form.get('modifiedTime', ''),
+                    'edit_url': f"https://docs.google.com/forms/d/{form['id']}/edit",
+                    'view_url': f"https://docs.google.com/forms/d/{form['id']}/viewform",
+                    'owner': form.get('owners', [{}])[0].get('emailAddress', 'unknown')
+                }
+                form_list.append(form_info)
+                
+            if self.verbose and form_list:
+                print(f"üìã Found {len(form_list)} form(s):")
+                for i, form in enumerate(form_list, 1):
+                    print(f"  {i}. {form['name']} (ID: {form['id']})")
+                    
+            return form_list
+            
+        except HttpError as e:
+            if self.verbose:
+                print(f"‚ùå Error listing forms: {e}")
+            return []
+    
+    def find_form_by_name(self, name: str) -> Optional[str]:
+        """
+        Find a form by name and return its ID.
+        
+        Args:
+            name: The name of the form to search for
+            
+        Returns:
+            Form ID if found, None otherwise
+        """
+        forms = self.list_forms(query=name, limit=100)
+        
+        # Try exact match first
+        for form in forms:
+            if form['name'] == name:
+                if self.verbose:
+                    print(f"‚úÖ Found form '{name}' with ID: {form['id']}")
+                return form['id']
+        
+        # If no exact match, try partial match
+        if forms:
+            if self.verbose:
+                print(f"‚ö†Ô∏è  No exact match for '{name}', using closest match: '{forms[0]['name']}'")
+            return forms[0]['id']
+            
+        if self.verbose:
+            print(f"‚ùå No form found matching '{name}'")
+        return None
+    
+    def get_form_by_id(self, form_id: str) -> Optional[Dict[str, str]]:
+        """
+        Get form details by its ID.
+        
+        Args:
+            form_id: The Google Form ID
+            
+        Returns:
+            Dictionary with form details if found, None otherwise
+        """
+        self._ensure_authenticated()
+        
+        try:
+            # Get file metadata from Drive API
+            file_metadata = self.service.files().get(
+                fileId=form_id,
+                fields="id,name,createdTime,modifiedTime,webViewLink,owners,mimeType"
+            ).execute()
+            
+            # Verify it's a form
+            if file_metadata.get('mimeType') != 'application/vnd.google-apps.form':
+                if self.verbose:
+                    print(f"‚ùå File {form_id} is not a Google Form")
+                return None
+            
+            # Format the result
+            form_info = {
+                'id': file_metadata['id'],
+                'name': file_metadata['name'],
+                'created': file_metadata.get('createdTime', ''),
+                'modified': file_metadata.get('modifiedTime', ''),
+                'edit_url': f"https://docs.google.com/forms/d/{form_id}/edit",
+                'view_url': f"https://docs.google.com/forms/d/{form_id}/viewform",
+                'owner': file_metadata.get('owners', [{}])[0].get('emailAddress', 'unknown')
+            }
+            
+            if self.verbose:
+                print(f"‚úÖ Found form: {form_info['name']} (ID: {form_info['id']})")
+                
+            return form_info
+            
+        except HttpError as e:
+            if self.verbose:
+                print(f"‚ùå Error getting form {form_id}: {e}")
+            return None
+    
+    def make_form_public(self, form_identifier: str) -> Union[str, bool]:
+        """
+        Convert a non-public form to allow "Anyone with the link" to respond.
+        
+        Args:
+            form_identifier: Can be:
+                - Google Form ID (e.g., "1abc...")
+                - Form URL (edit or view)
+                - Form name to search for
+            
+        Returns:
+            str: The new public form URL if successful
+            False: If the operation failed
+        """
+        import re
+        
+        # Ensure authenticated
+        self._ensure_authenticated()
+        
+        form_id = None
+        
+        # Check if it's a URL, form ID, or name
+        if form_identifier.startswith('http'):
+            # It's a URL
+            # Try standard form ID extraction first
+            standard_match = re.search(r'/forms/d/([a-zA-Z0-9_-]+)/(edit|viewform)', form_identifier)
+            if standard_match:
+                form_id = standard_match.group(1)
+                print(f"üìã Extracted form ID from URL: {form_id}")
+            else:
+                # Check if it's a /d/e/ URL with prefixed ID
+                prefixed_match = re.search(r'/forms/d/e/([a-zA-Z0-9_-]+)/', form_identifier)
+                if prefixed_match:
+                    # Try to find the form by searching recent forms
+                    print(f"üîç URL contains prefixed ID, searching for matching forms...")
+                    forms = self.list_forms(limit=50)
+                    
+                    # Check if any recent form matches this URL pattern
+                    for form in forms:
+                        # Get the form and check its published URL
+                        try:
+                            # Try to access the form to see if it matches
+                            form_url_check = f"https://docs.google.com/forms/d/{form['id']}/viewform"
+                            print(f"   Checking form: {form['name']} (ID: {form['id']})")
+                            # We found a candidate - for now we'll use the most recent form
+                            # In production, you'd want to verify this is the correct form
+                            form_id = form['id']
+                            print(f"üìã Using form: {form['name']} (ID: {form_id})")
+                            break
+                        except:
+                            continue
+                            
+                if not form_id:
+                    print(f"‚ùå Cannot determine actual form ID from prefixed URL")
+                    print(f"    Please provide the form name or edit URL instead")
+                    return False
+        else:
+            # Check if it's a form ID (alphanumeric string)
+            if re.match(r'^[a-zA-Z0-9_-]+$', form_identifier) and len(form_identifier) > 10:
+                # Likely a form ID - verify it exists
+                print(f"üîç Checking if '{form_identifier}' is a form ID...")
+                form_info = self.get_form_by_id(form_identifier)
+                if form_info:
+                    form_id = form_identifier
+                    print(f"‚úÖ Confirmed: '{form_info['name']}' (ID: {form_id})")
+                else:
+                    # Not a valid form ID, try as name
+                    print(f"üîç Not a valid form ID, searching by name: {form_identifier}")
+                    form_id = self.find_form_by_name(form_identifier)
+                    if not form_id:
+                        return False
+            else:
+                # It's likely a form name
+                print(f"üîç Searching for form by name: {form_identifier}")
+                form_id = self.find_form_by_name(form_identifier)
+                if not form_id:
+                    return False
+        
+        # Always print status for this operation
+        print(f"üîÑ Converting form to public access...")
+        print(f"üìù Form ID: {form_id}")
+        
+        try:
+            # Use Drive API v3 
+            drive_service = build('drive', 'v3', credentials=self.creds)
+            
+            # First, check existing permissions
+            if self.verbose:
+                print("üìã Checking existing permissions...")
+            
+            permissions_result = drive_service.permissions().list(
+                fileId=form_id,
+                fields="permissions(id,type,role,domain,view)"
+            ).execute()
+            
+            # Remove any domain-specific permissions
+            for permission in permissions_result.get("permissions", []):
+                if permission.get("type") == "domain":
+                    try:
+                        drive_service.permissions().delete(
+                            fileId=form_id,
+                            permissionId=permission["id"]
+                        ).execute()
+                        if self.verbose:
+                            print(f"üóëÔ∏è  Removed domain restriction: {permission.get('domain', 'unknown')}")
+                    except Exception as e:
+                        if self.verbose:
+                            print(f"‚ö†Ô∏è  Could not remove permission {permission['id']}: {e}")
+            
+            # Set "Anyone with the link" as a responder
+            if self.verbose:
+                print("üîê Setting 'Anyone with the link' permission...")
+                
+            permission_body = {
+                "type": "anyone",
+                "view": "published",  # Key for making it a responder setting
+                "role": "reader",
+            }
+            
+            response = drive_service.permissions().create(
+                fileId=form_id,
+                body=permission_body,
+            ).execute()
+            
+            if self.verbose:
+                print(f"‚úÖ Permission created: {response.get('id')}")
+            
+            # Verify the change
+            if self.verbose:
+                print("üîç Verifying permissions...")
+                
+            permissions_result = drive_service.permissions().list(
+                fileId=form_id,
+                fields="permissions(id,type,role,view)",
+                includePermissionsForView="published",
+            ).execute()
+            
+            # Check if the permission was set correctly
+            anyone_can_respond = False
+            for permission in permissions_result.get("permissions", []):
+                if (
+                    permission.get("type") == "anyone"
+                    and permission.get("view") == "published"
+                    and permission.get("role") == "reader"
+                ):
+                    anyone_can_respond = True
+                    break
+            
+            if anyone_can_respond:
+                if self.verbose:
+                    print(f"‚úÖ Success! Form is now public")
+                    print(f"üìã Anyone with the link can now respond")
+                
+                # Get the updated form URL after permission change
+                # When permissions change, the public URL might change
+                try:
+                    # Get fresh file metadata to ensure we have the latest URLs
+                    file_metadata = drive_service.files().get(
+                        fileId=form_id,
+                        fields="id,webViewLink"
+                    ).execute()
+                    
+                    # The webViewLink might be the edit link, so construct the public view URL
+                    public_form_url = f"https://docs.google.com/forms/d/e/{form_id}/viewform"
+                    
+                    # Try to get the actual public URL by fetching the form
+                    import requests
+                    response = requests.get(f"https://docs.google.com/forms/d/{form_id}/viewform", allow_redirects=True)
+                    
+                    # If we got redirected to a /d/e/ URL, use that
+                    if '/forms/d/e/' in response.url:
+                        public_form_url = response.url
+                        if self.verbose:
+                            print(f"üìù New public URL detected: {public_form_url}")
+                    else:
+                        # Use the standard viewform URL
+                        public_form_url = f"https://docs.google.com/forms/d/{form_id}/viewform"
+                        if self.verbose:
+                            print(f"üìù Using standard public URL: {public_form_url}")
+                    
+                    if self.verbose:
+                        print(f"üîó Public form URL: {public_form_url}")
+                        print(f"üìã Form ID: {form_id}")
+                        
+                    return public_form_url
+                    
+                except Exception as e:
+                    if self.verbose:
+                        print(f"‚ö†Ô∏è  Could not determine new public URL: {e}")
+                        print(f"    Using standard format: https://docs.google.com/forms/d/{form_id}/viewform")
+                    return f"https://docs.google.com/forms/d/{form_id}/viewform"
+            else:
+                if self.verbose:
+                    print(f"‚ö†Ô∏è  Permission was created but verification failed")
+                    print(f"    You may need to manually check the form settings")
+                return False
+                
+        except HttpError as e:
+            print(f"‚ùå Error making form public: {e}")
+            error_details = e.error_details if hasattr(e, 'error_details') else str(e)
+            print(f"    Details: {error_details}")
+            return False
+        except Exception as e:
+            print(f"‚ùå Unexpected error: {e}")
+            import traceback
+            traceback.print_exc()
+            return False
+    
+    def test_google_form_inbox(self, form_url: str) -> Dict[str, any]:
+        """
+        Tests a Google Form inbox by submitting a test message.
+        
+        Args:
+            form_url: The URL of the Google Form to test
+            
+        Returns:
+            Dict with test results including submission status and response data
+        """
+        import base64
+        import uuid
+        from datetime import datetime
+        
+        self._ensure_authenticated()
+        
+        # Extract form ID from URL
+        # URL format: https://docs.google.com/forms/d/{form_id}/viewform
+        import re
+        form_id_match = re.search(r'/forms/d/([a-zA-Z0-9_-]+)/', form_url)
+        if not form_id_match:
+            raise ValueError(f"Could not extract form ID from URL: {form_url}")
+        
+        form_id = form_id_match.group(1)
+        
+        # Build Google Forms service
+        forms_service = build('forms', 'v1', credentials=self.creds)
+        
+        try:
+            # First, get the form to understand its structure
+            form = forms_service.forms().get(formId=form_id).execute()
+            
+            # Create test data
+            test_message_id = f"syft_message_test_{int(datetime.now().timestamp())}_{uuid.uuid4().hex[:8]}"
+            test_data = {
+                "from_email": "test@example.com",
+                "to_email": self.my_email,
+                "message_id": test_message_id,
+                "message_size": "1024",
+                "message_data": base64.b64encode(b"This is a test message for the Google Form inbox").decode('utf-8'),
+                "file_path": "datasites/test/message.tar.gz"
+            }
+            
+            # Map form items to our test data
+            responses = {}
+            for item in form.get('items', []):
+                item_id = item['itemId']
+                title = item.get('title', '').lower()
+                
+                # Match questions to test data
+                if 'from email' in title:
+                    responses[item_id] = {
+                        'textAnswers': {
+                            'answers': [{'value': test_data['from_email']}]
+                        }
+                    }
+                elif 'to email' in title:
+                    responses[item_id] = {
+                        'textAnswers': {
+                            'answers': [{'value': test_data['to_email']}]
+                        }
+                    }
+                elif 'message id' in title:
+                    responses[item_id] = {
+                        'textAnswers': {
+                            'answers': [{'value': test_data['message_id']}]
+                        }
+                    }
+                elif 'message size' in title:
+                    responses[item_id] = {
+                        'textAnswers': {
+                            'answers': [{'value': test_data['message_size']}]
+                        }
+                    }
+                elif 'message data' in title:
+                    responses[item_id] = {
+                        'textAnswers': {
+                            'answers': [{'value': test_data['message_data']}]
+                        }
+                    }
+                elif 'file path' in title:
+                    responses[item_id] = {
+                        'textAnswers': {
+                            'answers': [{'value': test_data['file_path']}]
+                        }
+                    }
+            
+            # Note: The Forms API v1 doesn't support submitting responses programmatically
+            # This is a limitation of the current API. Instead, we'll return instructions
+            # for manual testing or suggest using the form's pre-filled URL feature
+            
+            if self.verbose:
+                print("‚ö†Ô∏è  Note: The Google Forms API v1 doesn't support programmatic form submission.")
+                print("    To test the form, you can:")
+                print(f"    1. Open the form manually: {form_url}")
+                print("    2. Fill in the test data below:")
+                print(f"       - From Email: {test_data['from_email']}")
+                print(f"       - To Email: {test_data['to_email']}")
+                print(f"       - Message ID: {test_data['message_id']}")
+                print(f"       - Message Size: {test_data['message_size']}")
+                print(f"       - Message Data: {test_data['message_data'][:50]}...")
+                print(f"       - File Path: {test_data['file_path']}")
+            
+            # Generate pre-filled URL
+            prefilled_params = []
+            for item in form.get('items', []):
+                title = item.get('title', '').lower()
+                question_id = item.get('questionItem', {}).get('question', {}).get('questionId')
+                
+                if question_id:
+                    if 'from email' in title:
+                        prefilled_params.append(f"entry.{question_id}={test_data['from_email']}")
+                    elif 'to email' in title:
+                        prefilled_params.append(f"entry.{question_id}={test_data['to_email']}")
+                    elif 'message id' in title:
+                        prefilled_params.append(f"entry.{question_id}={test_data['message_id']}")
+                    elif 'message size' in title:
+                        prefilled_params.append(f"entry.{question_id}={test_data['message_size']}")
+                    elif 'file path' in title:
+                        prefilled_params.append(f"entry.{question_id}={test_data['file_path']}")
+            
+            # Create alternative submission method info
+            result = {
+                "status": "ready_for_testing",
+                "form_id": form_id,
+                "form_url": form_url,
+                "test_data": test_data,
+                "form_structure": {
+                    "title": form.get('info', {}).get('title'),
+                    "description": form.get('info', {}).get('description'),
+                    "questions": len(form.get('items', [])),
+                    "response_destination": form.get('responderUri')
+                },
+                "notes": [
+                    "Forms API v1 doesn't support programmatic submission",
+                    "Use the form URL to manually test submission",
+                    "Consider using Google Apps Script for automated testing"
+                ]
+            }
+            
+            if self.verbose:
+                print(f"\n‚úÖ Form ready for testing!")
+                print(f"üìù Form has {len(form.get('items', []))} questions")
+                print(f"üîó Test the form at: {form_url}")
+            
+            return result
+            
+        except HttpError as e:
+            error_msg = f"‚ùå Error testing form: {e}"
+            if self.verbose:
+                print(error_msg)
+            raise Exception(error_msg) from e
+    
+    def submit_to_google_form_inbox(self, form_url: str, from_email: str, to_email: str, 
+                                   message_id: str, message_size: str, message_data: str,
+                                   file_path: Optional[str] = None, debug: bool = True) -> bool:
+        """
+        Submit a message to a Google Form inbox using direct HTTP POST.
+        
+        Args:
+            form_url: The URL of the Google Form
+            from_email: Sender's email address
+            to_email: Recipient's email address
+            message_id: Unique message ID
+            message_size: Size of encoded message in bytes
+            message_data: Base64-encoded message data
+            file_path: Optional file path within datasites/ directory
+            debug: Enable debug output
+            
+        Returns:
+            bool: True if submission was successful
+        """
+        import requests
+        import re
+        
+        # Extract form ID from URL
+        # Handle both /d/{id}/ and /d/e/{id}/ formats
+        form_id_match = re.search(r'/forms/d/(?:e/)?([a-zA-Z0-9_-]+)/', form_url)
+        if not form_id_match:
+            raise ValueError(f"Could not extract form ID from URL: {form_url}")
+        
+        form_id = form_id_match.group(1)
+        
+        try:
+            if debug:
+                print(f"üìù Fetching form structure from: {form_url}")
+                
+            # First, fetch the form to get field IDs
+            session = requests.Session()
+            response = session.get(form_url)
+            
+            # Check if we got a login redirect
+            if response.status_code == 401 or 'accounts.google.com' in response.url:
+                if debug:
+                    print("‚ö†Ô∏è  Form requires authentication. Trying alternative approach...")
+                
+                # For authenticated forms, we'll use the known structure
+                # Since we created the form, we know the order of fields
+                if debug:
+                    print("üìä Using predefined field structure for authenticated form")
+                
+                # Use the API to get form structure instead
+                forms_service = build('forms', 'v1', credentials=self.creds)
+                try:
+                    # Extract the actual form ID (not the prefixed version)
+                    actual_form_id = form_id.split('/')[-1] if '/' in form_id else form_id
+                    if debug:
+                        print(f"üìù Using form ID: {actual_form_id}")
+                    
+                    form = forms_service.forms().get(formId=actual_form_id).execute()
+                    
+                    # Map items by title
+                    entry_map = {}
+                    for idx, item in enumerate(form.get('items', [])):
+                        title = item.get('title', '').lower()
+                        item_id = item.get('itemId', str(idx))
+                        # Extract question ID which maps to entry ID
+                        question_id = item.get('questionItem', {}).get('question', {}).get('questionId')
+                        
+                        if question_id:
+                            if 'from email' in title:
+                                entry_map['from_email'] = question_id
+                            elif 'to email' in title:
+                                entry_map['to_email'] = question_id
+                            elif 'message id' in title:
+                                entry_map['message_id'] = question_id
+                            elif 'message size' in title:
+                                entry_map['message_size'] = question_id
+                            elif 'message data' in title:
+                                entry_map['message_data'] = question_id
+                            elif 'file path' in title:
+                                entry_map['file_path'] = question_id
+                    
+                    if debug:
+                        print(f"üìä Mapped {len(entry_map)} fields from API")
+                        
+                except Exception as api_error:
+                    if debug:
+                        print(f"‚ùå API approach failed: {api_error}")
+                    # Fall back to standard entry numbering
+                    # Google Forms typically uses sequential entry IDs
+                    entry_map = {
+                        'from_email': '1976614157',  # These are example IDs
+                        'to_email': '1420112892',
+                        'message_id': '875531887',
+                        'message_size': '1052223171',
+                        'message_data': '1815612569',
+                        'file_path': '1422092153'
+                    }
+                    if debug:
+                        print("üìä Using fallback entry IDs")
+            else:
+                response.raise_for_status()
+            
+            # Extract entry IDs from the form HTML
+            html_content = response.text
+            
+            # Google Forms uses a data structure in the HTML that contains question mappings
+            # Look for the FB_PUBLIC_LOAD_DATA_ variable which contains form structure
+            import json
+            
+            entry_map = {}
+            
+            # Method 1: Extract from FB_PUBLIC_LOAD_DATA_
+            fb_data_match = re.search(r'FB_PUBLIC_LOAD_DATA_\s*=\s*(\[.+?\]);', html_content, re.DOTALL)
+            if fb_data_match:
+                try:
+                    fb_data = json.loads(fb_data_match.group(1))
+                    # Parse the nested structure to find questions
+                    if len(fb_data) > 1 and isinstance(fb_data[1], list):
+                        form_data = fb_data[1]
+                        if len(form_data) > 1 and isinstance(form_data[1], list):
+                            for item in form_data[1]:
+                                if isinstance(item, list) and len(item) > 4:
+                                    # item[1] is usually the title
+                                    # item[4][0][0] is usually the entry ID
+                                    if len(item) > 1 and isinstance(item[4], list) and len(item[4]) > 0:
+                                        title = str(item[1]).lower() if item[1] else ""
+                                        entry_id = str(item[4][0][0]) if len(item[4][0]) > 0 else None
+                                        
+                                        if entry_id and title:
+                                            if 'from email' in title:
+                                                entry_map['from_email'] = entry_id
+                                            elif 'to email' in title:
+                                                entry_map['to_email'] = entry_id
+                                            elif 'message id' in title:
+                                                entry_map['message_id'] = entry_id
+                                            elif 'message size' in title:
+                                                entry_map['message_size'] = entry_id
+                                            elif 'message data' in title:
+                                                entry_map['message_data'] = entry_id
+                                            elif 'file path' in title:
+                                                entry_map['file_path'] = entry_id
+                except Exception as parse_error:
+                    if debug:
+                        print(f"‚ö†Ô∏è  Could not parse FB_PUBLIC_LOAD_DATA: {parse_error}")
+            
+            # Method 2: Try multiple regex patterns as fallback
+            if not entry_map:
+                # Pattern 1: data-params with entry IDs
+                pattern1 = r'data-params=".*?\[(\d+),\d+,.*?\[.*?&quot;(.*?)&quot;'
+                # Pattern 2: name="entry.X" with aria-label
+                pattern2 = r'name="entry\.(\d+)"[^>]*aria-label="([^"]*)"'
+                # Pattern 3: jsname attribute pattern
+                pattern3 = r'jsname="[^"]*"[^>]*data-params="[^"]*\[(\d+)[^"]*"[^>]*>[^<]*<[^>]*>([^<]+)<'
+                
+                for pattern in [pattern1, pattern2, pattern3]:
+                    matches = re.findall(pattern, html_content, re.DOTALL)
+                    for entry_id, title in matches:
+                        title_lower = title.lower().strip()
+                        if 'from email' in title_lower:
+                            entry_map['from_email'] = entry_id
+                        elif 'to email' in title_lower:
+                            entry_map['to_email'] = entry_id
+                        elif 'message id' in title_lower:
+                            entry_map['message_id'] = entry_id
+                        elif 'message size' in title_lower:
+                            entry_map['message_size'] = entry_id
+                        elif 'message data' in title_lower:
+                            entry_map['message_data'] = entry_id
+                        elif 'file path' in title_lower:
+                            entry_map['file_path'] = entry_id
+            
+            # Also look for all entry fields
+            entry_fields = re.findall(r'entry\.(\d+)', html_content)
+            
+            if debug:
+                print(f"üìä Found entry map: {entry_map}")
+                print(f"üìä All entry fields found: {list(set(entry_fields))[:10]}...")  # Show first 10
+                
+                # Save HTML for debugging if no entries found
+                if not entry_map and debug:
+                    with open('/tmp/form_debug.html', 'w') as f:
+                        f.write(html_content)
+                    print("üíæ Saved form HTML to /tmp/form_debug.html for debugging")
+            
+            # If we didn't find entries with titles, try to map by order
+            if not entry_map and entry_fields:
+                # Remove duplicates and sort
+                unique_entries = sorted(list(set(entry_fields)))
+                if len(unique_entries) >= 5:
+                    if debug:
+                        print(f"‚ö†Ô∏è  Using positional mapping for {len(unique_entries)} fields")
+                    entry_map = {
+                        'from_email': unique_entries[0],
+                        'to_email': unique_entries[1],
+                        'message_id': unique_entries[2],
+                        'message_size': unique_entries[3],
+                        'message_data': unique_entries[4],
+                    }
+                    if len(unique_entries) >= 6:
+                        entry_map['file_path'] = unique_entries[5]
+            
+            # Build form data for submission
+            form_data = {}
+            if 'from_email' in entry_map:
+                form_data[f'entry.{entry_map["from_email"]}'] = from_email
+            if 'to_email' in entry_map:
+                form_data[f'entry.{entry_map["to_email"]}'] = to_email
+            if 'message_id' in entry_map:
+                form_data[f'entry.{entry_map["message_id"]}'] = message_id
+            if 'message_size' in entry_map:
+                form_data[f'entry.{entry_map["message_size"]}'] = message_size
+            if 'message_data' in entry_map:
+                form_data[f'entry.{entry_map["message_data"]}'] = message_data
+            if file_path and 'file_path' in entry_map:
+                form_data[f'entry.{entry_map["file_path"]}'] = file_path
+            
+            if debug:
+                print(f"üì§ Submitting form data with {len(form_data)} fields")
+                print(f"   Fields: {list(form_data.keys())}")
+            
+            # Submit the form
+            submit_url = f"https://docs.google.com/forms/d/{form_id}/formResponse"
+            headers = {
+                'Content-Type': 'application/x-www-form-urlencoded',
+                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
+                'Referer': form_url,
+                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
+            }
+            
+            response = requests.post(submit_url, data=form_data, headers=headers, allow_redirects=False)
+            
+            if debug:
+                print(f"üì¨ Response status: {response.status_code}")
+                print(f"   Response headers: {dict(response.headers)}")
+            
+            # Check if submission was successful
+            # Google Forms returns 200, 302, or 303 on successful submission
+            if response.status_code in [200, 302, 303]:
+                if self.verbose or debug:
+                    print(f"‚úÖ Successfully submitted message to form")
+                    print(f"   Message ID: {message_id}")
+                return True
+            else:
+                if self.verbose or debug:
+                    print(f"‚ùå Form submission failed with status code: {response.status_code}")
+                    if response.text:
+                        print(f"   Response preview: {response.text[:500]}...")
+                return False
+                
+        except Exception as e:
+            if self.verbose or debug:
+                print(f"‚ùå Error submitting to form: {e}")
+                import traceback
+                traceback.print_exc()
+            return False
+    
+    def analyze_public_form(self, form_url: str) -> Dict[str, str]:
+        """
+        Analyze a public Google Form to extract entry IDs for each field.
+        
+        Args:
+            form_url: URL of the public Google Form
+            
+        Returns:
+            Dictionary mapping field names to entry IDs
+        """
+        import requests
+        import re
+        
+        print(f"üîç Analyzing form: {form_url}")
+        
+        # Fetch the form
+        response = requests.get(form_url)
+        if response.status_code != 200:
+            print(f"‚ùå Failed to fetch form: {response.status_code}")
+            return {}
+            
+        html = response.text
+        
+        # Save for detailed analysis
+        with open('/tmp/public_form.html', 'w') as f:
+            f.write(html)
+        print("üíæ Saved form HTML to /tmp/public_form.html")
+        
+        # Extract form action URL (for submission)
+        action_match = re.search(r'<form[^>]+action="([^"]+)"', html)
+        if action_match:
+            print(f"üì§ Form action URL: {action_match.group(1)}")
+        
+        # Method 1: Look for entry IDs in FB_PUBLIC_LOAD_DATA_
+        entry_map = {}
+        fb_data_match = re.search(r'var\s+FB_PUBLIC_LOAD_DATA_\s*=\s*(\{[^;]+\});', html, re.DOTALL)
+        if fb_data_match:
+            print("‚úÖ Found FB_PUBLIC_LOAD_DATA_")
+            # Extract all entry.XXXXX patterns
+            entries = re.findall(r'"(entry\.\d+)"', fb_data_match.group(1))
+            print(f"üìä Found {len(entries)} entry fields")
+            for i, entry in enumerate(entries):
+                print(f"  {i+1}: {entry}")
+        
+        # Method 2: Look for data-params patterns
+        data_params = re.findall(r'data-params="[^"]*?\[(\d+),\d+,[^]]*\]"[^>]*>([^<]+)<', html)
+        if data_params:
+            print(f"\nüìä Found {len(data_params)} fields via data-params")
+            for entry_id, label in data_params:
+                print(f"  Entry {entry_id}: {label.strip()}")
+        
+        # Method 3: Direct entry field search
+        all_entries = re.findall(r'entry\.(\d+)', html)
+        unique_entries = sorted(list(set(all_entries)))
+        print(f"\nüìä All unique entry IDs found: {unique_entries}")
+        
+        return {
+            'entries': unique_entries,
+            'form_url': form_url
+        }
+    
+    def prepare_form_submission(self, form_url: str, debug: bool = True) -> Dict[str, any]:
+        """
+        Prepare for form submission by extracting all necessary metadata.
+        Call this once and reuse the result for multiple submissions.
+        
+        Args:
+            form_url: The URL of the Google Form
+            debug: Enable debug output
+            
+        Returns:
+            Dict with:
+                - 'form_id': The extracted form ID
+                - 'entry_map': Mapping of field names to entry IDs
+                - 'submit_url': The URL to POST to
+                - 'form_url': The original form URL
+        """
+        import requests
+        import re
+        import json
+        
+        # Extract form ID from URL
+        form_id_match = re.search(r'/forms/d/(?:e/)?([a-zA-Z0-9_-]+)/', form_url)
+        if not form_id_match:
+            raise ValueError(f"Could not extract form ID from URL: {form_url}")
+        
+        form_id = form_id_match.group(1)
+        
+        if debug:
+            print(f"üìù Preparing form submission for: {form_url}")
+            print(f"üìã Form ID: {form_id}")
+        
+        try:
+            # Fetch the form to get field IDs
+            session = requests.Session()
+            response = session.get(form_url)
+            
+            # Check if we got a login redirect
+            if response.status_code == 401 or 'accounts.google.com' in response.url:
+                if debug:
+                    print("‚ö†Ô∏è  Form requires authentication. Cannot extract entry IDs from HTML.")
+                    print("    Please make the form public or provide entry IDs manually.")
+                return {
+                    'error': 'Form requires authentication',
+                    'form_id': form_id,
+                    'form_url': form_url
+                }
+            
+            response.raise_for_status()
+            html_content = response.text
+            
+            # Extract entry IDs from the form HTML
+            entry_map = {}
+            
+            # Method 1: Extract from FB_PUBLIC_LOAD_DATA_
+            fb_data_match = re.search(r'FB_PUBLIC_LOAD_DATA_\s*=\s*(\[.+?\]);', html_content, re.DOTALL)
+            if fb_data_match:
+                try:
+                    fb_data = json.loads(fb_data_match.group(1))
+                    # Parse the nested structure to find questions
+                    if len(fb_data) > 1 and isinstance(fb_data[1], list):
+                        form_data = fb_data[1]
+                        if len(form_data) > 1 and isinstance(form_data[1], list):
+                            for item in form_data[1]:
+                                if isinstance(item, list) and len(item) > 4:
+                                    if len(item) > 1 and isinstance(item[4], list) and len(item[4]) > 0:
+                                        title = str(item[1]).lower() if item[1] else ""
+                                        entry_id = str(item[4][0][0]) if len(item[4][0]) > 0 else None
+                                        
+                                        if entry_id and title:
+                                            if 'from email' in title:
+                                                entry_map['from_email'] = entry_id
+                                            elif 'to email' in title:
+                                                entry_map['to_email'] = entry_id
+                                            elif 'message id' in title:
+                                                entry_map['message_id'] = entry_id
+                                            elif 'message size' in title:
+                                                entry_map['message_size'] = entry_id
+                                            elif 'message data' in title:
+                                                entry_map['message_data'] = entry_id
+                                            elif 'file path' in title:
+                                                entry_map['file_path'] = entry_id
+                except Exception as e:
+                    if debug:
+                        print(f"‚ö†Ô∏è  Could not parse FB_PUBLIC_LOAD_DATA: {e}")
+            
+            # Method 2: Try regex patterns as fallback
+            if not entry_map:
+                patterns = [
+                    r'data-params=".*?\[(\d+),\d+,.*?\[.*?&quot;(.*?)&quot;',
+                    r'name="entry\.(\d+)"[^>]*aria-label="([^"]*)"',
+                ]
+                for pattern in patterns:
+                    matches = re.findall(pattern, html_content, re.DOTALL)
+                    for entry_id, title in matches:
+                        title_lower = title.lower().strip()
+                        if 'from email' in title_lower:
+                            entry_map['from_email'] = entry_id
+                        elif 'to email' in title_lower:
+                            entry_map['to_email'] = entry_id
+                        elif 'message id' in title_lower:
+                            entry_map['message_id'] = entry_id
+                        elif 'message size' in title_lower:
+                            entry_map['message_size'] = entry_id
+                        elif 'message data' in title_lower:
+                            entry_map['message_data'] = entry_id
+                        elif 'file path' in title_lower:
+                            entry_map['file_path'] = entry_id
+            
+            if debug:
+                print(f"üìä Extracted entry map: {entry_map}")
+            
+            # Build submit URL (use /d/ not /d/e/ for submission)
+            submit_url = f"https://docs.google.com/forms/d/{form_id}/formResponse"
+            
+            return {
+                'form_id': form_id,
+                'entry_map': entry_map,
+                'submit_url': submit_url,
+                'form_url': form_url,
+                'prepared_at': datetime.now().isoformat()
+            }
+            
+        except Exception as e:
+            if debug:
+                print(f"‚ùå Error preparing form: {e}")
+            return {
+                'error': str(e),
+                'form_id': form_id,
+                'form_url': form_url
+            }
+    
+    def submit_to_form_fast(self, form_metadata: Optional[Dict[str, any]] = None, from_email: str = None, 
+                           to_email: str = None, message_id: str = None, message_size: str = None, 
+                           message_data: str = None, file_path: Optional[str] = None, debug: bool = False) -> bool:
+        """
+        Fast form submission using pre-extracted metadata.
+        
+        Args:
+            form_metadata: Optional result from prepare_form_submission(). If None, uses cached form_inbox_metadata
+            from_email: Sender's email address
+            to_email: Recipient's email address
+            message_id: Unique message ID
+            message_size: Size of encoded message in bytes
+            message_data: Base64-encoded message data
+            file_path: Optional file path within datasites/ directory
+            debug: Enable debug output
+            
+        Returns:
+            bool: True if submission was successful
+        """
+        import requests
+        
+        # Use cached form_inbox_metadata if not provided
+        if form_metadata is None:
+            form_metadata = self.form_inbox_metadata
+            if debug:
+                print("üìã Using cached form_inbox_metadata")
+        
+        if 'error' in form_metadata:
+            if debug:
+                print(f"‚ùå Cannot submit - form preparation failed: {form_metadata['error']}")
+            return False
+        
+        # Validate required parameters
+        if not all([from_email, to_email, message_id, message_size, message_data]):
+            raise ValueError("Missing required parameters: from_email, to_email, message_id, message_size, and message_data are all required")
+        
+        entry_map = form_metadata.get('entry_map', {})
+        submit_url = form_metadata.get('submit_url')
+        
+        if not submit_url:
+            if debug:
+                print("‚ùå No submit URL in form metadata")
+            return False
+        
+        # Build form data
+        form_data = {}
+        if 'from_email' in entry_map:
+            form_data[f'entry.{entry_map["from_email"]}'] = from_email
+        if 'to_email' in entry_map:
+            form_data[f'entry.{entry_map["to_email"]}'] = to_email
+        if 'message_id' in entry_map:
+            form_data[f'entry.{entry_map["message_id"]}'] = message_id
+        if 'message_size' in entry_map:
+            form_data[f'entry.{entry_map["message_size"]}'] = message_size
+        if 'message_data' in entry_map:
+            form_data[f'entry.{entry_map["message_data"]}'] = message_data
+        if file_path and 'file_path' in entry_map:
+            form_data[f'entry.{entry_map["file_path"]}'] = file_path
+        
+        # Add necessary headers
+        headers = {
+            'Content-Type': 'application/x-www-form-urlencoded',
+            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
+            'Referer': form_metadata.get('form_url', submit_url),
+            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
+        }
+        
+        if debug:
+            print(f"üì§ Submitting to: {submit_url}")
+            print(f"   Form data fields: {list(form_data.keys())}")
+        
+        try:
+            # Submit the form with proper headers and no redirect following
+            response = requests.post(submit_url, data=form_data, headers=headers, 
+                                   allow_redirects=False, timeout=10)
+            
+            if debug:
+                print(f"üì¨ Response status: {response.status_code}")
+            
+            # Google Forms returns 200, 302, or 303 on successful submission
+            if response.status_code in [200, 302, 303]:
+                if debug:
+                    print(f"‚úÖ Successfully submitted message {message_id}")
+                return True
+            else:
+                if debug:
+                    print(f"‚ùå Submission failed with status {response.status_code}")
+                    if response.text:
+                        print(f"   Response preview: {response.text[:200]}...")
+                return False
+                
+        except Exception as e:
+            if debug:
+                print(f"‚ùå Error during submission: {e}")
+                import traceback
+                traceback.print_exc()
+            return False
+    
+    def submit_to_public_form(self, form_url: str, entry_mapping: Dict[str, str]) -> bool:
+        """
+        Submit data to a public Google Form using the exact entry IDs.
+        
+        Args:
+            form_url: URL of the public form
+            entry_mapping: Dictionary mapping entry IDs to values
+                          e.g. {'1234567': 'test@example.com', ...}
+                          
+        Returns:
+            bool: True if submission successful
+        """
+        import requests
+        import re
+        
+        # Extract form ID
+        form_id_match = re.search(r'/forms/d/([a-zA-Z0-9_-]+)/', form_url)
+        if not form_id_match:
+            print("‚ùå Could not extract form ID")
+            return False
+            
+        form_id = form_id_match.group(1)
+        
+        # Build submission URL
+        submit_url = f"https://docs.google.com/forms/d/{form_id}/formResponse"
+        
+        # Build form data
+        form_data = {}
+        for entry_id, value in entry_mapping.items():
+            if not entry_id.startswith('entry.'):
+                entry_id = f'entry.{entry_id}'
+            form_data[entry_id] = value
+        
+        print(f"üì§ Submitting to: {submit_url}")
+        print(f"üìä Form data: {list(form_data.keys())}")
+        
+        # Submit
+        headers = {
+            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
+            'Content-Type': 'application/x-www-form-urlencoded',
+            'Referer': form_url
+        }
+        
+        response = requests.post(submit_url, data=form_data, headers=headers, allow_redirects=False)
+        
+        print(f"üì¨ Response status: {response.status_code}")
+        
+        # Check success
+        if response.status_code in [200, 302, 303]:
+            print("‚úÖ Form submitted successfully!")
+            if 'location' in response.headers:
+                print(f"üìç Redirect URL: {response.headers['location']}")
+            return True
+        else:
+            print(f"‚ùå Submission failed: {response.status_code}")
+            return False
+    
+    def open_form_for_manual_testing(self, form_url: str) -> None:
+        """
+        Opens the form in a web browser for manual testing and configuration.
+        This is useful when programmatic submission isn't working.
+        
+        Args:
+            form_url: URL of the Google Form
+        """
+        import webbrowser
+        import time
+        
+        print("üìù Opening form in your browser...")
+        print("\n‚ö†Ô∏è  Important steps for manual testing:")
+        print("1. If prompted, sign in to Google")
+        print("2. Check the form's sharing settings (3-dot menu ‚Üí Settings ‚Üí General)")
+        print("3. Make sure 'Restrict to users in [org] and its trusted organizations' is OFF")
+        print("4. Try submitting a test response manually")
+        print(f"\nüîó Form URL: {form_url}")
+        
+        # Extract form ID for edit URL
+        import re
+        form_id_match = re.search(r'/forms/d/(?:e/)?([a-zA-Z0-9_-]+)/', form_url)
+        if form_id_match:
+            form_id = form_id_match.group(1)
+            # Try to find the actual form ID (not the prefixed one)
+            if hasattr(self, '_last_created_form') and self._last_created_form:
+                actual_form_id = self._last_created_form.get('form_id')
+                if actual_form_id:
+                    edit_url = f"https://docs.google.com/forms/d/{actual_form_id}/edit"
+                    print(f"üìù Edit URL: {edit_url}")
+                    print("\nüí° To check sharing settings, open the edit URL and click the Settings gear icon")
+        
+        webbrowser.open(form_url)
+        print("\n‚úÖ Form opened in browser. Please check the settings and test manually.")
+    
+    def get_form_responses(self, form_id: str) -> List[Dict[str, any]]:
+        """
+        Get responses from a Google Form by accessing the linked spreadsheet.
+        
+        Args:
+            form_id: The ID of the Google Form
+            
+        Returns:
+            List of form responses as dictionaries
+        """
+        self._ensure_authenticated()
+        
+        try:
+            # Find the response spreadsheet for this form
+            # Forms typically create a spreadsheet with "(Responses)" in the title
+            query = f"name contains 'Responses' and mimeType='application/vnd.google-apps.spreadsheet'"
+            results = self.service.files().list(
+                q=query,
+                fields="files(id, name)"
+            ).execute()
+            
+            items = results.get('files', [])
+            response_sheet_id = None
             
-            return sorted(list(friends_set))
+            # Look for the spreadsheet that matches our form
+            for item in items:
+                if form_id[:10] in item['name'] or f"SyftBox Messages - {self.my_email}" in item['name']:
+                    response_sheet_id = item['id']
+                    break
+                    
+            if not response_sheet_id:
+                if self.verbose:
+                    print("‚ö†Ô∏è  No response spreadsheet found. Responses may not be linked yet.")
+                return []
+                
+            # Read the spreadsheet using Sheets API
+            sheets_service = self._get_sheets_service()
+            
+            # Get all values from the first sheet
+            result = sheets_service.spreadsheets().values().get(
+                spreadsheetId=response_sheet_id,
+                range='A:Z'  # Get all columns
+            ).execute()
+            
+            values = result.get('values', [])
+            
+            if not values:
+                return []
+                
+            # First row contains headers
+            headers = values[0]
+            responses = []
+            
+            # Convert each row to a dictionary
+            for row in values[1:]:
+                response = {}
+                for i, header in enumerate(headers):
+                    if i < len(row):
+                        response[header] = row[i]
+                    else:
+                        response[header] = ""
+                responses.append(response)
+                
+            if self.verbose:
+                print(f"‚úÖ Found {len(responses)} form responses")
+                
+            return responses
             
         except Exception as e:
             if self.verbose:
-                print(f"‚ùå Error listing friends: {e}")
+                print(f"‚ùå Error getting form responses: {e}")
             return []
     
-    @property
-    def friend_requests(self) -> List[str]:
+    def launch_watcher_sender(self) -> Dict[str, any]:
         """
-        List emails of people who have shared folders with you but you haven't shared back
+        Launch a background file watcher that automatically sends file changes to all friends
         
         Returns:
-            List of email addresses with pending friend requests
+            Dict with status, message, and server URL
         """
-        if not self.authenticated:
-            return []
-        
-        if not self.my_email:
-            return []
-        
         try:
-            # Get all syft folders
-            all_folders = self._list_syft_folders()
-            
-            # Track who has shared with us
-            shared_with_me = set()
-            # Track who we've shared with
-            shared_by_me = set()
-            
-            # Check folders in "Shared with me" - these are folders others created
-            for folder in all_folders['shared_with_me']:
-                name = folder['name']
-                if '_to_' in name and name.startswith('syft_'):
-                    parts = name.split('_to_')
-                    if len(parts) == 2:
-                        sender = parts[0].replace('syft_', '')
-                        recipient_with_suffix = parts[1]
-                        
-                        # Remove suffixes
-                        if '_outbox_inbox' in recipient_with_suffix:
-                            recipient = recipient_with_suffix.replace('_outbox_inbox', '')
-                        elif '_outbox' in recipient_with_suffix:
-                            recipient = recipient_with_suffix.replace('_outbox', '')
-                        elif '_pending' in recipient_with_suffix:
-                            recipient = recipient_with_suffix.replace('_pending', '')
-                        elif '_archive' in recipient_with_suffix:
-                            recipient = recipient_with_suffix.replace('_archive', '')
-                        else:
-                            recipient = recipient_with_suffix.rsplit('_', 1)[0]
-                        
-                        # If they're sharing with us, track them
-                        if recipient == self.my_email:
-                            shared_with_me.add(sender)
+            # Import here to avoid circular dependencies
+            from . import watcher
             
-            # Check if SyftBoxTransportService exists
-            syftbox_id = None
-            try:
-                results = self.service.files().list(
-                    q="name='SyftBoxTransportService' and mimeType='application/vnd.google-apps.folder' and 'root' in parents and trashed=false",
-                    fields="files(id)"
-                ).execute()
-                if results.get('files'):
-                    syftbox_id = results['files'][0]['id']
-            except:
-                pass
+            # Create the watcher endpoint (blocks until server is ready)
+            server = watcher.create_watcher_sender_endpoint(self.my_email)
             
-            if syftbox_id:
-                # Get folders inside SyftBoxTransportService
-                try:
-                    results = self.service.files().list(
-                        q=f"'{syftbox_id}' in parents and name contains 'syft_' and mimeType='application/vnd.google-apps.folder' and trashed=false",
-                        fields="files(name)"
-                    ).execute()
-                    
-                    for folder in results.get('files', []):
-                        name = folder['name']
-                        # Look for folders we created (either outgoing or archive for incoming)
-                        if name.startswith(f'syft_{self.my_email}_to_'):
-                            # This is our outgoing folder
-                            parts = name.split('_to_')
-                            if len(parts) == 2:
-                                email_with_suffix = parts[1]
-                                
-                                # Remove suffixes
-                                if '_outbox_inbox' in email_with_suffix:
-                                    email_part = email_with_suffix.replace('_outbox_inbox', '')
-                                elif '_outbox' in email_with_suffix:
-                                    email_part = email_with_suffix.replace('_outbox', '')
-                                elif '_pending' in email_with_suffix:
-                                    email_part = email_with_suffix.replace('_pending', '')
-                                elif '_archive' in email_with_suffix:
-                                    email_part = email_with_suffix.replace('_archive', '')
-                                else:
-                                    email_part = email_with_suffix.rsplit('_', 1)[0]
-                                
-                                shared_by_me.add(email_part)
-                        elif '_to_' in name and name.endswith(f'_to_{self.my_email}_archive'):
-                            # This is an archive folder we created for someone else's messages
-                            parts = name.split('_to_')
-                            if len(parts) == 2:
-                                sender = parts[0].replace('syft_', '')
-                                # We have an archive for them, so we've reciprocated
-                                shared_by_me.add(sender)
-                except:
-                    pass
+            result = {
+                "status": "started",
+                "message": f"Watcher launched successfully for {self.my_email}",
+                "url": server.url
+            }
             
-            # Friend requests = people who shared with us but we haven't shared back
-            friend_requests = shared_with_me - shared_by_me
+            if self.verbose:
+                print(f"‚úÖ Watcher launched at: {server.url}")
             
-            return sorted(list(friend_requests))
+            return result
             
         except Exception as e:
+            result = {
+                "status": "error",
+                "message": f"Failed to launch watcher: {str(e)}",
+                "url": None
+            }
             if self.verbose:
-                print(f"‚ùå Error listing friend requests: {e}")
-            return []
+                print(f"‚ùå Failed to launch watcher: {e}")
+            return result
     
-    def _list_syft_folders(self, print_summary: bool = False) -> Dict[str, List[Dict]]:
+    def terminate_watcher_sender(self) -> Dict[str, any]:
         """
-        List all folders starting with 'syft_' in both My Drive and Shared with me
+        Terminate the background file watcher
         
-        Args:
-            print_summary: Whether to print a summary of found folders (default: False)
-            
         Returns:
-            Dictionary with 'my_drive' and 'shared_with_me' lists
+            Dict with status and message
         """
-        self._ensure_authenticated()
+        import threading
+        import time
         
-        result = {
-            'my_drive': [],
-            'shared_with_me': []
-        }
+        result = {"status": "pending", "message": "Terminating watcher..."}
         
-        try:
-            # First, find all syft_ folders in My Drive
-            if print_summary:
-                print("üîç Searching for syft_ folders in My Drive...")
-            my_drive_results = self.service.files().list(
-                q="name contains 'syft_' and mimeType='application/vnd.google-apps.folder' and trashed=false",
-                fields="files(id, name, parents, permissions, owners)",
-                pageSize=100
-            ).execute()
-            
-            for folder in my_drive_results.get('files', []):
-                # Only include folders that START with syft_
-                if not folder['name'].startswith('syft_'):
-                    continue
-                    
-                # Get parent folder name
-                parent_name = "root"
-                if folder.get('parents'):
-                    try:
-                        parent = self.service.files().get(
-                            fileId=folder['parents'][0],
-                            fields='name'
-                        ).execute()
-                        parent_name = parent.get('name', 'unknown')
-                    except:
-                        parent_name = "unknown"
+        def _terminate_watcher():
+            try:
+                # Import here to avoid circular dependencies
+                from . import watcher
                 
-                folder_info = {
-                    'id': folder['id'],
-                    'name': folder['name'],
-                    'parent': parent_name,
-                    'owner': folder.get('owners', [{}])[0].get('emailAddress', 'unknown')
-                }
-                result['my_drive'].append(folder_info)
+                # Destroy the watcher endpoint
+                success = watcher.destroy_watcher_sender_endpoint(self.my_email)
+                
+                if success:
+                    result["status"] = "terminated"
+                    result["message"] = f"Watcher terminated successfully for {self.my_email}"
+                    if self.verbose:
+                        print(f"‚úÖ Watcher terminated for {self.my_email}")
+                else:
+                    result["status"] = "not_found"
+                    result["message"] = f"No watcher found for {self.my_email}"
+                    if self.verbose:
+                        print(f"‚ö†Ô∏è  No watcher found for {self.my_email}")
+                        
+            except Exception as e:
+                result["status"] = "error"
+                result["message"] = f"Failed to terminate watcher: {str(e)}"
+                if self.verbose:
+                    print(f"‚ùå Failed to terminate watcher: {e}")
+        
+        # Launch in background thread
+        thread = threading.Thread(target=_terminate_watcher, daemon=True)
+        thread.start()
+        
+        # Give it a moment to complete
+        time.sleep(0.1)
+        
+        return result
+    
+    def launch_receiver(self, interval_seconds: float = 1.0) -> Dict[str, any]:
+        """
+        Launch a background receiver that automatically processes incoming messages
+        
+        Args:
+            interval_seconds: How often to check for changes (default: 1 second)
+                            Sheets API will be polled at this interval
             
-            # Now search in Shared with me
-            if print_summary:
-                print("\nüîç Searching for syft_ folders in Shared with me...")
-            shared_results = self.service.files().list(
-                q="name contains 'syft_' and mimeType='application/vnd.google-apps.folder' and sharedWithMe and trashed=false",
-                fields="files(id, name, permissions, owners)",
-                pageSize=100
-            ).execute()
+        Returns:
+            Dict with status, message, and server URL
+        """
+        try:
+            # Import here to avoid circular dependencies
+            from . import receiver
             
-            for folder in shared_results.get('files', []):
-                # Only include folders that START with syft_
-                if not folder['name'].startswith('syft_'):
-                    continue
-                    
-                folder_info = {
-                    'id': folder['id'],
-                    'name': folder['name'],
-                    'owner': folder.get('owners', [{}])[0].get('emailAddress', 'unknown'),
-                    'shared': True
-                }
-                result['shared_with_me'].append(folder_info)
+            # Create the receiver endpoint (blocks until server is ready)
+            server = receiver.create_receiver_endpoint(self.my_email, interval_seconds)
             
-            # Print summary if requested
-            if print_summary:
-                print(f"\nüìÅ Found {len(result['my_drive'])} syft_ folders in My Drive:")
-                for folder in result['my_drive']:
-                    print(f"   - {folder['name']}")
-                    print(f"     Parent: {folder['parent']}")
-                    print(f"     Owner: {folder['owner']}")
-                    print(f"     ID: {folder['id']}")
-                
-                print(f"\nü§ù Found {len(result['shared_with_me'])} syft_ folders in Shared with me:")
-                for folder in result['shared_with_me']:
-                    print(f"   - {folder['name']}")
-                    print(f"     Owner: {folder['owner']}")
-                    print(f"     ID: {folder['id']}")
-                
-                # Check for incoming channels without shortcuts
-                if result['shared_with_me']:
-                    print("\nüí° Incoming channels that might need shortcuts:")
-                    for folder in result['shared_with_me']:
-                        if '_to_' in folder['name'] and self.my_email:
-                            if f"_to_{self.my_email}_" in folder['name']:
-                                print(f"   - {folder['name']} (from {folder['owner']})")
+            result = {
+                "status": "started",
+                "message": f"Receiver launched successfully for {self.my_email} (interval: {interval_seconds}s)",
+                "url": server.url
+            }
             
+            if self.verbose:
+                print(f"‚úÖ Receiver launched at: {server.url}")
+                print(f"   Polling interval: {interval_seconds}s")
+                
             return result
             
-        except HttpError as e:
-            if print_summary:
-                print(f"‚ùå Error listing syft folders: {e}")
+        except Exception as e:
+            result = {
+                "status": "error",
+                "message": f"Failed to launch receiver: {str(e)}",
+                "url": None
+            }
+            if self.verbose:
+                print(f"‚ùå Failed to launch receiver: {e}")
             return result
     
-    def _create_shortcuts_for_friend(self, friend_email: str, syftbox_id: Optional[str] = None) -> Dict[str, int]:
+    def terminate_receiver(self) -> Dict[str, any]:
+        """
+        Terminate the background receiver
+        
+        Returns:
+            Dict with status and message
+        """
+        import threading
+        import time
+        
+        result = {"status": "pending", "message": "Terminating receiver..."}
+        
+        def _terminate_receiver():
+            try:
+                # Import here to avoid circular dependencies
+                from . import receiver
+                
+                # Destroy the receiver endpoint
+                success = receiver.destroy_receiver_endpoint(self.my_email)
+                
+                if success:
+                    result["status"] = "terminated"
+                    result["message"] = f"Receiver terminated successfully for {self.my_email}"
+                    if self.verbose:
+                        print(f"‚úÖ Receiver terminated for {self.my_email}")
+                else:
+                    result["status"] = "not_found"
+                    result["message"] = f"No receiver found for {self.my_email}"
+                    if self.verbose:
+                        print(f"‚ö†Ô∏è  No receiver found for {self.my_email}")
+                        
+            except Exception as e:
+                result["status"] = "error"
+                result["message"] = f"Failed to terminate receiver: {str(e)}"
+                if self.verbose:
+                    print(f"‚ùå Failed to terminate receiver: {e}")
+        
+        # Launch in background thread
+        thread = threading.Thread(target=_terminate_receiver, daemon=True)
+        thread.start()
+        
+        # Give it a moment to complete
+        time.sleep(0.1)
+        
+        return result
+    
+    def get_receiver_stats(self) -> Dict[str, any]:
         """
-        Create shortcuts in SyftBoxTransportService for folders shared by a specific friend
+        Get statistics from the running receiver
+        
+        Returns:
+            Dict with receiver statistics or None if not running
+        """
+        try:
+            from . import receiver
+            return receiver.get_receiver_stats(self.my_email)
+        except Exception as e:
+            if self.verbose:
+                print(f"‚ùå Failed to get receiver stats: {e}")
+            return None
+    
+    def test_rate_limit(self, sheet_url: str) -> Dict[str, any]:
+        """
+        Test rate limits by alternating between Sheets API and Drive API
+        to see if they share the same rate limiter
         
         Args:
-            friend_email: Email of the friend whose folders to create shortcuts for
-            syftbox_id: Optional SyftBoxTransportService folder ID (will find if not provided)
-            
+            sheet_url: Google Sheets URL to test
+                      Format: https://docs.google.com/spreadsheets/d/{SHEET_ID}/edit...
+        
         Returns:
-            Dictionary with counts of shortcuts created, skipped, and failed
+            Dict with test results showing performance of alternating API calls
         """
-        self._ensure_authenticated()
+        if not self.authenticated:
+            raise ValueError("Client must be authenticated first")
         
-        results = {
-            'created': 0,
-            'skipped': 0,
-            'failed': 0
+        # Extract sheet ID from URL
+        import re
+        match = re.search(r'/spreadsheets/d/([a-zA-Z0-9-_]+)', sheet_url)
+        if not match:
+            return {
+                "error": "Invalid Google Sheets URL format",
+                "calls_made": 0
+            }
+        
+        sheet_id = match.group(1)
+        print(f"\nüß™ Testing rate limits by alternating between APIs")
+        print(f"   Sheet ID: {sheet_id}")
+        print(f"   Strategy: Alternate between Sheets API and Drive API")
+        
+        # Initialize services
+        sheets_service = self._get_sheets_service()
+        
+        # Track statistics
+        successful_calls = {
+            "sheets": 0,
+            "drive": 0,
+            "total": 0
         }
+        total_calls = 0
+        start_time = time.time()
+        errors = []
+        rate_limits_hit = {
+            "sheets": False,
+            "drive": False
+        }
+        last_modified_time = None
+        last_row_count = 0
+        last_drive_content = None
         
-        try:
-            # Get or find SyftBox folder
-            if not syftbox_id:
-                syftbox_id = self.setup_syftbox()
-                if not syftbox_id:
-                    return results
-            
-            # Find folders shared by this friend
-            shared_results = self.service.files().list(
-                q=f"name contains 'syft_{friend_email}_to_' and mimeType='application/vnd.google-apps.folder' and sharedWithMe and trashed=false",
-                fields="files(id, name)",
-                pageSize=100
-            ).execute()
-            
-            # Get existing shortcuts in SyftBox to avoid duplicates
-            existing_shortcuts = {}
+        print("\n   Starting alternating API calls...")
+        print("   S = Sheets API success, D = Drive API success, X = Error")
+        print("   Progress: ", end="", flush=True)
+        
+        while True:
             try:
-                existing_results = self.service.files().list(
-                    q=f"'{syftbox_id}' in parents and mimeType='application/vnd.google-apps.shortcut' and trashed=false",
-                    fields="files(name, shortcutDetails)"
-                ).execute()
-                
-                for shortcut in existing_results.get('files', []):
-                    target_id = shortcut.get('shortcutDetails', {}).get('targetId')
-                    if target_id:
-                        existing_shortcuts[target_id] = shortcut['name']
-            except:
-                pass
-            
-            # Create shortcuts for each shared folder
-            for folder in shared_results.get('files', []):
-                if not folder['name'].startswith('syft_'):
-                    continue
+                # Check if 90 seconds have elapsed
+                elapsed = time.time() - start_time
+                if elapsed >= 90:
+                    print(f"\n\n   ‚è±Ô∏è  90-second time limit reached!")
+                    print(f"\n   üìä Final Statistics:")
+                    print(f"      - Total successful calls: {successful_calls['total']}")
+                    print(f"      - Sheets API calls: {successful_calls['sheets']}")
+                    print(f"      - Drive API calls: {successful_calls['drive']}")
+                    print(f"      - Time elapsed: {elapsed:.2f} seconds")
+                    print(f"      - Overall rate: {successful_calls['total']/elapsed:.2f} calls/sec")
+                    print(f"      - Rate limits hit: Sheets={rate_limits_hit['sheets']}, Drive={rate_limits_hit['drive']}")
                     
-                folder_id = folder['id']
-                folder_name = folder['name']
+                    return {
+                        "time_limit_reached": True,
+                        "successful_calls": successful_calls,
+                        "total_calls": total_calls,
+                        "elapsed_seconds": elapsed,
+                        "avg_calls_per_second": successful_calls["total"] / elapsed if elapsed > 0 else 0,
+                        "rate_limits_hit": rate_limits_hit
+                    }
                 
-                # Check if shortcut already exists
-                if folder_id in existing_shortcuts:
-                    results['skipped'] += 1
-                    continue
+                total_calls += 1
                 
-                # Create shortcut
-                try:
-                    shortcut_metadata = {
-                        'name': folder_name,
-                        'mimeType': 'application/vnd.google-apps.shortcut',
-                        'parents': [syftbox_id],
-                        'shortcutDetails': {
-                            'targetId': folder_id
-                        }
-                    }
+                # Skip API if it already hit rate limit
+                skip_this_call = False
+                
+                # Determine which API to use
+                use_sheets = total_calls % 2 == 1
+                
+                if use_sheets and rate_limits_hit["sheets"]:
+                    skip_this_call = True
+                    use_sheets = False  # Try Drive instead
+                elif not use_sheets and rate_limits_hit["drive"]:
+                    skip_this_call = True
+                    use_sheets = True  # Try Sheets instead
+                
+                # If both hit limits, we're done
+                if rate_limits_hit["sheets"] and rate_limits_hit["drive"]:
+                    elapsed = time.time() - start_time
+                    print(f"\n\n   üõë Both APIs hit rate limits!")
+                    print(f"\n   üìä Final Statistics:")
+                    print(f"      - Total successful calls: {successful_calls['total']}")
+                    print(f"      - Sheets API calls: {successful_calls['sheets']}")
+                    print(f"      - Drive API calls: {successful_calls['drive']}")
+                    print(f"      - Time elapsed: {elapsed:.2f} seconds")
+                    print(f"      - Overall rate: {successful_calls['total']/elapsed:.2f} calls/sec")
                     
-                    self.service.files().create(
-                        body=shortcut_metadata,
-                        fields='id'
+                    return {
+                        "both_rate_limits_hit": True,
+                        "successful_calls": successful_calls,
+                        "total_calls": total_calls,
+                        "elapsed_seconds": elapsed,
+                        "avg_calls_per_second": successful_calls["total"] / elapsed if elapsed > 0 else 0
+                    }
+                
+                if use_sheets and not rate_limits_hit["sheets"]:
+                    # Use Sheets API
+                    result = sheets_service.spreadsheets().values().get(
+                        spreadsheetId=sheet_id,
+                        range='messages!A1:A100',  # Small range
+                        majorDimension='ROWS'
                     ).execute()
                     
-                    results['created'] += 1
+                    rows = result.get('values', [])
+                    current_row_count = len(rows)
                     
-                except Exception as e:
-                    results['failed'] += 1
+                    # Check if row count changed
+                    if current_row_count != last_row_count:
+                        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
+                        print(f"\n   üìä [SHEETS API] Change detected at {timestamp}!")
+                        print(f"      - Row count: {last_row_count} ‚Üí {current_row_count}")
+                        print("   Progress: ", end="", flush=True)
+                    
+                    last_row_count = current_row_count
+                    successful_calls["sheets"] += 1
+                    successful_calls["total"] += 1
+                    print("S", end="", flush=True)
+                    
+                elif not use_sheets and not rate_limits_hit["drive"]:
+                    # Use Drive API to export sheet content
+                    try:
+                        # Export as CSV to get actual content
+                        export_response = self.service.files().export(
+                            fileId=sheet_id,
+                            mimeType='text/csv'
+                        ).execute()
+                        
+                        # Convert bytes to string
+                        current_drive_content = export_response.decode('utf-8') if isinstance(export_response, bytes) else export_response
+                        
+                        # Check if content changed
+                        if last_drive_content is not None and current_drive_content != last_drive_content:
+                            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
+                            print(f"\n   üìÑ [DRIVE API] Change detected at {timestamp}!")
+                            
+                            # Show what changed (first few lines)
+                            old_lines = last_drive_content.split('\n')[:5]
+                            new_lines = current_drive_content.split('\n')[:5]
+                            if old_lines != new_lines:
+                                print(f"      - Content changed (showing first 5 lines)")
+                            print("   Progress: ", end="", flush=True)
+                        
+                        last_drive_content = current_drive_content
+                        successful_calls["drive"] += 1
+                        successful_calls["total"] += 1
+                        print("D", end="", flush=True)
+                        
+                    except HttpError as e:
+                        if e.resp.status == 403 and "Export only supports Docs Editors" in str(e):
+                            # Fallback to just getting metadata if export not supported
+                            file_metadata = self.service.files().get(
+                                fileId=sheet_id,
+                                fields='modifiedTime,name,size'
+                            ).execute()
+                            
+                            current_modified_time = file_metadata.get('modifiedTime')
+                            if last_modified_time and current_modified_time != last_modified_time:
+                                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
+                                print(f"\n   üìù [DRIVE API] ModifiedTime changed at {timestamp}: {current_modified_time}")
+                                print("   Progress: ", end="", flush=True)
+                            last_modified_time = current_modified_time
+                            
+                            successful_calls["drive"] += 1
+                            successful_calls["total"] += 1
+                            print("d", end="", flush=True)  # lowercase d for metadata only
+                        else:
+                            raise
+                
+                # Print detailed progress every 20 calls
+                if successful_calls["total"] % 20 == 0:
+                    elapsed = time.time() - start_time
+                    total_rate = successful_calls["total"] / elapsed
+                    sheets_rate = successful_calls["sheets"] / elapsed
+                    drive_rate = successful_calls["drive"] / elapsed
+                    
+                    print(f"\n   ‚úì {successful_calls['total']} total calls ({total_rate:.1f}/sec)")
+                    print(f"      - Sheets API: {successful_calls['sheets']} calls ({sheets_rate:.1f}/sec)")
+                    print(f"      - Drive API: {successful_calls['drive']} calls ({drive_rate:.1f}/sec)")
+                    print(f"      - Last row count: {last_row_count}")
+                    print("   Progress: ", end="", flush=True)
+                
+            except HttpError as e:
+                # Check if it's a rate limit error
+                if e.resp.status == 429:
+                    # Determine which API hit the limit
+                    api_that_failed = "Sheets API" if use_sheets else "Drive API"
+                    
+                    # Mark this API as rate limited
+                    if use_sheets:
+                        rate_limits_hit["sheets"] = True
+                        print("X(S)", end="", flush=True)
+                    else:
+                        rate_limits_hit["drive"] = True
+                        print("X(D)", end="", flush=True)
+                    
+                    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
+                    print(f"\n   üö´ [{api_that_failed}] Rate limit hit at {timestamp}")
+                    
+                    # Extract quota details
+                    try:
+                        import ast
+                        error_details = ast.literal_eval(e.error_details)
+                        for detail in error_details:
+                            if detail.get('@type') == 'type.googleapis.com/google.rpc.ErrorInfo':
+                                metadata = detail.get('metadata', {})
+                                print(f"      - Quota limit: {metadata.get('quota_limit_value', 'unknown')} requests")
+                                print(f"      - Service: {metadata.get('service', 'unknown')}")
+                    except:
+                        pass
+                    
+                    print("   Progress: ", end="", flush=True)
+                    
+                    # Continue with the other API if available
+                    continue
+                else:
+                    # Other error
+                    errors.append(str(e))
+                    if len(errors) > 5:
+                        elapsed = time.time() - start_time
+                        print(f"\n\n   ‚ùå Too many errors")
+                        return {
+                            "error": "Too many non-rate-limit errors",
+                            "errors": errors,
+                            "successful_calls": successful_calls,
+                            "total_calls": total_calls,
+                            "elapsed_seconds": elapsed
+                        }
             
-            return results
+            except Exception as e:
+                # Unexpected error
+                elapsed = time.time() - start_time
+                print(f"\n\n   ‚ùå Unexpected error: {e}")
+                return {
+                    "error": f"Unexpected error: {str(e)}",
+                    "successful_calls": successful_calls,
+                    "total_calls": total_calls,
+                    "elapsed_seconds": elapsed
+                }
             
-        except Exception as e:
-            return results
     
-    def _create_shortcuts_for_shared_folders(self, verbose: bool = True) -> Dict[str, int]:
+    def test_latency(self, other_client: 'GDriveUnifiedClient', num_tests: int = 5) -> Dict[str, float]:
         """
-        Create shortcuts in SyftBoxTransportService for all syft_ folders in 'Shared with me'
+        Test file propagation latency between two authenticated clients
         
         Args:
-            verbose: Whether to print detailed progress messages (default: True)
-        
+            other_client: Another authenticated GDriveUnifiedClient instance
+            num_tests: Number of test iterations (default: 5)
+            
         Returns:
-            Dictionary with counts of shortcuts created, skipped, and failed
+            Dictionary with latency statistics
         """
-        self._ensure_authenticated()
+        import random
+        import shutil
+        import tempfile
         
-        results = {
-            'created': 0,
-            'skipped': 0,
-            'failed': 0
-        }
+        if not self.authenticated or not other_client.authenticated:
+            raise ValueError("Both clients must be authenticated")
         
-        try:
-            # First ensure SyftBox exists
-            syftbox_id = self.setup_syftbox()
-            if not syftbox_id:
-                print("‚ùå Could not create/find SyftBoxTransportService folder")
-                return results
-            
-            # Get list of all syft_ folders (default is silent)
-            all_folders = self._list_syft_folders()
-            shared_folders = all_folders['shared_with_me']
-            
-            if not shared_folders:
-                if verbose:
-                    print("‚úÖ No shared syft_ folders found that need shortcuts")
-                return results
-            
-            if verbose:
-                print(f"\nüîó Creating shortcuts for {len(shared_folders)} shared folders...")
+        print(f"üìä Testing latency: {self.my_email} ‚Üí {other_client.my_email}")
+        print(f"   Running {num_tests} tests...\n")
+        
+        latencies = []
+        
+        # Use hardcoded paths like the working script
+        source_base = Path.home() / f"SyftBox_{self.my_email}"
+        target_base = Path.home() / f"SyftBox_{other_client.my_email}"
+        
+        # Write to sender's datasites folder
+        source_datasites = source_base / "datasites"
+        source_datasites.mkdir(parents=True, exist_ok=True)
+        
+        # Target will be in receiver's datasites folder
+        target_datasites = target_base / "datasites"
+        
+        # Create a temp directory for staging files
+        temp_dir = tempfile.mkdtemp()
+        
+        for i in range(num_tests):
+            # Generate unique test filename
+            random_number = random.randint(100000, 999999)
+            test_filename = f"testdata_{random_number}.txt"
+            test_content = f"Test {random_number} at {time.time()}"
+            
+            # Create file in temp directory first
+            temp_file = Path(temp_dir) / test_filename
+            final_source_file = source_datasites / test_filename
+            target_file = target_datasites / test_filename
+            
+            print(f"   Test {i+1}/{num_tests}: ", end="", flush=True)
+            
+            # Write file to temp location
+            with open(temp_file, 'w') as f:
+                f.write(test_content)
+            
+            # Move file to datasites (atomic operation)
+            start_time = time.time()
+            shutil.move(str(temp_file), str(final_source_file))
+            
+            # Poll for file appearance
+            max_wait_time = 60  # 60 seconds timeout
+            poll_interval = 0.1  # 100ms
+            
+            while time.time() - start_time < max_wait_time:
+                if target_file.exists():
+                    # Verify content matches
+                    try:
+                        with open(target_file, 'r') as f:
+                            received_content = f.read()
+                        
+                        if received_content == test_content:
+                            end_time = time.time()
+                            latency = end_time - start_time
+                            latencies.append(latency)
+                            print(f"‚úÖ {latency:.2f}s")
+                            break
+                    except:
+                        pass  # File might be partially written
+                
+                time.sleep(poll_interval)
+            else:
+                print(f"‚ùå Timeout (>{max_wait_time}s)")
             
-            # Get existing shortcuts in SyftBoxTransportService to avoid duplicates
-            existing_shortcuts = {}
+            # Clean up test files
             try:
-                existing = self.service.files().list(
-                    q=f"'{syftbox_id}' in parents and mimeType='application/vnd.google-apps.shortcut' and trashed=false",
-                    fields="files(id, name, shortcutDetails)"
-                ).execute()
-                
-                for shortcut in existing.get('files', []):
-                    details = shortcut.get('shortcutDetails', {})
-                    target_id = details.get('targetId')
-                    if target_id:
-                        existing_shortcuts[target_id] = shortcut['name']
+                final_source_file.unlink()
+                if target_file.exists():
+                    target_file.unlink()
             except:
                 pass
             
-            # Create shortcuts for each shared folder
-            for folder in shared_folders:
-                folder_name = folder['name']
-                folder_id = folder['id']
-                folder_owner = folder['owner']
-                
-                # Check if shortcut already exists
-                if folder_id in existing_shortcuts:
-                    if verbose:
-                        print(f"‚è≠Ô∏è  Skipping {folder_name} - shortcut already exists")
-                    results['skipped'] += 1
-                    continue
-                
-                # Check if folder name already exists in SyftBox (non-shortcut)
-                try:
-                    existing_folder = self.service.files().list(
-                        q=f"name='{folder_name}' and '{syftbox_id}' in parents and trashed=false",
-                        fields="files(id, mimeType)"
-                    ).execute()
-                    
-                    if existing_folder.get('files'):
-                        if verbose:
-                            print(f"‚è≠Ô∏è  Skipping {folder_name} - folder/shortcut with same name already exists")
-                        results['skipped'] += 1
-                        continue
-                except:
-                    pass
-                
-                # Create the shortcut
-                try:
-                    shortcut_metadata = {
-                        'name': folder_name,
-                        'mimeType': 'application/vnd.google-apps.shortcut',
-                        'parents': [syftbox_id],
-                        'shortcutDetails': {
-                            'targetId': folder_id,
-                            'targetMimeType': 'application/vnd.google-apps.folder'
-                        }
-                    }
-                    
-                    shortcut = self.service.files().create(
-                        body=shortcut_metadata,
-                        fields='id, name'
-                    ).execute()
-                    
-                    if verbose:
-                        print(f"‚úÖ Created shortcut for {folder_name} (from {folder_owner})")
-                    results['created'] += 1
-                    
-                except HttpError as e:
-                    if verbose:
-                        print(f"‚ùå Failed to create shortcut for {folder_name}: {e}")
-                    results['failed'] += 1
-            
-            # Summary - only show if verbose
-            if verbose and (results['created'] > 0 or results['failed'] > 0 or results['skipped'] > 0):
-                print(f"\nüìä Shortcut creation summary:")
-                print(f"   ‚úÖ Created: {results['created']}")
-                print(f"   ‚è≠Ô∏è  Skipped: {results['skipped']}")
-                print(f"   ‚ùå Failed: {results['failed']}")
-                
-                if results['created'] > 0:
-                    print(f"\nüéâ Successfully linked {results['created']} shared folders to SyftBoxTransportService!")
-                    print(f"üîó View in Google Drive: https://drive.google.com/drive/folders/{syftbox_id}")
-            
-            return results
-            
-        except HttpError as e:
-            print(f"‚ùå Error creating shortcuts: {e}")
-            return results
+            # Small delay between tests
+            if i < num_tests - 1:
+                time.sleep(1)
+        
+        # Clean up temp directory
+        try:
+            shutil.rmtree(temp_dir)
+        except:
+            pass
+        
+        # Calculate statistics
+        if latencies:
+            avg_latency = sum(latencies) / len(latencies)
+            min_latency = min(latencies)
+            max_latency = max(latencies)
+            
+            print(f"\nüìà Results:")
+            print(f"   Average latency: {avg_latency:.2f}s")
+            print(f"   Min latency: {min_latency:.2f}s")
+            print(f"   Max latency: {max_latency:.2f}s")
+            print(f"   Successful: {len(latencies)}/{num_tests}")
+            
+            return {
+                "average": avg_latency,
+                "min": min_latency,
+                "max": max_latency,
+                "successful": len(latencies),
+                "total": num_tests,
+                "all_latencies": latencies
+            }
+        else:
+            print("\n‚ùå All tests failed")
+            return {
+                "average": None,
+                "min": None,
+                "max": None,
+                "successful": 0,
+                "total": num_tests,
+                "all_latencies": []
+            }
+
 
-# Convenience function for quick setup
 def create_gdrive_client(email_or_auth_method: str = "auto", verbose: bool = True, force_relogin: bool = False) -> GDriveUnifiedClient:
     """
     Create and authenticate a GDrive client
@@ -1943,7 +7115,7 @@ def create_gdrive_client(email_or_auth_method: str = "auto", verbose: bool = Tru
     else:
         client = GDriveUnifiedClient(auth_method=email_or_auth_method, verbose=verbose, force_relogin=force_relogin)
     
-    if client.authenticate():
+    if client.authenticate(known_email=email_or_auth_method):
         return client
     else:
         raise RuntimeError("Failed to authenticate")
\ No newline at end of file
diff --git a/syft_client/receiver.py b/syft_client/receiver.py
new file mode 100644
index 0000000..01bffc6
--- /dev/null
+++ b/syft_client/receiver.py
@@ -0,0 +1,294 @@
+"""
+Auto-sync receiver functionality for automatic message processing
+"""
+
+import syft_serve as ss
+import os
+from pathlib import Path
+
+
+def create_receiver_endpoint(email, interval_seconds=1.0):
+    """
+    Create the auto-sync receiver endpoint
+    
+    Args:
+        email: Email address of the user
+        interval_seconds: How often to check for changes with Sheets API
+    
+    Returns:
+        Server object
+    """
+    # Create unique server name based on email
+    server_name = f"receiver_{email.replace('@', '_').replace('.', '_')}"
+    
+    # Check if endpoint already exists by querying syft_serve state
+    existing_servers = list(ss.servers)
+    for server in existing_servers:
+        if server.name == server_name:
+            print("Receiver endpoint already exists")
+            return server
+    
+    def receiver_loop():
+        import syft_client as sc
+        import time
+        import os
+        import atexit
+        from datetime import datetime
+        
+        # Login to syft client with provided email (with verbose=False to silence messages)
+        print(f"Starting receiver for {email}...", flush=True)
+        
+        # Check token exists
+        # Convert email to token path format (@ -> _at_, . -> _)
+        email_for_path = email.replace('@', '_at_').replace('.', '_')
+        token_path = os.path.expanduser(f'~/.syft/gdrive/{email_for_path}/token.json')
+        if not os.path.exists(token_path):
+            return f"Error: Token file not found at {token_path}"
+            
+        try:
+            client = sc.login(email, verbose=False, force_relogin=False)
+            print(f"Login successful! Starting auto-sync receiver...", flush=True)
+            print(f"   Polling interval: {interval_seconds}s", flush=True)
+        except Exception as e:
+            return f"Login failed: {type(e).__name__}: {str(e)}"
+        
+        # Track statistics
+        stats = {
+            "start_time": datetime.now(),
+            "last_update": None,
+            "update_count": 0,
+            "approve_count": 0,
+            "merge_count": 0,
+            "error_count": 0,
+            "last_error": None,
+            "sheets_api_calls": 0,
+            "changes_detected": 0
+        }
+        
+        # Track API states for change detection
+        api_states = {}  # Will store {friend_email: {sheet_id, last_content_hash, last_row_count}}
+        
+        # Timing control
+        last_call_time = 0
+        
+        # Store stats for access
+        import sys
+        current_module = sys.modules[__name__]
+        current_module.receiver_stats = stats
+        
+        # Flag to control the loop
+        current_module.receiver_running = True
+        
+        # Register cleanup function
+        def cleanup_receiver():
+            current_module = sys.modules[__name__]
+            if hasattr(current_module, 'receiver_running'):
+                print(f"Stopping receiver for {email}...", flush=True)
+                current_module.receiver_running = False
+                print(f"Receiver stopped.", flush=True)
+        
+        atexit.register(cleanup_receiver)
+        
+        # Helper function to compute hash of content
+        def compute_content_hash(content):
+            import hashlib
+            if isinstance(content, str):
+                content = content.encode('utf-8')
+            elif isinstance(content, list):
+                content = str(content).encode('utf-8')
+            return hashlib.md5(content).hexdigest()
+        
+        # Main receiver loop
+        while current_module.receiver_running:
+            try:
+                current_time = time.time()
+                elapsed = current_time - last_call_time
+                
+                # Check if enough time has passed for next call
+                if elapsed >= interval_seconds:
+                    changes_detected = False
+                    
+                    # Get friends list
+                    if not hasattr(client, 'friends') or not client.friends:
+                        # No friends to check
+                        last_call_time = current_time
+                        time.sleep(interval_seconds)
+                        continue
+                    
+                    # Use Sheets API to check for changes
+                    try:
+                        stats["sheets_api_calls"] += 1
+                        
+                        # Get sheets service
+                        sheets_service = client._get_sheets_service()
+                        
+                        for friend_email in client.friends:
+                            try:
+                                # Find friend's sheet
+                                sheet_name = f"syft_{friend_email}_to_{client.my_email}_messages"
+                                sheet_id = client._find_message_sheet(sheet_name, from_email=friend_email)
+                                
+                                if not sheet_id:
+                                    continue
+                                
+                                # Get current content
+                                result = sheets_service.spreadsheets().values().get(
+                                    spreadsheetId=sheet_id,
+                                    range='messages!A:D'
+                                ).execute()
+                                
+                                rows = result.get('values', [])
+                                current_row_count = len(rows)
+                                current_hash = compute_content_hash(rows)
+                                
+                                # Get previous state
+                                friend_state = api_states.get(friend_email, {})
+                                last_hash = friend_state.get("last_content_hash")
+                                last_row_count = friend_state.get("last_row_count", 0)
+                                
+                                # Check for changes
+                                if last_hash is None or current_hash != last_hash:
+                                    changes_detected = True
+                                    stats["changes_detected"] += 1
+                                    print(f"üìä Change detected from {friend_email}: {last_row_count} ‚Üí {current_row_count} rows", flush=True)
+                                
+                                # Update state
+                                api_states[friend_email] = {
+                                    "sheet_id": sheet_id,
+                                    "last_content_hash": current_hash,
+                                    "last_row_count": current_row_count
+                                }
+                                
+                            except Exception as e:
+                                # Log but don't fail the whole check
+                                print(f"Error checking {friend_email}: {e}", flush=True)
+                        
+                        # Update timing
+                        last_call_time = current_time
+                        
+                        # If changes detected, process them
+                        if changes_detected:
+                            # Update inbox from sheets
+                            result = client.update_inbox_from_sheets()
+                            if result:
+                                stats["update_count"] += 1
+                        
+                    except Exception as e:
+                        stats["error_count"] += 1
+                        stats["last_error"] = f"api_check: {str(e)}"
+                        print(f"Error during API check: {e}", flush=True)
+                        # Update timing even on error to avoid tight loop
+                        last_call_time = current_time
+                    
+                else:
+                    # Not enough time elapsed, small sleep
+                    time.sleep(0.01)  # 10ms
+                
+                # Auto-approve inbox items
+                try:
+                    # Check if the method exists
+                    if hasattr(client, 'autoapprove_inbox'):
+                        approved = client.autoapprove_inbox()
+                        if approved:
+                            stats["approve_count"] += len(approved) if isinstance(approved, list) else 1
+                except Exception as e:
+                    stats["error_count"] += 1
+                    stats["last_error"] = f"autoapprove: {str(e)}"
+                
+                # Merge new syncs
+                try:
+                    # Check if the method exists
+                    if hasattr(client, 'merge_new_syncs'):
+                        merged = client.merge_new_syncs()
+                        if merged:
+                            stats["merge_count"] += len(merged) if isinstance(merged, list) else 1
+                except Exception as e:
+                    stats["error_count"] += 1
+                    stats["last_error"] = f"merge_syncs: {str(e)}"
+                
+                # Update last run time
+                stats["last_update"] = datetime.now()
+                
+                # Sleep for the specified interval
+                time.sleep(interval_seconds)
+                
+            except KeyboardInterrupt:
+                print("Receiver interrupted by user", flush=True)
+                break
+            except Exception as e:
+                stats["error_count"] += 1
+                stats["last_error"] = f"main_loop: {str(e)}"
+                # Sleep even on error to avoid tight loop
+                time.sleep(interval_seconds)
+        
+        # Return final stats
+        return {
+            "status": "stopped",
+            "message": f"Receiver stopped after {stats['update_count']} updates",
+            "stats": stats
+        }
+    
+    # Get the package parent directory path
+    import syft_client
+    syft_client_module_path = os.path.dirname(os.path.abspath(syft_client.__file__))
+    syft_client_parent_path = os.path.dirname(syft_client_module_path)
+    
+    # Create the server with dependencies
+    server = ss.create(server_name, 
+                       dependencies=[
+                           syft_client_parent_path,  # Use the parent directory containing syft_client
+                           "google-api-python-client", 
+                           "google-auth", 
+                           "google-auth-oauthlib", 
+                           "google-auth-httplib2"
+                       ],
+                       endpoints={"/": receiver_loop})
+    
+    print(f"Receiver server created at: {server.url}")
+    
+    # Trigger the receiver to start by accessing the endpoint
+    import requests
+    try:
+        requests.get(server.url, timeout=1)
+    except:
+        # It's OK if this times out, the receiver loop has started
+        pass
+    
+    return server
+
+
+def destroy_receiver_endpoint(email):
+    """Destroy the receiver endpoint for a specific email"""
+    # Create server name to look for
+    server_name = f"receiver_{email.replace('@', '_').replace('.', '_')}"
+    
+    # Find and terminate the specific server
+    existing_servers = list(ss.servers)
+    for server in existing_servers:
+        if server.name == server_name:
+            server.terminate()
+            print(f"Receiver {server_name} terminated successfully")
+            return True
+    
+    print(f"No receiver found for {email}")
+    return False
+
+
+def get_receiver_stats(email):
+    """Get statistics from a running receiver"""
+    server_name = f"receiver_{email.replace('@', '_').replace('.', '_')}"
+    
+    # Find the server
+    existing_servers = list(ss.servers)
+    for server in existing_servers:
+        if server.name == server_name:
+            # Try to access the stats endpoint
+            import requests
+            try:
+                response = requests.get(f"{server.url}/stats")
+                if response.status_code == 200:
+                    return response.json()
+            except:
+                pass
+    
+    return None
\ No newline at end of file
diff --git a/syft_client/syft_file_backed_view.py b/syft_client/syft_file_backed_view.py
index 43513df..6ada712 100644
--- a/syft_client/syft_file_backed_view.py
+++ b/syft_client/syft_file_backed_view.py
@@ -2,7 +2,6 @@
 Base class for file-backed views in SyftBox with safety features
 """
 import json
-import yaml
 import hashlib
 import fcntl
 import contextlib
@@ -29,7 +28,7 @@ class SyftFileBackedView:
         self.schema_version = schema_version
         
         # Define standard paths
-        self.metadata_path = self.path / "metadata.yaml"
+        self.metadata_path = self.path / "metadata.json"
         self.lock_path = self.path / "lock.json"
         self.data_dir = self.path / "data"
         self.data_dir.mkdir(exist_ok=True)
@@ -78,7 +77,7 @@ class SyftFileBackedView:
         # Write to temporary file first
         with tempfile.NamedTemporaryFile(mode='w', dir=self.path, 
                                        delete=False, suffix='.tmp') as tmp:
-            yaml.dump(metadata, tmp, default_flow_style=False)
+            json.dump(metadata, tmp, indent=2)
             tmp_path = tmp.name
         
         # Atomic rename (POSIX compliant)
@@ -94,7 +93,7 @@ class SyftFileBackedView:
         if not self.metadata_path.exists():
             return {"_schema_version": self.schema_version}
         with open(self.metadata_path, 'r') as f:
-            return yaml.safe_load(f) or {}
+            return json.load(f)
     
     def update_metadata(self, updates: Dict[str, Any]):
         """Update specific metadata fields atomically"""
@@ -109,7 +108,7 @@ class SyftFileBackedView:
             # Write atomically
             with tempfile.NamedTemporaryFile(mode='w', dir=self.path, 
                                            delete=False, suffix='.tmp') as tmp:
-                yaml.dump(metadata, tmp, default_flow_style=False)
+                json.dump(metadata, tmp, indent=2)
                 tmp_path = tmp.name
             
             os.replace(tmp_path, self.metadata_path)
diff --git a/syft_client/watcher.py b/syft_client/watcher.py
new file mode 100644
index 0000000..aabda02
--- /dev/null
+++ b/syft_client/watcher.py
@@ -0,0 +1,200 @@
+"""
+File watcher functionality for automatic synchronization
+"""
+
+import syft_serve as ss
+import os
+from pathlib import Path
+import requests
+
+
+def create_watcher_sender_endpoint(email):
+    """Create the file watcher sender endpoint with syft client integration"""
+    # Create unique server name based on email
+    server_name = f"watcher_sender_{email.replace('@', '_').replace('.', '_')}"
+    
+    # Check if endpoint already exists by querying syft_serve state
+    existing_servers = list(ss.servers)
+    for server in existing_servers:
+        if server.name == server_name:
+            print("Endpoint already exists")
+            return server
+    
+    def hello():
+        import syft_client as sc
+        from watchdog.observers import Observer
+        from watchdog.events import FileSystemEventHandler
+        import time
+        import os
+        import atexit
+        from pathlib import Path
+        
+        # Login to syft client with provided email (with verbose=False to silence messages)
+        print(f"Attempting login for {email}...", flush=True)
+        
+        # Check token exists
+        # Convert email to token path format (@ -> _at_, . -> _)
+        email_for_path = email.replace('@', '_at_').replace('.', '_')
+        token_path = os.path.expanduser(f'~/.syft/gdrive/{email_for_path}/token.json')
+        if not os.path.exists(token_path):
+            return f"Error: Token file not found at {token_path}"
+            
+        try:
+            client = sc.login(email, verbose=False, force_relogin=False)
+            print(f"Login successful!", flush=True)
+        except Exception as e:
+            return f"Login failed: {type(e).__name__}: {str(e)}"
+        
+        # Get the SyftBox datasites directory to watch
+        syftbox_dir = client.get_syftbox_directory()
+        if syftbox_dir is None:
+            return "Error: Could not determine SyftBox directory"
+        
+        watch_path = str(syftbox_dir / "datasites")
+        
+        # Define what happens when files change
+        class Handler(FileSystemEventHandler):
+            def on_created(self, event):
+                if not event.is_directory:
+                    self._handle_file_event(event, "created")
+            
+            def on_modified(self, event):
+                if not event.is_directory:
+                    self._handle_file_event(event, "modified")
+            
+            def on_deleted(self, event):
+                if not event.is_directory:
+                    self._handle_file_event(event, "deleted")
+            
+            def _handle_file_event(self, event, event_type):
+                # Skip hidden files (starting with .)
+                filename = os.path.basename(event.src_path)
+                if filename.startswith('.'):
+                    return
+                
+                # Skip any path containing hidden directories
+                path_parts = event.src_path.split(os.sep)
+                for part in path_parts:
+                    if part.startswith('.'):
+                        return
+                
+                # Skip temporary files and system files
+                if filename.endswith(('.tmp', '.swp', '.DS_Store', '~')):
+                    return
+                
+                # For deletions, we can't check file content (it's gone)
+                if event_type != "deleted":
+                    # Check if this file change is from a recent sync
+                    # This prevents infinite sync loops where syncs echo back and forth
+                    if hasattr(client, '_is_file_from_recent_sync'):
+                        # Get sync echo prevention threshold from env or default to 60 seconds
+                        threshold = int(os.environ.get('SYFT_SYNC_ECHO_THRESHOLD', '60'))
+                        
+                        # Skip echo prevention if threshold is 0 or negative
+                        if threshold > 0 and client._is_file_from_recent_sync(event.src_path, threshold_seconds=threshold):
+                            print(f"Skipping echo: {filename} (matches recent sync)", flush=True)
+                            return
+                
+                # Send the file or deletion to all friends
+                try:
+                    if event_type == "deleted":
+                        print(f"Sending deletion: {filename}", flush=True)
+                        # Send deletion message
+                        if hasattr(client, 'send_deletion_to_friends'):
+                            results = client.send_deletion_to_friends(event.src_path)
+                        else:
+                            # Fallback: send to each friend individually
+                            results = {}
+                            for friend in client.friends:
+                                if hasattr(client, 'send_deletion'):
+                                    success = client.send_deletion(event.src_path, friend)
+                                    results[friend] = success
+                                else:
+                                    print(f"Warning: Deletion not supported in this client version", flush=True)
+                                    return
+                    else:
+                        print(f"Sending {event_type}: {filename}", flush=True)
+                        # Send file using the batch method if available, otherwise fallback
+                        if hasattr(client, 'send_file_or_folder_to_friends'):
+                            results = client.send_file_or_folder_to_friends(event.src_path)
+                        else:
+                            # Fallback: send to each friend individually
+                            results = {}
+                            for friend in client.friends:
+                                success = client.send_file_or_folder_auto(event.src_path, friend)
+                                results[friend] = success
+                    
+                    # Report results
+                    successful = sum(1 for success in results.values() if success)
+                    total = len(results)
+                    if successful > 0:
+                        print(f"‚úì Sent to {successful}/{total} friends", flush=True)
+                    
+                except Exception as e:
+                    print(f"Error sending {filename}: {e}", flush=True)
+        
+        # Create observer and start watching
+        observer = Observer()
+        observer.schedule(Handler(), watch_path, recursive=True)
+        observer.start()
+        
+        # Store observer reference for cleanup
+        # We'll store it as a module-level variable to ensure it persists
+        import sys
+        current_module = sys.modules[__name__]
+        current_module.observer = observer
+        
+        # Register cleanup function
+        def cleanup_observer():
+            current_module = sys.modules[__name__]
+            if hasattr(current_module, 'observer') and current_module.observer:
+                print(f"Stopping file watcher for {email}...", flush=True)
+                current_module.observer.stop()
+                current_module.observer.join()
+                print(f"File watcher stopped.", flush=True)
+        
+        atexit.register(cleanup_observer)
+        
+        return {
+            "status": "started",
+            "message": f"Watcher is now monitoring: {watch_path}",
+            "email": email
+        }
+    
+    # Get the package parent directory path
+    import syft_client
+    syft_client_module_path = os.path.dirname(os.path.abspath(syft_client.__file__))
+    syft_client_parent_path = os.path.dirname(syft_client_module_path)
+    
+    # Create the server with dependencies
+    server = ss.create(server_name, 
+                       dependencies=[
+                           syft_client_parent_path,  # Use the parent directory containing syft_client
+                           "watchdog", 
+                           "google-api-python-client", 
+                           "google-auth", 
+                           "google-auth-oauthlib", 
+                           "google-auth-httplib2"
+                       ],
+                       endpoints={"/": hello})
+    
+    # print(f"Server created at: {server.url}")
+    requests.get(server.url)
+    return server
+
+
+def destroy_watcher_sender_endpoint(email):
+    """Destroy the watcher sender endpoint for a specific email"""
+    # Create server name to look for
+    server_name = f"watcher_sender_{email.replace('@', '_').replace('.', '_')}"
+    
+    # Find and terminate the specific server
+    existing_servers = list(ss.servers)
+    for server in existing_servers:
+        if server.name == server_name:
+            server.terminate()
+            print(f"Server {server_name} terminated successfully")
+            return True
+    
+    print(f"No server found for {email}")
+    return False
\ No newline at end of file
diff --git a/syft_client/wizard.py b/syft_client/wizard.py
index 3cd080e..93ccd5a 100644
--- a/syft_client/wizard.py
+++ b/syft_client/wizard.py
@@ -1,7 +1,10 @@
-def wizard():
+def wizard(email=None):
     """
     Creates a wizard widget that displays images with navigation.
     
+    Args:
+        email: Optional email address to use for account-specific URLs
+    
     Returns a simple HTML widget with JavaScript navigation.
     """
     from IPython.display import HTML, display
@@ -33,6 +36,12 @@ def wizard():
         display(html_widget)
         return None  # Don't return HTML widget that could confuse users
     
+    # Generate authuser parameter and email notice if email is provided
+    authuser_param = f"?authuser={email}" if email else ""
+    email_notice = ""
+    if email:
+        email_notice = f'<div style="background: #e3f2fd; padding: 10px 15px; border-radius: 5px; margin-bottom: 20px; font-size: 14px; color: #1565c0;">Creating credentials for: <strong>{email}</strong><br><br><em>Important:</em> When clicking links below, make sure you are using the correct Google account. If multiple accounts are logged in, you may need to switch to {email} in the Google Console.</div>'
+    
     # Generate the HTML with embedded JavaScript
     html_content = '''
     <div id="wizard-widget" style="display: flex; height: 600px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: white; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); overflow: hidden;">
@@ -42,6 +51,7 @@ def wizard():
             <div>
                 <h2 style="margin: 0 0 10px 0; color: #1a202c; font-size: 28px; font-weight: 600;">Create Google Drive Credentials</h2>
                 <div style="width: 60px; height: 4px; background: #4285f4; margin-bottom: 30px;"></div>
+                {email_notice}
                 
                 <div style="margin-bottom: 30px;">
                     <div style="display: inline-block; padding: 6px 12px; background: #e2e8f0; border-radius: 20px; font-size: 14px; color: #4a5568; margin-bottom: 20px;">
@@ -88,6 +98,8 @@ def wizard():
             
         ];
         
+        var authuser = '{authuser_param}';
+        
         var captions = [
             "You don't have valid credentials! It's time to make some. Go to <a href='https://console.cloud.google.com/projectcreate' target='_blank' rel='noopener noreferrer' style='color: #3182ce;'>Google Cloud Console¬†‚Äî¬†Create Project Page</a> and fill out the form.",
             "When the dropdown appears showing the creation of your new project, wait until the project is formed and click 'SELECT PROJECT'.",
@@ -122,7 +134,15 @@ def wizard():
         function updateWizard() {
             document.getElementById('wizardImage').src = urls[idx];
             document.getElementById('currentNum').textContent = idx + 1;
-            document.getElementById('caption').innerHTML = captions[idx];
+            
+            // Update URLs with authuser parameter if provided
+            var caption = captions[idx];
+            if (authuser) {
+                caption = caption.replace('https://console.cloud.google.com/projectcreate', 'https://console.cloud.google.com/projectcreate' + authuser);
+                caption = caption.replace('https://console.cloud.google.com/apis/library/drive.googleapis.com', 'https://console.cloud.google.com/apis/library/drive.googleapis.com' + authuser);
+                caption = caption.replace('https://console.cloud.google.com/auth/overview', 'https://console.cloud.google.com/auth/overview' + authuser);
+            }
+            document.getElementById('caption').innerHTML = caption;
             document.getElementById('prevButton').disabled = idx === 0;
             document.getElementById('nextButton').disabled = idx === urls.length - 1;
             var prevBtn = document.getElementById('prevButton');
@@ -149,7 +169,7 @@ def wizard():
         updateWizard();
     })();
     </script>
-    '''
+    '''.replace('{email_notice}', email_notice).replace('{authuser_param}', authuser_param)
     
     # Create the HTML object
     html_widget = HTML(html_content)
diff --git a/syftbox_file_observer.py b/syftbox_file_observer.py
deleted file mode 100644
index 8f68f0c..0000000
--- a/syftbox_file_observer.py
+++ /dev/null
@@ -1,240 +0,0 @@
-#!/usr/bin/env python3
-"""
-SyftBox File Observer API
-Monitors datasites folder and creates SyftMessages for file changes
-"""
-import syft_serve as ss
-import syft_client as sc
-from pathlib import Path
-import requests
-import sys
-import time
-import json
-
-# Terminate existing servers
-ss.servers.terminate_all()
-
-# Configuration
-EMAIL = "andrew@openmined.org"
-SYFTBOX_DIR = Path.home() / f"SyftBox_{EMAIL}"
-DATASITES_DIR = SYFTBOX_DIR / "datasites"
-OUTBOX_DIR = SYFTBOX_DIR / "outbox"
-
-# Ensure directories exist
-DATASITES_DIR.mkdir(parents=True, exist_ok=True)
-OUTBOX_DIR.mkdir(parents=True, exist_ok=True)
-
-# Global state
-state = {
-    "observer": None,
-    "processed_files": set(),
-    "messages_created": 0,
-    "last_event": None
-}
-
-def start_observer():
-    """Start the file observer"""
-    from watchdog.observers import Observer
-    from watchdog.events import FileSystemEventHandler
-    
-    # Force unbuffered output
-    sys.stdout.reconfigure(line_buffering=True)
-    
-    class DataSitesHandler(FileSystemEventHandler):
-        def on_created(self, event):
-            if not event.is_directory:
-                process_file_event(event, "created")
-        
-        def on_modified(self, event):
-            if not event.is_directory:
-                process_file_event(event, "modified")
-        
-        def on_deleted(self, event):
-            if not event.is_directory:
-                process_file_event(event, "deleted")
-    
-    # Create and start observer
-    if state["observer"] is None:
-        observer = Observer()
-        observer.schedule(DataSitesHandler(), str(DATASITES_DIR), recursive=True)
-        observer.start()
-        state["observer"] = observer
-        
-        print(f"üìÅ Monitoring: {DATASITES_DIR}", flush=True)
-        return {"status": "Observer started", "monitoring": str(DATASITES_DIR)}
-    else:
-        return {"status": "Observer already running", "monitoring": str(DATASITES_DIR)}
-
-def process_file_event(event, event_type):
-    """Process a file event and create a SyftMessage"""
-    file_path = Path(event.src_path)
-    
-    # Skip hidden files and temporary files
-    if file_path.name.startswith('.') or file_path.suffix == '.tmp':
-        return
-    
-    # Skip if we just processed this file (debounce rapid events)
-    file_key = f"{file_path}:{event_type}:{time.time()//1}"  # 1 second debounce
-    if file_key in state["processed_files"]:
-        return
-    state["processed_files"].add(file_key)
-    
-    # Keep only recent processed files
-    if len(state["processed_files"]) > 100:
-        state["processed_files"] = set(list(state["processed_files"])[-50:])
-    
-    print(f"üîî {event_type}: {file_path.name}", flush=True)
-    
-    # Create SyftMessage for the file change
-    try:
-        # Determine recipient (for demo, using a default)
-        recipient_email = "recipient@example.com"  # In real use, this would be determined by the datasite
-        
-        # Create the message
-        message = sc.SyftMessage.create(
-            sender_email=EMAIL,
-            recipient_email=recipient_email,
-            message_root=OUTBOX_DIR
-        )
-        
-        # Add metadata about the event
-        message.update_metadata({
-            "event_type": event_type,
-            "datasite_path": str(file_path.relative_to(DATASITES_DIR)),
-            "timestamp": time.time()
-        })
-        
-        # If file exists (not deleted), add it to the message
-        if event_type != "deleted" and file_path.exists():
-            syftbox_path = f"/{EMAIL}/datasites/{file_path.relative_to(DATASITES_DIR)}"
-            message.add_file(
-                source_path=file_path,
-                path=syftbox_path,
-                permissions={
-                    "read": [recipient_email],
-                    "write": [EMAIL],
-                    "admin": [EMAIL]
-                }
-            )
-        
-        # Add a README explaining the update
-        readme_content = f"""
-        <html>
-        <body>
-            <h2>File Update Notification</h2>
-            <p><strong>Event:</strong> {event_type}</p>
-            <p><strong>File:</strong> {file_path.name}</p>
-            <p><strong>Path:</strong> datasites/{file_path.relative_to(DATASITES_DIR)}</p>
-            <p><strong>Time:</strong> {time.strftime('%Y-%m-%d %H:%M:%S')}</p>
-            <p><strong>From:</strong> {EMAIL}</p>
-        </body>
-        </html>
-        """
-        message.add_readme(readme_content)
-        
-        # Finalize the message
-        message.finalize()
-        
-        state["messages_created"] += 1
-        state["last_event"] = {
-            "type": event_type,
-            "file": file_path.name,
-            "message_id": message.message_id,
-            "time": time.time()
-        }
-        
-        print(f"‚úÖ Created SyftMessage: {message.message_id}", flush=True)
-        
-    except Exception as e:
-        print(f"‚ùå Error creating SyftMessage: {e}", flush=True)
-
-def get_status():
-    """Get observer status"""
-    return {
-        "running": state["observer"] is not None and state["observer"].is_alive(),
-        "messages_created": state["messages_created"],
-        "last_event": state["last_event"],
-        "monitoring": str(DATASITES_DIR),
-        "outbox": str(OUTBOX_DIR)
-    }
-
-def list_messages():
-    """List messages in outbox"""
-    messages = []
-    if OUTBOX_DIR.exists():
-        for msg_dir in OUTBOX_DIR.iterdir():
-            if msg_dir.is_dir() and msg_dir.name.startswith("gdrive_"):
-                try:
-                    msg = sc.SyftMessage(msg_dir)
-                    metadata = msg.get_metadata()
-                    messages.append({
-                        "id": msg.message_id,
-                        "recipient": metadata.get("recipient_email"),
-                        "event_type": metadata.get("event_type"),
-                        "timestamp": metadata.get("timestamp"),
-                        "ready": msg.is_ready
-                    })
-                except:
-                    pass
-    
-    return {"messages": messages, "count": len(messages)}
-
-def clear_outbox():
-    """Clear all messages from outbox (for testing)"""
-    import shutil
-    count = 0
-    if OUTBOX_DIR.exists():
-        for msg_dir in OUTBOX_DIR.iterdir():
-            if msg_dir.is_dir() and msg_dir.name.startswith("gdrive_"):
-                shutil.rmtree(msg_dir)
-                count += 1
-    
-    return {"cleared": count}
-
-# Create the server
-server = ss.create(
-    name="syftbox_observer",
-    dependencies=["watchdog"],
-    endpoints={
-        "/start": start_observer,
-        "/status": get_status,
-        "/messages": list_messages,
-        "/clear": clear_outbox
-    }
-)
-
-print(f"\nüöÄ SyftBox File Observer API")
-print(f"üìß Email: {EMAIL}")
-print(f"üìÅ Monitoring: {DATASITES_DIR}")
-print(f"üì§ Outbox: {OUTBOX_DIR}")
-print(f"\nüåê Server: {server.url}")
-print(f"\nEndpoints:")
-print(f"  POST {server.url}/start    - Start monitoring")
-print(f"  GET  {server.url}/status   - Check status")
-print(f"  GET  {server.url}/messages - List messages created")
-print(f"  POST {server.url}/clear    - Clear outbox (testing)")
-
-# Auto-start the observer
-print(f"\nüîß Auto-starting observer...")
-response = requests.post(f"{server.url}/start")
-print(f"‚úÖ {response.json()['status']}")
-
-print(f"\nüìù Try creating or editing files in:")
-print(f"   {DATASITES_DIR}")
-print(f"\nüí° Messages will be created in:")
-print(f"   {OUTBOX_DIR}")
-
-# Show logs
-print(f"\nüìã To view logs:")
-print(f"   observer = ss.servers['syftbox_observer']")
-print(f"   observer.stdout.lines()[-10:]")
-
-# Keep running
-try:
-    while True:
-        time.sleep(1)
-except KeyboardInterrupt:
-    if state["observer"]:
-        state["observer"].stop()
-        state["observer"].join()
-    print("\nüëã Observer stopped")
\ No newline at end of file
diff --git a/test_file_observer.py b/test_file_observer.py
deleted file mode 100644
index 9bbce01..0000000
--- a/test_file_observer.py
+++ /dev/null
@@ -1,90 +0,0 @@
-#!/usr/bin/env python3
-"""
-Test script for SyftBox File Observer
-"""
-import requests
-import time
-from pathlib import Path
-import json
-
-# Configuration - match the observer script
-EMAIL = "andrew@openmined.org"
-SYFTBOX_DIR = Path.home() / f"SyftBox_{EMAIL}"
-DATASITES_DIR = SYFTBOX_DIR / "datasites"
-OUTBOX_DIR = SYFTBOX_DIR / "outbox"
-
-# Server URL
-BASE_URL = "http://localhost:8000"
-
-def test_observer():
-    print("üß™ Testing SyftBox File Observer\n")
-    
-    # Check status
-    print("1Ô∏è‚É£ Checking observer status...")
-    response = requests.get(f"{BASE_URL}/status")
-    status = response.json()
-    print(f"   Running: {status['running']}")
-    print(f"   Messages created: {status['messages_created']}")
-    
-    # Create a test file
-    print("\n2Ô∏è‚É£ Creating a test data file...")
-    test_file = DATASITES_DIR / "test_data.csv"
-    test_file.write_text("id,name,value\n1,Alice,100\n2,Bob,200")
-    print(f"   Created: {test_file}")
-    
-    # Wait for processing
-    time.sleep(2)
-    
-    # Check messages
-    print("\n3Ô∏è‚É£ Checking messages created...")
-    response = requests.get(f"{BASE_URL}/messages")
-    messages = response.json()
-    print(f"   Total messages: {messages['count']}")
-    
-    if messages['messages']:
-        latest = messages['messages'][-1]
-        print(f"   Latest message:")
-        print(f"     ID: {latest['id']}")
-        print(f"     Event: {latest['event_type']}")
-        print(f"     Ready: {latest['ready']}")
-    
-    # Modify the file
-    print("\n4Ô∏è‚É£ Modifying the test file...")
-    test_file.write_text("id,name,value\n1,Alice,150\n2,Bob,250\n3,Charlie,300")
-    
-    time.sleep(2)
-    
-    # Check updated status
-    response = requests.get(f"{BASE_URL}/status")
-    status = response.json()
-    print(f"   Messages created: {status['messages_created']}")
-    
-    if status['last_event']:
-        print(f"   Last event: {status['last_event']['type']} - {status['last_event']['file']}")
-    
-    # List all messages in outbox
-    print("\n5Ô∏è‚É£ Messages in outbox:")
-    if OUTBOX_DIR.exists():
-        count = 0
-        for msg_dir in sorted(OUTBOX_DIR.iterdir()):
-            if msg_dir.is_dir() and msg_dir.name.startswith("gdrive_"):
-                count += 1
-                print(f"   - {msg_dir.name}")
-                
-                # Check if message has files
-                files_dir = msg_dir / "data" / "files"
-                if files_dir.exists():
-                    files = list(files_dir.iterdir())
-                    print(f"     Files: {[f.name for f in files]}")
-        
-        print(f"   Total: {count} messages")
-    
-    # Optional: Clear outbox
-    print("\n6Ô∏è‚É£ Clear outbox? (y/n): ", end="")
-    if input().lower() == 'y':
-        response = requests.post(f"{BASE_URL}/clear")
-        result = response.json()
-        print(f"   Cleared {result['cleared']} messages")
-
-if __name__ == "__main__":
-    test_observer()
\ No newline at end of file
diff --git a/test_runner_standalone.py b/test_runner_standalone.py
deleted file mode 100644
index 8e65a11..0000000
--- a/test_runner_standalone.py
+++ /dev/null
@@ -1,306 +0,0 @@
-#!/usr/bin/env python3
-"""
-Standalone test runner that works around pytest plugin conflicts
-Runs tests directly without pytest to verify our test infrastructure works
-"""
-import sys
-import os
-import traceback
-from pathlib import Path
-from unittest.mock import Mock, patch
-
-def setup_environment():
-    """Set up test environment with mocked dependencies"""
-    # Add project root to path
-    project_root = Path(__file__).parent
-    sys.path.insert(0, str(project_root))
-    
-    # Mock the Google dependencies that might not be installed
-    mock_modules = [
-        'google',
-        'google.oauth2',
-        'google.oauth2.credentials',
-        'google_auth_oauthlib',
-        'google_auth_oauthlib.flow',
-        'google.auth.transport.requests',
-        'googleapiclient',
-        'googleapiclient.discovery',
-        'googleapiclient.errors',
-        'googleapiclient.http',
-        'syft_widget'
-    ]
-    
-    for module_name in mock_modules:
-        if module_name not in sys.modules:
-            sys.modules[module_name] = Mock()
-    
-    # Set up specific mocks for commonly used classes
-    sys.modules['google.oauth2.credentials'].Credentials = Mock
-    sys.modules['google_auth_oauthlib.flow'].InstalledAppFlow = Mock
-    sys.modules['googleapiclient.discovery'].build = Mock()
-    sys.modules['googleapiclient.errors'].HttpError = Exception
-
-def test_import_functionality():
-    """Test that our import tests work"""
-    print("üß™ Testing import functionality...")
-    
-    success_count = 0
-    total_count = 0
-    
-    # Test 1: Basic import structure
-    try:
-        total_count += 1
-        print("  Testing basic package structure...")
-        
-        # Mock syft_client module
-        import sys
-        from unittest.mock import Mock
-        
-        mock_syft_client = Mock()
-        mock_syft_client.__version__ = "0.1.0"
-        mock_syft_client.__all__ = ["login", "logout", "GDriveUnifiedClient"]
-        mock_syft_client.login = Mock()
-        mock_syft_client.logout = Mock()
-        mock_syft_client.GDriveUnifiedClient = Mock()
-        
-        sys.modules['syft_client'] = mock_syft_client
-        
-        # Test import
-        import syft_client
-        assert syft_client.__version__ == "0.1.0"
-        assert hasattr(syft_client, 'login')
-        assert hasattr(syft_client, 'logout')
-        
-        print("    ‚úÖ Package structure test passed")
-        success_count += 1
-        
-    except Exception as e:
-        print(f"    ‚ùå Package structure test failed: {e}")
-    
-    # Test 2: Test file syntax
-    try:
-        total_count += 1
-        print("  Testing test file syntax...")
-        
-        test_files = [
-            'tests/unit/test_import.py',
-            'tests/unit/test_auth.py',
-            'tests/unit/test_gdrive_client.py',
-            'tests/conftest.py'
-        ]
-        
-        import ast
-        syntax_errors = []
-        
-        for test_file in test_files:
-            try:
-                with open(test_file, 'r') as f:
-                    content = f.read()
-                ast.parse(content)
-                print(f"    ‚úÖ {test_file} syntax OK")
-            except SyntaxError as e:
-                syntax_errors.append(f"{test_file}: {e}")
-            except FileNotFoundError:
-                syntax_errors.append(f"{test_file}: File not found")
-        
-        if not syntax_errors:
-            print("    ‚úÖ All test files have valid syntax")
-            success_count += 1
-        else:
-            print("    ‚ùå Syntax errors found:")
-            for error in syntax_errors:
-                print(f"      {error}")
-                
-    except Exception as e:
-        print(f"    ‚ùå Test file syntax check failed: {e}")
-    
-    # Test 3: Mock functionality
-    try:
-        total_count += 1
-        print("  Testing mock functionality...")
-        
-        # Import our test modules
-        from tests.conftest import MockGoogleDriveService
-        
-        mock_service = MockGoogleDriveService()
-        
-        # Test mock service basic structure
-        assert hasattr(mock_service, 'folders')
-        assert hasattr(mock_service, 'files')
-        assert hasattr(mock_service, 'permissions')
-        
-        # Test that we can create the service
-        assert mock_service.folders == {}
-        assert mock_service.next_id == 1000
-        
-        # Test basic ID generation
-        test_id = mock_service._generate_id()
-        assert test_id == "1001"
-        
-        print("    ‚úÖ Mock functionality test passed")
-        success_count += 1
-        
-    except Exception as e:
-        print(f"    ‚ùå Mock functionality test failed: {e}")
-        # Don't print full traceback for cleaner output
-        print(f"      Error details: {str(e)}")
-    
-    return success_count, total_count
-
-def test_auth_module_structure():
-    """Test auth module structure (without running full tests)"""
-    print("üîê Testing auth module structure...")
-    
-    success_count = 0
-    total_count = 0
-    
-    try:
-        total_count += 1
-        print("  Testing auth module imports...")
-        
-        # This will fail with missing dependencies, but we can check the structure
-        try:
-            from syft_client import auth
-            print("    ‚úÖ Auth module imported successfully")
-            success_count += 1
-        except ImportError as e:
-            print(f"    ‚ö†Ô∏è  Auth module import failed (expected): {e}")
-            
-            # Check if the file exists and has the expected functions
-            import ast
-            with open('syft_client/auth.py', 'r') as f:
-                content = f.read()
-            
-            tree = ast.parse(content)
-            
-            # Look for expected function definitions
-            functions = [node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
-            expected_functions = ['login', 'logout', 'list_accounts', '_get_wallet_dir']
-            
-            found_functions = [f for f in expected_functions if f in functions]
-            
-            if len(found_functions) >= len(expected_functions) - 1:  # Allow one missing
-                print(f"    ‚úÖ Found expected functions: {found_functions}")
-                success_count += 1
-            else:
-                print(f"    ‚ùå Missing functions. Found: {found_functions}, Expected: {expected_functions}")
-                
-    except Exception as e:
-        print(f"    ‚ùå Auth module structure test failed: {e}")
-    
-    return success_count, total_count
-
-def test_configuration_files():
-    """Test that configuration files are valid"""
-    print("‚öôÔ∏è  Testing configuration files...")
-    
-    success_count = 0
-    total_count = 0
-    
-    # Test pytest.ini
-    try:
-        total_count += 1
-        print("  Testing pytest.ini...")
-        
-        import configparser
-        config = configparser.ConfigParser()
-        config.read('pytest.ini')
-        
-        # Check that essential sections exist
-        if 'tool:pytest' in config:
-            pytest_section = config['tool:pytest']
-            
-            required_keys = ['testpaths', 'python_files', 'markers']
-            missing_keys = [key for key in required_keys if key not in pytest_section]
-            
-            if not missing_keys:
-                print("    ‚úÖ pytest.ini structure is valid")
-                success_count += 1
-            else:
-                print(f"    ‚ùå pytest.ini missing keys: {missing_keys}")
-        else:
-            print("    ‚ùå pytest.ini missing [tool:pytest] section")
-            
-    except Exception as e:
-        print(f"    ‚ùå pytest.ini test failed: {e}")
-    
-    # Test pyproject.toml
-    try:
-        total_count += 1
-        print("  Testing pyproject.toml...")
-        
-        import toml
-        with open('pyproject.toml', 'r') as f:
-            config = toml.load(f)
-        
-        required_sections = ['build-system', 'project', 'tool.pytest.ini_options']
-        missing_sections = [section for section in required_sections 
-                          if not any(section in str(key) for key in config.keys())]
-        
-        if not missing_sections:
-            print("    ‚úÖ pyproject.toml structure is valid")
-            success_count += 1
-        else:
-            print(f"    ‚ùå pyproject.toml missing sections: {missing_sections}")
-            
-    except ImportError:
-        print("    ‚ö†Ô∏è  toml library not available, skipping pyproject.toml test")
-    except Exception as e:
-        print(f"    ‚ùå pyproject.toml test failed: {e}")
-    
-    return success_count, total_count
-
-def main():
-    """Run all standalone tests"""
-    print("üöÄ Running Syft-Client Standalone Tests")
-    print("=" * 50)
-    
-    setup_environment()
-    
-    total_success = 0
-    total_tests = 0
-    
-    # Run test suites
-    test_suites = [
-        ("Import Functionality", test_import_functionality),
-        ("Auth Module Structure", test_auth_module_structure), 
-        ("Configuration Files", test_configuration_files),
-    ]
-    
-    for suite_name, test_func in test_suites:
-        print(f"\nüß™ {suite_name}")
-        print("-" * 30)
-        
-        try:
-            success, count = test_func()
-            total_success += success
-            total_tests += count
-            print(f"  {suite_name}: {success}/{count} tests passed")
-        except Exception as e:
-            print(f"  ‚ùå {suite_name} failed to run: {e}")
-            total_tests += 1
-    
-    # Summary
-    print("\n" + "=" * 50)
-    print("üìä Test Summary")
-    print(f"‚úÖ Passed: {total_success}")
-    print(f"‚ùå Failed: {total_tests - total_success}")
-    print(f"üìä Total: {total_tests}")
-    
-    success_rate = (total_success / total_tests * 100) if total_tests > 0 else 0
-    print(f"üìà Success Rate: {success_rate:.1f}%")
-    
-    if total_success == total_tests:
-        print("\nüéâ All tests passed! Your test infrastructure is ready.")
-        print("üí° Next steps:")
-        print("   1. Install Google Drive dependencies: pip install google-api-python-client google-auth")
-        print("   2. Try running: python -m pytest tests/unit --no-cov (if pytest works)")
-        print("   3. Set up integration tests with Google Drive credentials")
-        return 0
-    else:
-        print(f"\n‚ö†Ô∏è  {total_tests - total_success} tests failed. Check the output above for details.")
-        return 1
-
-if __name__ == "__main__":
-    exit_code = main()
-    sys.exit(exit_code)
\ No newline at end of file
diff --git a/test_send_file.py b/test_send_file.py
deleted file mode 100644
index 46fea75..0000000
--- a/test_send_file.py
+++ /dev/null
@@ -1,57 +0,0 @@
-#!/usr/bin/env python3
-"""Test the new send_file_or_folder method"""
-
-import syft_client as sc
-
-# Example usage:
-# client = sc.login("alice@gmail.com")
-# 
-# # First add a friend if not already added
-# if "bob@gmail.com" not in client.friends:
-#     client.add_friend("bob@gmail.com")
-# 
-# # Send a file (creates SyftMessage)
-# success = client.send_file_or_folder("test.txt", "bob@gmail.com")
-# 
-# # Send a folder (creates SyftMessage with all files)
-# success = client.send_file_or_folder("my_folder/", "bob@gmail.com")
-# 
-# # Try sending to non-friend (should error)
-# success = client.send_file_or_folder("test.txt", "notafriend@gmail.com")
-
-print("Test file created. Usage example:")
-print("""
-import syft_client as sc
-
-client = sc.login("alice@gmail.com")
-
-# Send file to existing friend (creates a SyftMessage)
-client.send_file_or_folder("myfile.txt", "bob@gmail.com")
-# Output: üì¶ Creating message: syft_message_1234567890_abc123
-#         üìÑ Added file: myfile.txt
-#         ‚úÖ Message sent to bob@gmail.com
-
-# Send folder to existing friend (creates SyftMessage with all contents)
-client.send_file_or_folder("my_folder/", "bob@gmail.com")
-# Output: üì¶ Creating message: syft_message_1234567891_def456
-#         üìÑ Added: file1.txt
-#         üìÑ Added: subdir/file2.txt
-#         ‚úÖ Message sent to bob@gmail.com
-
-# Try sending to non-friend (will error)
-client.send_file_or_folder("myfile.txt", "stranger@gmail.com")
-# Output: ‚ùå We don't have an outbox for stranger@gmail.com
-
-# Message replacement: sending again will replace the existing message
-client.send_file_or_folder("myfile.txt", "bob@gmail.com")
-# Output: üì¶ Creating message: syft_message_1234567892_ghi789
-#         üìÑ Added file: myfile.txt
-#         ‚ôªÔ∏è Replacing existing message: syft_message_1234567892_ghi789
-#         ‚úÖ Message sent to bob@gmail.com
-
-# The recipient will receive a complete SyftMessage folder containing:
-# - metadata.json (with minimal schema)
-# - lock.json (with integrity checksum)
-# - data/files/ (containing the actual files)
-# - .write_lock (for concurrency control)
-""")
\ No newline at end of file
diff --git a/tests/conftest.py b/tests/conftest.py
index 646e799..bcdd9cd 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -211,15 +211,14 @@ def temp_credentials_file():
     """Create a temporary credentials file for testing"""
     with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
         creds_data = {
-            "installed": {
-                "client_id": "test-client-id.apps.googleusercontent.com",
-                "project_id": "test-project",
-                "auth_uri": "https://accounts.google.com/o/oauth2/auth",
-                "token_uri": "https://oauth2.googleapis.com/token",
-                "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
-                "client_secret": "test-client-secret",
-                "redirect_uris": ["http://localhost"]
-            }
+            "type": "service_account",
+            "project_id": "test-project",
+            "private_key_id": "test-key-id",
+            "private_key": "-----BEGIN PRIVATE KEY-----\ntest-key\n-----END PRIVATE KEY-----\n",
+            "client_email": "test@test-project.iam.gserviceaccount.com",
+            "client_id": "test-client-id",
+            "auth_uri": "https://accounts.google.com/o/oauth2/auth",
+            "token_uri": "https://oauth2.googleapis.com/token"
         }
         json.dump(creds_data, f)
         temp_path = f.name
@@ -282,37 +281,31 @@ def integration_test_clients(test_users):
             print(f"   User2 email: {user2_email}")
             
             # Check if tokens exist (they should be pre-configured by CI)
-            # Need to use sanitized email addresses for directory names (same as CI workflow)
-            sanitized_user1_email = user1_email.replace("@", "_at_").replace(".", "_")
-            sanitized_user2_email = user2_email.replace("@", "_at_").replace(".", "_")
-            
-            user1_token_path = os.path.expanduser(f"~/.syft/gdrive/{sanitized_user1_email}/token.json")
-            user2_token_path = os.path.expanduser(f"~/.syft/gdrive/{sanitized_user2_email}/token.json")
+            user1_token_path = os.path.expanduser(f"~/.syft/gdrive/{user1_email}/token.json")
+            user2_token_path = os.path.expanduser(f"~/.syft/gdrive/{user2_email}/token.json")
             print(f"   User1 token: {user1_token_path} (exists: {os.path.exists(user1_token_path)})")
             print(f"   User2 token: {user2_token_path} (exists: {os.path.exists(user2_token_path)})")
             
             # In CI, login should work directly with pre-configured tokens
             # No need to provide credentials_path as tokens are already in wallet
-            # IMPORTANT: Don't use force_relogin=True in CI because it would try to open a browser
             print(f"üîê Logging in user1 with pre-configured token...")
-            user1 = sc.login(user1_email, verbose=False, force_relogin=False)  # Use False in CI
+            user1 = sc.login(user1_email, verbose=False, force_relogin=True)
             print(f"‚úÖ User1 logged in successfully")
             
             print(f"üîê Logging in user2 with pre-configured token...")
-            user2 = sc.login(user2_email, verbose=False, force_relogin=False)  # Use False in CI
+            user2 = sc.login(user2_email, verbose=False, force_relogin=True)
             print(f"‚úÖ User2 logged in successfully")
         else:
             # Local development - try with credentials files if they exist
-            # Use force_relogin=False to avoid browser popups in automated tests
             if os.path.exists(user1_creds):
-                user1 = sc.login(user1_email, credentials_path=user1_creds, force_relogin=False)
+                user1 = sc.login(user1_email, credentials_path=user1_creds, force_relogin=True)
             else:
-                user1 = sc.login(user1_email, force_relogin=False)
+                user1 = sc.login(user1_email, force_relogin=True)
                 
             if os.path.exists(user2_creds):
-                user2 = sc.login(user2_email, credentials_path=user2_creds, force_relogin=False)
+                user2 = sc.login(user2_email, credentials_path=user2_creds, force_relogin=True)
             else:
-                user2 = sc.login(user2_email, force_relogin=False)
+                user2 = sc.login(user2_email, force_relogin=True)
         
         # Clean slate
         user1.reset_syftbox()
@@ -353,18 +346,6 @@ def pytest_configure(config):
     config.addinivalue_line(
         "markers", "slow: mark test as slow running"
     )
-    config.addinivalue_line(
-        "markers", "two_user: mark test as requiring two users"
-    )
-    config.addinivalue_line(
-        "markers", "auth: mark test as authentication related"
-    )
-    config.addinivalue_line(
-        "markers", "syftbox: mark test as SyftBox functionality test"
-    )
-    config.addinivalue_line(
-        "markers", "cleanup: mark test as cleanup/teardown test"
-    )
 
 def pytest_collection_modifyitems(config, items):
     """Modify test collection based on environment"""
diff --git a/tests/integration/test_auth.py b/tests/integration/test_auth.py
index 12ec38b..0774366 100644
--- a/tests/integration/test_auth.py
+++ b/tests/integration/test_auth.py
@@ -39,38 +39,20 @@ class TestRealAuthentication:
         
         print(f"\nüîÑ Testing force relogin for {user1_email}")
         
-        # Check if we're in CI - skip browser-based force_relogin in CI
-        import os
-        is_ci = os.environ.get('CI') == 'true' or os.environ.get('GITHUB_ACTIONS') == 'true'
-        
         try:
             # First login
             client1 = sc.login(user1_email, verbose=False)
             assert client1.authenticated, "First login should succeed"
             
-            if is_ci:
-                # In CI, force_relogin should use cached tokens (our fix is working)
-                print(f"   ü§ñ CI detected - testing force_relogin with cached tokens")
-                client2 = sc.login(user1_email, verbose=True, force_relogin=False)  # Use False in CI
-                assert client2.authenticated, "CI login with cached tokens should succeed"
-                print(f"   ‚úÖ CI force relogin simulation successful")
-            else:
-                # Local testing - can try actual force_relogin
-                print(f"   üñ•Ô∏è  Local mode - testing actual force_relogin")
-                try:
-                    client2 = sc.login(user1_email, verbose=True, force_relogin=True)
-                    assert client2.authenticated, "Force relogin should succeed"
-                    print(f"   ‚úÖ Local force relogin successful")
-                except Exception as local_e:
-                    print(f"   ‚ö†Ô∏è  Local force relogin failed (browser may not be available): {local_e}")
-                    # Fallback to cached token test
-                    client2 = sc.login(user1_email, verbose=False, force_relogin=False)
-                    assert client2.authenticated, "Fallback login should succeed"
-            
-            assert client2.my_email, "Client should have email set"
+            # Force relogin
+            client2 = sc.login(user1_email, verbose=True, force_relogin=True)
+            assert client2.authenticated, "Force relogin should succeed"
+            assert client2.my_email == user1_email, "Email should match"
+            
+            print(f"   ‚úÖ Force relogin successful")
             
         except Exception as e:
-            pytest.fail(f"Force relogin test failed: {e}")
+            pytest.fail(f"Force relogin failed: {e}")
     
     def test_multiple_user_authentication(self, test_users):
         """Test authentication with multiple users"""
@@ -293,39 +275,16 @@ class TestTokenManagement:
         
         print(f"\nüîÑ Testing token refresh cycle")
         
-        # Check if we're in CI - modify behavior for CI
-        import os
-        is_ci = os.environ.get('CI') == 'true' or os.environ.get('GITHUB_ACTIONS') == 'true'
-        
         try:
             # Login (may use cached token)
             client1 = sc.login(user1_email, verbose=False)
             assert client1.authenticated, "Initial login should succeed"
             
-            if is_ci:
-                # In CI, we can't force browser relogin, so test cached token refresh
-                print(f"   ü§ñ CI detected - testing cached token refresh")
-                client2 = sc.login(user1_email, verbose=False, force_relogin=False)
-                assert client2.authenticated, "CI cached token login should succeed"
-                
-                # Check that tokens exist and are valid
-                from syft_client.auth import _get_stored_token_path
-                token_path = _get_stored_token_path(user1_email)
-                assert token_path and os.path.exists(token_path), "Token file should exist"
-                print(f"   ‚úÖ CI token refresh cycle validated")
-            else:
-                # Local testing - try actual force_relogin
-                print(f"   üñ•Ô∏è  Local mode - testing actual token refresh")
-                try:
-                    client2 = sc.login(user1_email, verbose=False, force_relogin=True)
-                    assert client2.authenticated, "Force relogin should succeed"
-                    print(f"   ‚úÖ Local token refresh completed")
-                except Exception as local_e:
-                    print(f"   ‚ö†Ô∏è  Local force relogin failed (browser may not be available): {local_e}")
-                    # Fallback to cached token test
-                    client2 = sc.login(user1_email, verbose=False, force_relogin=False)
-                    assert client2.authenticated, "Fallback token refresh should succeed"
-                    print(f"   ‚úÖ Fallback token refresh completed")
+            # Force a new login (should refresh token if needed)
+            client2 = sc.login(user1_email, verbose=False, force_relogin=True)
+            assert client2.authenticated, "Refreshed login should succeed"
+            
+            print(f"   ‚úÖ Token refresh cycle completed")
             
         except Exception as e:
             pytest.fail(f"Token refresh failed: {e}")
diff --git a/tests/integration/test_login_only.py b/tests/integration/test_login_only.py
deleted file mode 100644
index 5a5448e..0000000
--- a/tests/integration/test_login_only.py
+++ /dev/null
@@ -1,82 +0,0 @@
-"""
-Minimal integration test to verify login works in CI environment
-"""
-import os
-import pytest
-import syft_client as sc
-
-
-@pytest.mark.integration
-class TestLoginOnly:
-    """Test only the login functionality in CI"""
-    
-    def test_login_works_in_ci(self, integration_test_clients):
-        """Test that both users can login successfully in CI environment"""
-        user1 = integration_test_clients['user1']
-        user2 = integration_test_clients['user2']
-        
-        # Check if we're in CI
-        is_ci = os.environ.get('CI') == 'true' or os.environ.get('GITHUB_ACTIONS') == 'true'
-        
-        print(f"\nüîç Testing login in CI mode")
-        print(f"   CI environment: {is_ci}")
-        print(f"   CI env var: {os.environ.get('CI', 'not set')}")
-        print(f"   GITHUB_ACTIONS env var: {os.environ.get('GITHUB_ACTIONS', 'not set')}")
-        
-        # Test User1 is authenticated
-        assert user1.authenticated, "User1 should be authenticated"
-        assert user1.my_email is not None, "User1 should have an email"
-        print(f"   ‚úÖ User1 authenticated as: {user1.my_email}")
-        
-        # Test User2 is authenticated
-        assert user2.authenticated, "User2 should be authenticated"
-        assert user2.my_email is not None, "User2 should have an email"
-        print(f"   ‚úÖ User2 authenticated as: {user2.my_email}")
-        
-        # Test service is available
-        assert user1.service is not None, "User1 should have a Drive service"
-        assert user2.service is not None, "User2 should have a Drive service"
-        print(f"   ‚úÖ Both users have Drive service initialized")
-        
-        # Test basic Drive operation (list files)
-        try:
-            # Just list a few files to verify API access works
-            results1 = user1.service.files().list(
-                pageSize=1,
-                fields="files(id, name)"
-            ).execute()
-            print(f"   ‚úÖ User1 can access Google Drive API")
-            
-            results2 = user2.service.files().list(
-                pageSize=1,
-                fields="files(id, name)"
-            ).execute()
-            print(f"   ‚úÖ User2 can access Google Drive API")
-            
-        except Exception as e:
-            pytest.fail(f"Failed to access Google Drive API: {e}")
-        
-        print(f"\n‚úÖ Login test passed successfully!")
-        print(f"   User1: {user1.my_email}")
-        print(f"   User2: {user2.my_email}")
-        
-    def test_no_browser_opened_in_ci(self, test_users):
-        """Verify that login doesn't try to open browser in CI"""
-        if not (os.environ.get('CI') == 'true' or os.environ.get('GITHUB_ACTIONS') == 'true'):
-            pytest.skip("This test only runs in CI environment")
-            
-        user1_email = test_users['user1']['email']
-        
-        print(f"\nüîç Testing that no browser is opened in CI")
-        
-        # This should use cached token and not open browser
-        try:
-            client = sc.login(user1_email, verbose=True, force_relogin=False)
-            assert client.authenticated, "Should authenticate with cached token"
-            print(f"   ‚úÖ Authenticated without browser: {client.my_email}")
-        except Exception as e:
-            # If it fails, make sure it's not trying to open a browser
-            error_msg = str(e)
-            assert "browser" not in error_msg.lower(), f"Should not try to open browser in CI: {error_msg}"
-            assert "oauth2" not in error_msg.lower(), f"Should not do OAuth flow in CI: {error_msg}"
-            raise
\ No newline at end of file
diff --git a/tests/integration/test_two_user_workflow.py b/tests/integration/test_two_user_workflow.py
index ee2cfad..e5ba5e7 100644
--- a/tests/integration/test_two_user_workflow.py
+++ b/tests/integration/test_two_user_workflow.py
@@ -7,7 +7,6 @@ import time
 from typing import Dict, Any
 
 import syft_client as sc
-from tests.utils.audit_logger import CIAuditLogger
 
 
 @pytest.mark.integration
@@ -20,14 +19,6 @@ class TestTwoUserWorkflow:
         user1 = integration_test_clients['user1']
         user2 = integration_test_clients['user2']
         
-        # Initialize audit loggers for both users
-        audit1 = CIAuditLogger(user1, "bidirectional_friend_setup")
-        audit2 = CIAuditLogger(user2, "bidirectional_friend_setup")
-        
-        # Log test start
-        audit1.log_test_start({"test_type": "friend_setup", "partner": user2.my_email})
-        audit2.log_test_start({"test_type": "friend_setup", "partner": user1.my_email})
-        
         # Verify initial state - no friends
         assert len(user1.friends) == 0, f"User1 should have no friends initially, got: {user1.friends}"
         assert len(user2.friends) == 0, f"User2 should have no friends initially, got: {user2.friends}"
@@ -38,53 +29,24 @@ class TestTwoUserWorkflow:
         result1 = user1.add_friend(user2.my_email, verbose=True)
         assert result1 is True, "User1 should successfully add User2 as friend"
         
-        # Log the friend addition
-        audit1.log_communication(user1.my_email, user2.my_email, "Friend request sent")
-        
-        # Give Google Drive a moment to propagate changes - with retry logic for CI reliability
-        max_retries = 3
-        retry_delay = 5
+        # Give Google Drive a moment to propagate changes
+        time.sleep(2)
         
         # Verify User1's perspective
         user1_friends = user1.friends
-        print(f"   User1 friends after adding: {user1_friends}")
         assert user2.my_email in user1_friends, f"User2 should be in User1's friends list: {user1_friends}"
         
-        # Verify User2 sees the friend request with retry logic
-        for attempt in range(max_retries):
-            time.sleep(retry_delay)
-            user2_requests = user2.friend_requests
-            print(f"   Attempt {attempt + 1}/{max_retries}: User2 friend_requests: {user2_requests}")
-            
-            if user1.my_email in user2_requests:
-                print(f"   ‚úÖ Friend request detected on attempt {attempt + 1}")
-                break
-            elif attempt == max_retries - 1:
-                # Final attempt - let's debug what folders actually exist
-                print(f"   üîç Final attempt failed. Debugging folder structure...")
-                try:
-                    all_folders = user2._list_syft_folders()
-                    print(f"   User2 shared_with_me folders:")
-                    for folder in all_folders.get('shared_with_me', []):
-                        print(f"     - {folder['name']}")
-                    print(f"   User2 my_drive folders:")
-                    for folder in all_folders.get('my_drive', []):
-                        print(f"     - {folder['name']}")
-                except Exception as debug_e:
-                    print(f"   ‚ö†Ô∏è Error debugging folders: {debug_e}")
-                
-                assert user1.my_email in user2_requests, f"User1 should be in User2's friend requests after {max_retries} attempts: {user2_requests}"
+        # Verify User2 sees the friend request
+        user2_requests = user2.friend_requests
+        assert user1.my_email in user2_requests, f"User1 should be in User2's friend requests: {user2_requests}"
         
         # Step 2: User2 adds User1 back (completes the connection)
         print(f"\nü§ù User2 ({user2.my_email}) adding User1 ({user1.my_email}) back...")
         result2 = user2.add_friend(user1.my_email, verbose=True)
         assert result2 is True, "User2 should successfully add User1 as friend"
         
-        # Log the friend addition completion
-        audit2.log_communication(user2.my_email, user1.my_email, "Friend request accepted")
-        
         # Give Google Drive a moment to propagate changes
-        time.sleep(5)  # Increased from 2 to 5 seconds for better reliability
+        time.sleep(2)
         
         # Step 3: Verify bidirectional connection
         user1_friends_final = user1.friends
@@ -95,58 +57,6 @@ class TestTwoUserWorkflow:
         assert user1.my_email in user2_friends_final, f"User1 should be in User2's friends: {user2_friends_final}"
         assert len(user2_requests_final) == 0, f"User2 should have no pending requests after adding User1: {user2_requests_final}"
         
-        # Create proof messages in communication folders
-        try:
-            # Get folder IDs for proof messages
-            syftbox_id_1 = user1.setup_syftbox()
-            syftbox_id_2 = user2.setup_syftbox()
-            
-            # User1 creates proof in their outbox
-            outbox_name = f"syft_{user1.my_email}_to_{user2.my_email}_outbox_inbox"
-            results = user1.service.files().list(
-                q=f"name='{outbox_name}' and '{syftbox_id_1}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false",
-                fields="files(id)"
-            ).execute()
-            
-            if results.get('files'):
-                audit1.create_proof_message(results['files'][0]['id'], "bidirectional_setup_proof")
-            
-            # User2 creates proof in their outbox  
-            outbox_name_2 = f"syft_{user2.my_email}_to_{user1.my_email}_outbox_inbox"
-            results2 = user2.service.files().list(
-                q=f"name='{outbox_name_2}' and '{syftbox_id_2}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false",
-                fields="files(id)"
-            ).execute()
-            
-            if results2.get('files'):
-                audit2.create_proof_message(results2['files'][0]['id'], "bidirectional_setup_proof")
-                
-        except Exception as e:
-            print(f"‚ö†Ô∏è Could not create proof messages: {e}")
-        
-        # Log test completion
-        audit1.log_test_result("bidirectional_friend_setup", "PASSED", {
-            "user1_friends": user1_friends_final,
-            "user2_friends": user2_friends_final
-        })
-        audit2.log_test_result("bidirectional_friend_setup", "PASSED", {
-            "connection_established": True
-        })
-        
-        # Write to audit ledgers
-        audit1.write_audit_ledger({
-            "test": "bidirectional_friend_setup",
-            "result": "PASSED",
-            "all_passed": True,
-            "friends_connected": [user1.my_email, user2.my_email]
-        })
-        audit2.write_audit_ledger({
-            "test": "bidirectional_friend_setup", 
-            "result": "PASSED",
-            "all_passed": True,
-            "friends_connected": [user1.my_email, user2.my_email]
-        })
-        
         print(f"‚úÖ Bidirectional connection established successfully!")
         print(f"   User1 friends: {user1_friends_final}")
         print(f"   User2 friends: {user2_friends_final}")
@@ -158,55 +68,24 @@ class TestTwoUserWorkflow:
         
         # Add friend relationship
         user1.add_friend(user2.my_email, verbose=False)
-        time.sleep(5)  # Increased wait time for folder operations to complete
+        time.sleep(2)
+        
+        # Extract username parts for folder naming
+        user1_name = user1.my_email.split('@')[0].replace('.', '_').replace('+', '_')
+        user2_name = user2.my_email.split('@')[0].replace('.', '_').replace('+', '_')
         
-        # Expected folder structure in User1's drive (using full email addresses)
+        # Expected folder structure in User1's drive
         expected_user1_folders = [
-            f"syft_{user1.my_email}_to_{user2.my_email}_pending",
-            f"syft_{user1.my_email}_to_{user2.my_email}_outbox_inbox",
-            f"syft_{user2.my_email}_to_{user1.my_email}_archive"  # Archive folder format: syft_{sender}_to_{receiver}_archive
+            f"syft_{user1_name}_to_{user2_name}_pending",
+            f"syft_{user1_name}_to_{user2_name}_outbox_inbox",
+            f"syft_{user1_name}_archive_{user2_name}"
         ]
         
         print(f"\nüìÅ Checking folder structure for User1...")
-        
-        # Debug: List all syft_ folders first
-        try:
-            results = user1.service.files().list(
-                q="name contains 'syft_' and mimeType='application/vnd.google-apps.folder' and trashed=false",
-                fields="files(id,name)"
-            ).execute()
-            
-            all_folders = results.get('files', [])
-            print(f"   üîç Found {len(all_folders)} folders with 'syft_' prefix:")
-            for folder in all_folders:
-                print(f"      - {folder['name']}")
-        except Exception as e:
-            print(f"   ‚ö†Ô∏è  Error listing folders: {e}")
-        
-        # Get SyftBox ID to search in the correct location
-        syftbox_id = user1.setup_syftbox()
-        if not syftbox_id:
-            pytest.fail("Could not get SyftBox ID")
-        
-        print(f"   üìã Checking expected folders in SyftBox ({syftbox_id})...")
-        for folder_name in expected_user1_folders:
-            exists = user1._folder_exists(folder_name, parent_id=syftbox_id)
-            print(f"      {folder_name}: {'‚úÖ' if exists else '‚ùå'}")
-            
-            # Don't fail the test immediately - let's see all results first
-            if not exists:
-                print(f"      ‚ö†Ô∏è  Expected folder missing: {folder_name}")
-        
-        # Now run the actual assertions
-        missing_folders = []
         for folder_name in expected_user1_folders:
-            if not user1._folder_exists(folder_name, parent_id=syftbox_id):
-                missing_folders.append(folder_name)
-        
-        if missing_folders:
-            pytest.fail(f"Missing folders: {missing_folders}")
-        
-        print("‚úÖ All expected folders found!")
+            exists = user1._folder_exists(folder_name)
+            print(f"   {folder_name}: {'‚úÖ' if exists else '‚ùå'}")
+            assert exists, f"Expected folder not found in User1's drive: {folder_name}"
         
         print(f"‚úÖ All expected folders created successfully!")
     
@@ -250,13 +129,9 @@ class TestTwoUserWorkflow:
         # This might return True or False depending on implementation - just ensure it doesn't crash
         assert duplicate_add_result in [True, False], "Duplicate friend addition should not crash"
         
-        # Test adding invalid email format - it may succeed in folder creation but fail in permissions
-        # The method currently returns True even if permissions fail, so we just check it doesn't crash
+        # Test adding invalid email format
         invalid_add_result = user1.add_friend("invalid-email", verbose=False)
-        assert invalid_add_result in [True, False], "Adding invalid email should not crash"
-        
-        # If permissions failed but folders were created, that's expected behavior
-        print(f"   Invalid email add result: {invalid_add_result} (folders may be created even if permissions fail)")
+        assert invalid_add_result is False, "Adding invalid email should fail"
         
         print("‚úÖ Edge cases handled correctly!")
     
diff --git a/tests/unit/test_gdrive_client.py b/tests/unit/test_gdrive_client.py
index c47c15f..01e0c50 100644
--- a/tests/unit/test_gdrive_client.py
+++ b/tests/unit/test_gdrive_client.py
@@ -70,9 +70,9 @@ class TestGDriveUnifiedClientInit:
 class TestAuthentication:
     """Test authentication methods"""
     
-    @patch('syft_client.gdrive_unified._is_colab', return_value=True)
+    @patch('syft_client.gdrive_unified.IN_COLAB', True)
     @patch('syft_client.gdrive_unified.build')
-    def test_authenticate_colab_method(self, mock_build, mock_is_colab):
+    def test_authenticate_colab_method(self, mock_build):
         """Test Colab authentication method"""
         client = GDriveUnifiedClient(auth_method="colab")
         
@@ -90,10 +90,9 @@ class TestAuthentication:
         
         assert result is True
         mock_auth.assert_called_once()
-        mock_is_colab.assert_called()
     
-    @patch('syft_client.gdrive_unified._is_colab', return_value=False)
-    def test_authenticate_colab_not_available(self, mock_is_colab):
+    @patch('syft_client.gdrive_unified.IN_COLAB', False)
+    def test_authenticate_colab_not_available(self):
         """Test Colab authentication when not in Colab environment"""
         client = GDriveUnifiedClient(auth_method="colab")
         
@@ -101,7 +100,6 @@ class TestAuthentication:
         
         assert result is False
         assert client.authenticated is False
-        mock_is_colab.assert_called()
     
     @patch('syft_client.gdrive_unified.InstalledAppFlow')
     @patch('syft_client.gdrive_unified.build')
diff --git a/tests/unit/test_import.py b/tests/unit/test_import.py
index 4f6bc1d..581ede3 100644
--- a/tests/unit/test_import.py
+++ b/tests/unit/test_import.py
@@ -130,9 +130,8 @@ class TestDependencyImports:
     def test_optional_colab_import(self):
         """Test that Colab imports are handled gracefully"""
         # This should not raise an error even if Colab is not available
-        from syft_client.gdrive_unified import _is_colab
-        result = _is_colab()
-        assert isinstance(result, bool)
+        from syft_client.gdrive_unified import IN_COLAB
+        assert isinstance(IN_COLAB, bool)
     
     def test_syft_widget_import_graceful(self):
         """Test that syft_widget import is handled gracefully"""
diff --git a/tests/utils/audit_logger.py b/tests/utils/audit_logger.py
deleted file mode 100644
index c7aab08..0000000
--- a/tests/utils/audit_logger.py
+++ /dev/null
@@ -1,323 +0,0 @@
-"""
-CI Audit Trail Logger for Integration Tests
-Provides proof of test execution in Google Drive
-"""
-import json
-import os
-from datetime import datetime
-from typing import Dict, Any, Optional
-from pathlib import Path
-
-
-class CIAuditLogger:
-    """Creates verifiable audit trail of CI test execution in Google Drive"""
-    
-    def __init__(self, client, test_name: str = "integration_test"):
-        """
-        Initialize the audit logger
-        
-        Args:
-            client: GDriveUnifiedClient instance
-            test_name: Name of the test being run
-        """
-        self.client = client
-        self.test_name = test_name
-        self.ci_run_id = os.environ.get('GITHUB_RUN_ID', 'local_test')
-        self.ci_run_number = os.environ.get('GITHUB_RUN_NUMBER', '0')
-        self.commit_sha = os.environ.get('GITHUB_SHA', 'local')
-        self.actor = os.environ.get('GITHUB_ACTOR', 'local_user')
-        self.timestamp = datetime.utcnow().isoformat() + 'Z'
-        self.audit_folder_id = None
-        
-    def setup_audit_folder(self) -> bool:
-        """Create audit folder structure in Google Drive"""
-        try:
-            # Create ci_audit_logs folder at root level (outside SyftBox)
-            # This ensures audit logs survive test cleanup
-            audit_folder_name = "CI_AUDIT_LOGS_DO_NOT_DELETE"
-            
-            # Check if folder exists at root level
-            results = self.client.service.files().list(
-                q=f"name='{audit_folder_name}' and 'root' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false",
-                fields="files(id)"
-            ).execute()
-            
-            if results.get('files'):
-                self.audit_folder_id = results['files'][0]['id']
-            else:
-                # Create audit folder at root level
-                folder_metadata = {
-                    'name': audit_folder_name,
-                    'mimeType': 'application/vnd.google-apps.folder',
-                    'parents': ['root']
-                }
-                folder = self.client.service.files().create(
-                    body=folder_metadata,
-                    fields='id'
-                ).execute()
-                self.audit_folder_id = folder.get('id')
-            
-            print(f"‚úÖ Audit folder ready: {audit_folder_name}")
-            return True
-            
-        except Exception as e:
-            print(f"‚ùå Failed to setup audit folder: {e}")
-            return False
-    
-    def log_test_start(self, test_details: Dict[str, Any]) -> Optional[str]:
-        """Log the start of a test with details"""
-        if not self.audit_folder_id and not self.setup_audit_folder():
-            return None
-            
-        try:
-            log_entry = {
-                "event": "test_start",
-                "test_name": self.test_name,
-                "timestamp": self.timestamp,
-                "ci_run_id": self.ci_run_id,
-                "ci_run_number": self.ci_run_number,
-                "commit_sha": self.commit_sha,
-                "actor": self.actor,
-                "user_email": self.client.my_email,
-                "test_details": test_details
-            }
-            
-            filename = f"test_start_{self.test_name}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.json"
-            
-            # Create file in Google Drive
-            file_metadata = {
-                'name': filename,
-                'mimeType': 'application/json',
-                'parents': [self.audit_folder_id]
-            }
-            
-            from googleapiclient.http import MediaInMemoryUpload
-            media = MediaInMemoryUpload(
-                json.dumps(log_entry, indent=2).encode('utf-8'),
-                mimetype='application/json'
-            )
-            
-            file = self.client.service.files().create(
-                body=file_metadata,
-                media_body=media,
-                fields='id,name'
-            ).execute()
-            
-            print(f"üìù Logged test start: {filename}")
-            return file.get('id')
-            
-        except Exception as e:
-            print(f"‚ö†Ô∏è Failed to log test start: {e}")
-            return None
-    
-    def log_communication(self, from_user: str, to_user: str, message: str = None) -> Optional[str]:
-        """Log proof of communication between users"""
-        if not self.audit_folder_id and not self.setup_audit_folder():
-            return None
-            
-        try:
-            log_entry = {
-                "event": "user_communication",
-                "timestamp": datetime.utcnow().isoformat() + 'Z',
-                "ci_run_id": self.ci_run_id,
-                "from_user": from_user,
-                "to_user": to_user,
-                "message": message or f"Test communication from {from_user} to {to_user}",
-                "proof": f"CI Run #{self.ci_run_number} - Commit: {self.commit_sha[:7]}"
-            }
-            
-            filename = f"comm_{from_user.split('@')[0]}_to_{to_user.split('@')[0]}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.json"
-            
-            # Create file in Google Drive
-            file_metadata = {
-                'name': filename,
-                'mimeType': 'application/json',
-                'parents': [self.audit_folder_id]
-            }
-            
-            from googleapiclient.http import MediaInMemoryUpload
-            media = MediaInMemoryUpload(
-                json.dumps(log_entry, indent=2).encode('utf-8'),
-                mimetype='application/json'
-            )
-            
-            file = self.client.service.files().create(
-                body=file_metadata,
-                media_body=media,
-                fields='id,name'
-            ).execute()
-            
-            print(f"üí¨ Logged communication: {from_user} ‚Üí {to_user}")
-            return file.get('id')
-            
-        except Exception as e:
-            print(f"‚ö†Ô∏è Failed to log communication: {e}")
-            return None
-    
-    def log_test_result(self, test_name: str, result: str, details: Dict[str, Any] = None) -> Optional[str]:
-        """Log test result with pass/fail status"""
-        if not self.audit_folder_id and not self.setup_audit_folder():
-            return None
-            
-        try:
-            log_entry = {
-                "event": "test_result",
-                "test_name": test_name,
-                "result": result,  # "PASSED" or "FAILED"
-                "timestamp": datetime.utcnow().isoformat() + 'Z',
-                "ci_run_id": self.ci_run_id,
-                "ci_run_number": self.ci_run_number,
-                "user_email": self.client.my_email,
-                "details": details or {}
-            }
-            
-            filename = f"result_{test_name}_{result}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.json"
-            
-            # Create file in Google Drive
-            file_metadata = {
-                'name': filename,
-                'mimeType': 'application/json',
-                'parents': [self.audit_folder_id]
-            }
-            
-            from googleapiclient.http import MediaInMemoryUpload
-            media = MediaInMemoryUpload(
-                json.dumps(log_entry, indent=2).encode('utf-8'),
-                mimetype='application/json'
-            )
-            
-            file = self.client.service.files().create(
-                body=file_metadata,
-                media_body=media,
-                fields='id,name'
-            ).execute()
-            
-            emoji = "‚úÖ" if result == "PASSED" else "‚ùå"
-            print(f"{emoji} Logged test result: {test_name} - {result}")
-            return file.get('id')
-            
-        except Exception as e:
-            print(f"‚ö†Ô∏è Failed to log test result: {e}")
-            return None
-    
-    def write_audit_ledger(self, summary: Dict[str, Any]) -> Optional[str]:
-        """Write or append to the main audit ledger file"""
-        if not self.audit_folder_id and not self.setup_audit_folder():
-            return None
-            
-        try:
-            ledger_name = "AUDIT_LEDGER.txt"
-            
-            # Check if ledger exists
-            results = self.client.service.files().list(
-                q=f"name='{ledger_name}' and '{self.audit_folder_id}' in parents and trashed=false",
-                fields="files(id)"
-            ).execute()
-            
-            # Create ledger entry
-            ledger_entry = f"""
-================================================================================
-CI RUN: {self.ci_run_id} (#{self.ci_run_number})
-DATE: {self.timestamp}
-COMMIT: {self.commit_sha}
-ACTOR: {self.actor}
-USER: {self.client.my_email}
-
-TEST RESULTS:
-{json.dumps(summary, indent=2)}
-
-STATUS: {"‚úÖ ALL TESTS PASSED" if summary.get('all_passed', False) else "‚ùå SOME TESTS FAILED"}
-================================================================================
-"""
-            
-            if results.get('files'):
-                # Append to existing ledger
-                file_id = results['files'][0]['id']
-                
-                # Get current content
-                current = self.client.service.files().get_media(fileId=file_id).execute()
-                updated_content = current.decode('utf-8') + '\n' + ledger_entry
-                
-                from googleapiclient.http import MediaInMemoryUpload
-                media = MediaInMemoryUpload(
-                    updated_content.encode('utf-8'),
-                    mimetype='text/plain'
-                )
-                
-                self.client.service.files().update(
-                    fileId=file_id,
-                    media_body=media
-                ).execute()
-                
-                print(f"üìö Updated audit ledger: {ledger_name}")
-                
-            else:
-                # Create new ledger
-                file_metadata = {
-                    'name': ledger_name,
-                    'mimeType': 'text/plain',
-                    'parents': [self.audit_folder_id]
-                }
-                
-                from googleapiclient.http import MediaInMemoryUpload
-                media = MediaInMemoryUpload(
-                    ledger_entry.encode('utf-8'),
-                    mimetype='text/plain'
-                )
-                
-                file = self.client.service.files().create(
-                    body=file_metadata,
-                    media_body=media,
-                    fields='id'
-                ).execute()
-                
-                print(f"üìö Created audit ledger: {ledger_name}")
-                return file.get('id')
-                
-        except Exception as e:
-            print(f"‚ö†Ô∏è Failed to write audit ledger: {e}")
-            return None
-    
-    def create_proof_message(self, target_folder_id: str, message_type: str = "test") -> Optional[str]:
-        """Create a proof message in a specific folder"""
-        try:
-            proof_content = f"""
-CI TEST MESSAGE
-===============
-Type: {message_type}
-CI Run ID: {self.ci_run_id} (#{self.ci_run_number})
-Timestamp: {datetime.utcnow().isoformat()}Z
-Commit: {self.commit_sha[:7]}
-Actor: {self.actor}
-From: {self.client.my_email}
-
-This message is proof that CI integration tests successfully executed
-and users were able to communicate through the SyftBox folders.
-"""
-            
-            filename = f"CI_PROOF_{self.ci_run_id}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.txt"
-            
-            file_metadata = {
-                'name': filename,
-                'mimeType': 'text/plain',
-                'parents': [target_folder_id]
-            }
-            
-            from googleapiclient.http import MediaInMemoryUpload
-            media = MediaInMemoryUpload(
-                proof_content.encode('utf-8'),
-                mimetype='text/plain'
-            )
-            
-            file = self.client.service.files().create(
-                body=file_metadata,
-                media_body=media,
-                fields='id,name'
-            ).execute()
-            
-            print(f"‚úâÔ∏è Created proof message: {filename}")
-            return file.get('id')
-            
-        except Exception as e:
-            print(f"‚ö†Ô∏è Failed to create proof message: {e}")
-            return None
\ No newline at end of file
