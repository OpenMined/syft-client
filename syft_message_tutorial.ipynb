{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SyftObject and SyftMessage Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the file-backed `SyftObject` and `SyftMessage` classes for secure, transport-agnostic file syncing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft_client as sc\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding SyftObject\n",
    "\n",
    "`SyftObject` is a base class that provides file-backed storage with:\n",
    "- Atomic operations (no partial writes)\n",
    "- Concurrency control (file locking)\n",
    "- Path security (prevents directory traversal)\n",
    "- Streaming for large files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: {\n",
      "  \"_schema_version\": \"1.0.0\",\n",
      "  \"_updated_at\": \"2025-08-22T14:10:21.276327\",\n",
      "  \"author\": \"alice@example.com\",\n",
      "  \"name\": \"Example Object\",\n",
      "  \"type\": \"demo\"\n",
      "}\n",
      "\n",
      "Directory structure:\n",
      "  .write_lock\n",
      "  data\n",
      "  metadata.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary directory for our examples\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    # Create a basic SyftObject\n",
    "    obj_path = Path(tmpdir) / \"my_object\"\n",
    "    obj = sc.SyftObject(obj_path)\n",
    "    \n",
    "    # Set some metadata\n",
    "    obj.set_metadata({\n",
    "        \"name\": \"Example Object\",\n",
    "        \"type\": \"demo\",\n",
    "        \"author\": \"alice@example.com\"\n",
    "    })\n",
    "    \n",
    "    # Read metadata back\n",
    "    metadata = obj.get_metadata()\n",
    "    print(\"Metadata:\", json.dumps(metadata, indent=2))\n",
    "    \n",
    "    # Check directory structure\n",
    "    print(\"\\nDirectory structure:\")\n",
    "    for p in sorted(obj_path.rglob(\"*\")):\n",
    "        print(f\"  {p.relative_to(obj_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {\"setting\": \"value\"}\n",
      "Users: [{'name': 'Alice'}, {'name': 'Bob'}]\n",
      "\n",
      "All data files:\n",
      "  config.json\n",
      "  users.json\n"
     ]
    }
   ],
   "source": [
    "# Working with data files\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    obj = sc.SyftObject(Path(tmpdir) / \"data_example\")\n",
    "    \n",
    "    # Write some data files\n",
    "    obj.write_data_file(\"config.json\", b'{\"setting\": \"value\"}')\n",
    "    obj.write_json(\"users.json\", [{\"name\": \"Alice\"}, {\"name\": \"Bob\"}])\n",
    "    \n",
    "    # Read them back\n",
    "    config = obj.read_data_file(\"config.json\")\n",
    "    users = obj.read_json(\"users.json\")\n",
    "    \n",
    "    print(\"Config:\", config.decode())\n",
    "    print(\"Users:\", users)\n",
    "    \n",
    "    # List all data files\n",
    "    print(\"\\nAll data files:\")\n",
    "    for f in obj.list_data_files():\n",
    "        print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checksum: 99baed7c2e510a0a2c3528fac497371276e05f848d7ce63d84b17b72f57dca29\n",
      "\n",
      "Is locked: True\n",
      "Lock info: {\n",
      "  \"checksum\": \"99baed7c2e510a0a2c3528fac497371276e05f848d7ce63d84b17b72f57dca29\",\n",
      "  \"locked_at\": \"2025-08-22T14:10:21.601665\",\n",
      "  \"schema_version\": \"1.0.0\",\n",
      "  \"finalized\": true,\n",
      "  \"reviewer\": \"bob@example.com\"\n",
      "}\n",
      "\n",
      "Checksum valid: True\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate checksums and locking\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    obj = sc.SyftObject(Path(tmpdir) / \"lockable\")\n",
    "    \n",
    "    # Add some content\n",
    "    obj.write_data_file(\"data.txt\", b\"Important data\")\n",
    "    obj.set_metadata({\"status\": \"draft\"})\n",
    "    \n",
    "    # Calculate checksum\n",
    "    checksum = obj.calculate_checksum()\n",
    "    print(f\"Checksum: {checksum}\")\n",
    "    \n",
    "    # Lock the object\n",
    "    obj.lock(finalized=True, reviewer=\"bob@example.com\")\n",
    "    \n",
    "    # Check lock status\n",
    "    print(f\"\\nIs locked: {obj.is_locked()}\")\n",
    "    print(f\"Lock info: {json.dumps(obj.get_lock_info(), indent=2)}\")\n",
    "    \n",
    "    # Verify integrity\n",
    "    print(f\"\\nChecksum valid: {obj.validate_checksum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Working with SyftMessage\n",
    "\n",
    "`SyftMessage` extends `SyftObject` for file syncing between users. It provides:\n",
    "- Message creation with unique IDs\n",
    "- File attachment with metadata\n",
    "- Permission tracking\n",
    "- Message validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID: gdrive_alice@example.com_bob@example.com_1755886221_0eaf44e9\n",
      "Sender: alice@example.com\n",
      "Recipient: bob@example.com\n",
      "Timestamp: 1755886221.937682\n"
     ]
    }
   ],
   "source": [
    "# Create a new message\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    # Create message root directory\n",
    "    outbox = Path(tmpdir) / \"outbox\"\n",
    "    outbox.mkdir()\n",
    "    \n",
    "    # Create a new message\n",
    "    message = sc.SyftMessage.create(\n",
    "        sender_email=\"alice@example.com\",\n",
    "        recipient_email=\"bob@example.com\",\n",
    "        message_root=outbox,\n",
    "        message_type=\"file_sync\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Message ID: {message.message_id}\")\n",
    "    print(f\"Sender: {message.sender_email}\")\n",
    "    print(f\"Recipient: {message.recipient_email}\")\n",
    "    print(f\"Timestamp: {message.timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added files:\n",
      "\n",
      "  data.csv:\n",
      "    Path: /alice@example.com/shared/data.csv\n",
      "    Size: 35 bytes\n",
      "    Hash: 4acab7e77f0730f4...\n",
      "    Read: ['bob@example.com', 'charlie@example.com']\n",
      "\n",
      "  report.txt:\n",
      "    Path: /alice@example.com/private/report.txt\n",
      "    Size: 30 bytes\n",
      "    Hash: d3777fdfd65c9f3b...\n",
      "    Read: ['bob@example.com']\n"
     ]
    }
   ],
   "source": [
    "# Add files to a message\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    # Create some test files\n",
    "    test_files = Path(tmpdir) / \"test_files\"\n",
    "    test_files.mkdir()\n",
    "    \n",
    "    # Create test data\n",
    "    (test_files / \"data.csv\").write_text(\"id,name,value\\n1,Alice,100\\n2,Bob,200\")\n",
    "    (test_files / \"report.txt\").write_text(\"This is a confidential report.\")\n",
    "    \n",
    "    # Create message\n",
    "    outbox = Path(tmpdir) / \"outbox\"\n",
    "    message = sc.SyftMessage.create(\n",
    "        sender_email=\"alice@example.com\",\n",
    "        recipient_email=\"bob@example.com\",\n",
    "        message_root=outbox\n",
    "    )\n",
    "    \n",
    "    # Add files with permissions\n",
    "    file1 = message.add_file(\n",
    "        source_path=test_files / \"data.csv\",\n",
    "        syftbox_path=\"/alice@example.com/shared/data.csv\",\n",
    "        permissions={\n",
    "            \"read\": [\"bob@example.com\", \"charlie@example.com\"],\n",
    "            \"write\": [\"alice@example.com\"],\n",
    "            \"admin\": [\"alice@example.com\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    file2 = message.add_file(\n",
    "        source_path=test_files / \"report.txt\",\n",
    "        syftbox_path=\"/alice@example.com/private/report.txt\",\n",
    "        permissions={\n",
    "            \"read\": [\"bob@example.com\"],\n",
    "            \"write\": [],\n",
    "            \"admin\": [\"alice@example.com\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"Added files:\")\n",
    "    for f in message.get_files():\n",
    "        print(f\"\\n  {f['filename']}:\")\n",
    "        print(f\"    Path: {f['syftbox_path']}\")\n",
    "        print(f\"    Size: {f['file_size']} bytes\")\n",
    "        print(f\"    Hash: {f['file_hash'][:16]}...\")\n",
    "        print(f\"    Read: {f['permissions']['read']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready before finalize: False\n",
      "Ready after finalize: True\n",
      "\n",
      "Validation: ✓ Valid\n",
      "\n",
      "Message structure:\n",
      "  .write_lock\n",
      "  README.html\n",
      "  data/files/test.txt\n",
      "  lock.json\n",
      "  metadata.yaml\n"
     ]
    }
   ],
   "source": [
    "# Finalize and validate a message\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    # Create and populate message\n",
    "    outbox = Path(tmpdir) / \"outbox\"\n",
    "    message = sc.SyftMessage.create(\n",
    "        sender_email=\"alice@example.com\",\n",
    "        recipient_email=\"bob@example.com\",\n",
    "        message_root=outbox\n",
    "    )\n",
    "    \n",
    "    # Add a test file\n",
    "    test_file = Path(tmpdir) / \"test.txt\"\n",
    "    test_file.write_text(\"Hello, Bob!\")\n",
    "    message.add_file(test_file, \"/alice@example.com/notes/test.txt\")\n",
    "    \n",
    "    # Add a README\n",
    "    message.add_readme(\"\"\"\n",
    "    <html>\n",
    "    <body>\n",
    "        <h1>File Update</h1>\n",
    "        <p>Hi Bob, here's the latest test file.</p>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\")\n",
    "    \n",
    "    print(f\"Ready before finalize: {message.is_ready}\")\n",
    "    \n",
    "    # Finalize the message\n",
    "    message.finalize()\n",
    "    \n",
    "    print(f\"Ready after finalize: {message.is_ready}\")\n",
    "    \n",
    "    # Validate the message\n",
    "    is_valid, error = message.validate()\n",
    "    print(f\"\\nValidation: {'✓ Valid' if is_valid else f'✗ Invalid: {error}'}\")\n",
    "    \n",
    "    # Show directory structure\n",
    "    print(\"\\nMessage structure:\")\n",
    "    for p in sorted(message.path.rglob(\"*\")):\n",
    "        if p.is_file():\n",
    "            print(f\"  {p.relative_to(message.path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Simulating Message Transfer\n",
    "\n",
    "Let's simulate sending a message from Alice to Bob through a shared folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ALICE CREATES MESSAGE ===\n",
      "Created message: gdrive_alice@research.org_bob@research.org_1755886222_2d86efc4\n",
      "Sent to shared folder: gdrive_alice@research.org_bob@research.org_1755886222_2d86efc4\n",
      "\n",
      "=== BOB RECEIVES MESSAGE ===\n",
      "Message valid: True\n",
      "\n",
      "Extracting: alice_data.csv\n",
      "  From: alice@research.org\n",
      "  Target path: /alice@research.org/results/metrics.csv\n",
      "  Permissions: Read=['bob@research.org']\n",
      "  Content: metric,value\n",
      "accuracy,0.95\n",
      "loss,0.05\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    tmpdir = Path(tmpdir)\n",
    "    \n",
    "    # Setup directories\n",
    "    alice_outbox = tmpdir / \"alice\" / \"outbox\"\n",
    "    shared_folder = tmpdir / \"shared\" / \".syft\" / \"messages\"\n",
    "    bob_inbox = tmpdir / \"bob\" / \"inbox\"\n",
    "    \n",
    "    for d in [alice_outbox, shared_folder, bob_inbox]:\n",
    "        d.mkdir(parents=True)\n",
    "    \n",
    "    # ALICE: Create and send a message\n",
    "    print(\"=== ALICE CREATES MESSAGE ===\")\n",
    "    \n",
    "    # Create test file\n",
    "    alice_data = tmpdir / \"alice_data.csv\"\n",
    "    alice_data.write_text(\"metric,value\\naccuracy,0.95\\nloss,0.05\")\n",
    "    \n",
    "    # Create message\n",
    "    message = sc.SyftMessage.create(\n",
    "        sender_email=\"alice@research.org\",\n",
    "        recipient_email=\"bob@research.org\",\n",
    "        message_root=alice_outbox\n",
    "    )\n",
    "    \n",
    "    # Add file\n",
    "    message.add_file(\n",
    "        source_path=alice_data,\n",
    "        syftbox_path=\"/alice@research.org/results/metrics.csv\",\n",
    "        permissions={\n",
    "            \"read\": [\"bob@research.org\"],\n",
    "            \"write\": [\"alice@research.org\"],\n",
    "            \"admin\": [\"alice@research.org\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Finalize\n",
    "    message.finalize()\n",
    "    print(f\"Created message: {message.message_id}\")\n",
    "    \n",
    "    # \"Send\" by copying to shared folder\n",
    "    shared_msg_path = shared_folder / message.path.name\n",
    "    shutil.copytree(message.path, shared_msg_path)\n",
    "    print(f\"Sent to shared folder: {shared_msg_path.name}\")\n",
    "    \n",
    "    # BOB: Receive and process the message\n",
    "    print(\"\\n=== BOB RECEIVES MESSAGE ===\")\n",
    "    \n",
    "    # \"Receive\" by copying from shared folder\n",
    "    bob_msg_path = bob_inbox / message.path.name\n",
    "    shutil.copytree(shared_msg_path, bob_msg_path)\n",
    "    \n",
    "    # Load the message\n",
    "    received_msg = sc.SyftMessage(bob_msg_path)\n",
    "    \n",
    "    # Validate\n",
    "    is_valid, error = received_msg.validate()\n",
    "    print(f\"Message valid: {is_valid}\")\n",
    "    \n",
    "    # Extract files\n",
    "    bob_files = tmpdir / \"bob\" / \"extracted\"\n",
    "    bob_files.mkdir()\n",
    "    \n",
    "    for file_info in received_msg.get_files():\n",
    "        print(f\"\\nExtracting: {file_info['filename']}\")\n",
    "        print(f\"  From: {received_msg.sender_email}\")\n",
    "        print(f\"  Target path: {file_info['syftbox_path']}\")\n",
    "        print(f\"  Permissions: Read={file_info['permissions']['read']}\")\n",
    "        \n",
    "        # Extract the file\n",
    "        dest = bob_files / file_info['filename']\n",
    "        received_msg.extract_file(file_info['filename'], dest)\n",
    "        \n",
    "        # Read and display content\n",
    "        print(f\"  Content: {dest.read_text()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Security Features\n",
    "\n",
    "Let's demonstrate the security features that protect against malicious inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Blocked: ../../../etc/passwd - Path traversal attempt detected: ../../../etc/passwd\n",
      "✓ Blocked: ./../sensitive.txt - Path traversal attempt detected: ./../sensitive.txt\n",
      "✓ Blocked: subdir/../../../escape.txt - Path traversal attempt detected: subdir/../../../escape.txt\n",
      "✓ Blocked: .hidden_file.txt - Hidden files not allowed: .hidden_file.txt\n",
      "✓ Allowed: data.txt\n",
      "✓ Allowed: report.pdf\n",
      "✓ Allowed: results_2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Path traversal protection\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    obj = sc.SyftObject(Path(tmpdir) / \"secure_object\")\n",
    "    \n",
    "    # These will be rejected\n",
    "    dangerous_names = [\n",
    "        \"../../../etc/passwd\",\n",
    "        \"./../sensitive.txt\", \n",
    "        \"subdir/../../../escape.txt\",\n",
    "        \".hidden_file.txt\"\n",
    "    ]\n",
    "    \n",
    "    for name in dangerous_names:\n",
    "        try:\n",
    "            obj.write_data_file(name, b\"malicious content\")\n",
    "            print(f\"❌ SECURITY FAIL: {name} was allowed!\")\n",
    "        except ValueError as e:\n",
    "            print(f\"✓ Blocked: {name} - {e}\")\n",
    "    \n",
    "    # These are safe\n",
    "    safe_names = [\"data.txt\", \"report.pdf\", \"results_2024.csv\"]\n",
    "    \n",
    "    for name in safe_names:\n",
    "        try:\n",
    "            obj.write_data_file(name, b\"safe content\")\n",
    "            print(f\"✓ Allowed: {name}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"❌ Wrongly blocked: {name} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Concurrent access demonstration\nimport threading\nimport time\n\nwith tempfile.TemporaryDirectory() as tmpdir:\n    obj = sc.SyftObject(Path(tmpdir) / \"concurrent_test\")\n    \n    # Initial value\n    obj.set_metadata({\"counter\": 0})\n    \n    def increment_counter(thread_id):\n        for i in range(5):\n            # WRONG WAY - Race condition!\n            # current = obj.get_metadata()[\"counter\"]\n            # time.sleep(0.01)  # Simulate some work\n            # obj.update_metadata({\"counter\": current + 1})\n            \n            # RIGHT WAY - Atomic update\n            def atomic_increment(metadata):\n                current = metadata.get(\"counter\", 0)\n                time.sleep(0.01)  # Simulate some work\n                metadata[\"counter\"] = current + 1\n                print(f\"Thread {thread_id}: incremented to {current + 1}\")\n                return metadata\n            \n            obj.update_metadata_atomic(atomic_increment)\n    \n    # Run two threads concurrently\n    t1 = threading.Thread(target=increment_counter, args=(1,))\n    t2 = threading.Thread(target=increment_counter, args=(2,))\n    \n    t1.start()\n    t2.start()\n    \n    t1.join()\n    t2.join()\n    \n    # Check final value\n    final = obj.get_metadata()[\"counter\"]\n    print(f\"\\nFinal counter: {final}\")\n    print(f\"Expected: 10\")\n    print(f\"Correct: {final == 10}\")"
  },
  {
   "cell_type": "markdown",
   "source": "### Concurrent Access: Wrong Way vs Right Way\n\nThe following example shows why you need atomic operations for concurrent updates:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# WRONG WAY - Race condition demonstration\nimport threading\nimport time\n\nwith tempfile.TemporaryDirectory() as tmpdir:\n    obj = sc.SyftObject(Path(tmpdir) / \"race_condition_demo\")\n    obj.set_metadata({\"counter\": 0})\n    \n    def bad_increment(thread_id):\n        for i in range(5):\n            # Reading and writing are separate operations\n            current = obj.get_metadata()[\"counter\"]\n            time.sleep(0.01)  # This delay makes the race condition more likely\n            obj.update_metadata({\"counter\": current + 1})\n            print(f\"Thread {thread_id}: incremented to {current + 1}\")\n    \n    threads = [threading.Thread(target=bad_increment, args=(i,)) for i in range(2)]\n    for t in threads:\n        t.start()\n    for t in threads:\n        t.join()\n    \n    final = obj.get_metadata()[\"counter\"]\n    print(f\"\\nFinal counter: {final} (Expected: 10)\")\n    print(\"❌ Race condition causes lost updates!\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# RIGHT WAY - Using atomic updates\nimport threading\nimport time\n\nwith tempfile.TemporaryDirectory() as tmpdir:\n    obj = sc.SyftObject(Path(tmpdir) / \"atomic_demo\")\n    obj.set_metadata({\"counter\": 0})\n    \n    def good_increment(thread_id):\n        for i in range(5):\n            # The update function is called while holding an exclusive lock\n            def atomic_update(metadata):\n                current = metadata.get(\"counter\", 0)\n                time.sleep(0.01)  # Work inside the lock is atomic\n                metadata[\"counter\"] = current + 1\n                print(f\"Thread {thread_id}: incremented to {current + 1}\")\n                return metadata\n            \n            obj.update_metadata_atomic(atomic_update)\n    \n    threads = [threading.Thread(target=good_increment, args=(i,)) for i in range(2)]\n    for t in threads:\n        t.start()\n    for t in threads:\n        t.join()\n    \n    final = obj.get_metadata()[\"counter\"]\n    print(f\"\\nFinal counter: {final} (Expected: 10)\")\n    print(\"✅ Atomic updates ensure correctness!\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Performance with Large Files\n",
    "\n",
    "The streaming features allow handling large files without loading them into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10MB file using streaming...\n",
      "Written to: /private/var/folders/d4/s582723j2hqbtw60rnn5345r0000gn/T/tmpjpi4y43k/large_files/data/large_data.bin\n",
      "\n",
      "Calculating hash (streaming)...\n",
      "Hash: 462a12a876c0364e...\n",
      "\n",
      "File size: 10.0 MB\n",
      "✓ File processed without loading into memory\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    obj = sc.SyftObject(Path(tmpdir) / \"large_files\")\n",
    "    \n",
    "    # Create a \"large\" file using a stream\n",
    "    # (In practice, this could be a multi-GB file)\n",
    "    class LargeFileStream(io.BytesIO):\n",
    "        def __init__(self, size_mb=10):\n",
    "            self.size = size_mb * 1024 * 1024\n",
    "            self.position = 0\n",
    "        \n",
    "        def read(self, size=-1):\n",
    "            if size == -1:\n",
    "                size = self.size - self.position\n",
    "            else:\n",
    "                size = min(size, self.size - self.position)\n",
    "            \n",
    "            if size <= 0:\n",
    "                return b''\n",
    "            \n",
    "            # Generate data on the fly\n",
    "            data = b'x' * size\n",
    "            self.position += size\n",
    "            return data\n",
    "    \n",
    "    # Write a \"10MB\" file using streaming\n",
    "    print(\"Writing 10MB file using streaming...\")\n",
    "    stream = LargeFileStream(10)\n",
    "    path = obj.write_data_file_stream(\"large_data.bin\", stream)\n",
    "    print(f\"Written to: {path}\")\n",
    "    \n",
    "    # Calculate hash without loading into memory\n",
    "    print(\"\\nCalculating hash (streaming)...\")\n",
    "    file_hash = obj.calculate_file_hash(path)\n",
    "    print(f\"Hash: {file_hash[:16]}...\")\n",
    "    \n",
    "    # The file is processed in chunks, not loaded entirely\n",
    "    print(f\"\\nFile size: {path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "    print(\"✓ File processed without loading into memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The `SyftObject` and `SyftMessage` classes provide:\n",
    "\n",
    "1. **File-backed storage** - All data persists to disk\n",
    "2. **Atomic operations** - No partial writes or corrupted state\n",
    "3. **Concurrency safety** - Multiple processes can access safely\n",
    "4. **Security** - Path traversal protection and input validation\n",
    "5. **Performance** - Streaming for large files\n",
    "6. **Transport agnostic** - Can be used with any transport (email, GDrive, etc.)\n",
    "\n",
    "### Important Notes on Locking\n",
    "\n",
    "The implementation uses file-based locking to prevent concurrent access issues:\n",
    "- **exclusive_access()** - Used for write operations\n",
    "- **shared_access()** - Used for read operations  \n",
    "- Methods ending in **_no_lock()** are internal and assume the caller already holds a lock\n",
    "\n",
    "This prevents deadlocks when methods call each other internally.\n",
    "\n",
    "These building blocks enable secure, decentralized file syncing as described in the Beach RFC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}